[{"categories":null,"content":"slice 切片 切片是基于数组实现的，它的底层是数组，可以理解为对 底层数组的抽象。 切片不是线程安全的 源码包中src/runtime/slice.go 定义了slice的数据结构： type slice struct { array unsafe.Pointer //底层指针 len int //长度 cap int //预存空间 } slice：占用24个字节 array：指向底层数组的指针，占用8个字节 len：切片的长度，占用8个字节 cap：切片的容量，cap 总是大于等于 len 的，占用8个字节 slice有4种初始化方式 // 初始化方式1：直接声明 var slice1 []int // 初始化方式2：使用字面量 slice2 := []int{1, 2, 3, 4} // 初始化方式3：使用make创建slice slice3 := make([]int, 3, 5) // 初始化方式4: 从切片或数组“截取” slcie4 := arr[1:3] 通过一个简单程序，看下slice初始化调用的底层函数 package main import \"fmt\" func main() { slice := make([]int, 0) slice = append(slice, 1) fmt.Println(slice, len(slice), cap(slice)) } 通过 go tool compile -S test.go | grep CALL 得到汇编代码 0x0042 00066 (test.go:6) CALL runtime.makeslice(SB) 0x006d 00109 (test.go:7) CALL runtime.growslice(SB) 0x00a4 00164 (test.go:8) CALL runtime.convTslice(SB) 0x00c0 00192 (test.go:8) CALL runtime.convT64(SB) 0x00d8 00216 (test.go:8) CALL runtime.convT64(SB) 0x0166 00358 ($GOROOT/src/fmt/print.go:274) CALL fmt.Fprintln(SB) 0x0180 00384 (test.go:5) CALL runtime.morestack_noctxt(SB) 0x0079 00121 (\u003cautogenerated\u003e:1) CALL runtime.efaceeq(SB) 0x00a0 00160 (\u003cautogenerated\u003e:1) CALL runtime.morestack_noctxt(SB) 初始化slice调用的是runtime.makeslice，makeslice函数的工作主要就是计算slice所需内存大小，然后调用mallocgc进行内存的分配 所需内存大小 = 切片中元素大小 * 切片的容量 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { // NOTE: Produce a len out of range error instead of a // cap out of range error when someone does make([]T, bignumber). // cap out of range is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } 数组和切片slice的区别 1） 数组长度不同 数组初始化必须指定长度，并且长度就是固定的 切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大 2）函数传参不同 数组是值类型，将一个数组赋值给另一个数组时，传递的是一份深拷贝，函数传参操作都会复制整个数组数据，会占用额外的内存，函数内对数组元素值的修改，不会修改原数组内容。 切片是引用类型，将一个切片赋值给另一个切片时，传递的是一份浅拷贝，函数传参操作不会拷贝整个切片，只会复制len和cap，底层共用同一个数组，不会占用额外的内存，函数内对数组元素值的修改，会修改原数组内容。 3）计算数组长度方式不同 数组需要遍历计算数组长度，时间复杂度为O(n) 切片底层包含len字段，可以通过len()计算切片长度，时间复杂度为O(1) Map Go中的map是一个指针，占用8个字节，指向hmap结构体 源码包中src/runtime/map.go定义了hmap的数据结构： hmap包含若干个结构为bmap的数组，每个bmap底层都采用链表结构，bmap通常叫其bucket hmap结构体 // A header for a Go map. type hmap struct { count int // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。 flags uint8 // 状态标志（是否处于正在写入的状态等） B uint8 // buckets（桶）的对数 // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶 noverflow uint16 // 溢出桶的数量 hash0 uint32 // 生成hash的随机数种子 buckets unsafe.Pointer // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。 oldbuckets unsafe.Pointer // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。 nevacuate uintptr // 表示扩容进度，小于此地址的buckets代表已搬迁完成。 extra *mapextra // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍 } bmap结构体 bmap 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低B位是相同的，关于key的定位我们在map的查询中详细说明。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置)。 // A bucket for a Go map. type bmap struct { tophash [bucketCnt]uint8 // len为8的数组 // 用来快速定位key是否在这个bmap中 // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中 } 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体： type bmap struct{ tophash [8]uint8 keys [8]keytype // keytype 由编译器编译时候确定 values [8]elemtype // elemtype 由编译器编译时候确定 overflow uintptr // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中 } tophash就是用于实现快速定位key的位置，在实现过程中会使用key的hash值的高8位作为tophash值，存放在bmap的tophash字段中 tophash字段不仅存储key哈希值的高8位，还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于minTopHash的 为了避免key哈希值的高8位值和这些状态值相等，产生混淆情况，所以当key哈希值高8位若小于minTopHash时候，自动将其值加上minTopHash作为该key的tophash。桶单元的状态值如下： emptyRest = 0 // 表明此桶单元为空，且更高索引的单元也是空 emptyOne = 1 // 表明此桶单元为空 evacuatedX = 2 // 用于表示扩容迁移到新桶前半段区间 evacuatedY = 3 // 用于表示扩容迁移到新桶后半段区间 evacuatedEmpty = 4 // 用于表示此单元已迁移 minTopHash = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值 func tophash(hash uintptr) uint8 { top ","date":"2022-05-10","objectID":"/map%E5%92%8Cslice%E5%8E%9F%E7%90%86%E5%BA%95%E5%B1%82/:0:0","tags":null,"title":"Map和slice原理底层","uri":"/map%E5%92%8Cslice%E5%8E%9F%E7%90%86%E5%BA%95%E5%B1%82/"},{"categories":null,"content":"总结 bmap（bucket）内存数据结构可视化如下: 注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/… 这样的形式，当key和value类型不一样的时候，key和value占用字节大小不一样，使用key/value这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间 ","date":"2022-05-10","objectID":"/map%E5%92%8Cslice%E5%8E%9F%E7%90%86%E5%BA%95%E5%B1%82/:1:0","tags":null,"title":"Map和slice原理底层","uri":"/map%E5%92%8Cslice%E5%8E%9F%E7%90%86%E5%BA%95%E5%B1%82/"},{"categories":null,"content":"内存逃逸 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:0:0","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"暂时性内存泄漏 获取长字符串中的一段导致长字符串未被释放 获取长slice中的一段导致长slice未被释放 在长slice中新建slice导致泄漏 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:0:1","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"永久性内存泄漏 goroutine泄漏 time.Ticker 未关闭导致泄漏 Finalizer导致泄漏 Deferring Function Call导致泄漏 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:0:2","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"常见的内存逃逸 指针逃逸 栈空间不足 变量大小不确定 动态类型 闭包引用对象 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:1:0","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"小总结 栈上分配内存比在堆中分配内存效率更高 栈上分配的内存不需要 GC 处理，而堆需要 逃逸分析目的是决定内分配地址是栈还是堆 逃逸分析在编译阶段完成 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:2:0","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"堆与栈 ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:3:0","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"常见的逃逸现象 package main import \"fmt\" func main() { name := test() fmt.Println(name()) } func test() func() string { return func() string { //name 从原来的栈上，逃逸到堆上 return \"公众号-后端时光\" } } // go build -gcflags=\"-m -l\" eee.go // -m：表示内存分析 -l：表示防止内联优化 原因是 go/src/fmt/print.go 文件中 Println 方法传参数类型 interface{}, 编译器对传入的变量类型未知，所有统一处理分配到了堆上面去了。 pprof排查 什么是pprof? pprof是Go的性能分析工具,在程序运行中可以记录程序的运行信息,可以是CPU使用情况、内存使用情况、goroutine运行状况等,当需要性能调优或定位bug时候,这些记录的信息是相当重要。 package main import ( \"fmt\" \"net/http\" _ \"net/http/pprof\" ) func main() { ip := \"127.0.0.1:6069\" if err := http.ListenAndServe(ip, nil); err != nil { fmt.Printf(\"start pprof failed on %s\\n\", ip) } } ","date":"2022-05-10","objectID":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/:4:0","tags":null,"title":"内存逃逸","uri":"/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":null,"content":"redis 简介：Redis ，全称 Remote Dictionary Server ，是一个基于内存的高性能 Key-Value 数据库。 脚本自动安装任意版本 sh redis-install.sh 4.0.10 #! /usr/bin/bash ##redis任何版本全程自动化源码编译安装 ##用法：sh redis-install.sh 4.0.10 （后面跟的是你需要的版本号，需要什么版本就写什么版本），我这里安装的4.0.10 version=$1 usage(){ echo \"usage: $0version\" } if [ $# -ne 1 ] then usage exit -1 fi #Redis安装包下载 cd /usr/local/src if [ ! -f redis-${version}.tar.gz ] then curl -o /usr/local/src/redis-${version}.tar.gz http://download.redis.io/releases/redis-${version}.tar.gz fi #Redis依赖包安装 yum clean all yum makecache fast yum -y install gcc gcc-c++ tcl #编译Redis所需要的gcc yum -y install centos-release-scl yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils source /opt/rh/devtoolset-9/enable echo \"source /opt/rh/devtoolset-9/enable\" \u003e\u003e/etc/profile gcc --version ##内系统参数核优化 cat \u003e\u003e /etc/rc.d/rc.local \u003c\u003c \"EOF\" ##关闭Linux的THP（内存管理系统）通过使用更大的内存页面，来减少具有大量内存的计算机上的TLB的开销 if [ -f /sys/kernel/mm/transparent_hugepage/enabled ] then echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled fi if [ -f /sys/kernel/mm/transparent_hugepage/defrag ] then echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag fi EOF chmod u+x /etc/rc.d/rc.local if [ -f /sys/kernel/mm/transparent_hugepage/enabled ] then echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled fi if [ -f /sys/kernel/mm/transparent_hugepage/defrag ] then echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag fi cat \u003e\u003e /etc/sysctl.conf \u003c\u003c \"EOF\" #Linux系统内核参数优化 net.core.somaxconn = 2048 net.ipv4.tcp_max_syn_backlog = 2048 vm.overcommit_memory = 1 EOF sysctl -p cat \u003e /etc/security/limits.conf \u003c\u003c \"EOF\" root soft nofile 65535 root hard nofile 65535 * soft nofile 65535 * hard nofile 65535 EOF #Redis编译安装 cd /usr/local/src tar -zxvf redis-${version}.tar.gz cd /usr/local/src/redis-${version} make make PREFIX=/usr/local/redis install #Redis基础配置 mkdir -p /usr/local/redis/{etc,logs,data} egrep -v \"^$|^#\" /usr/local/src/redis-${version}/redis.conf \u003e /usr/local/redis/etc/redis.conf #sed -i \"s/bind 127.0.0.1/bind 0.0.0.0/g\" /usr/local/redis/etc/redis.conf sed -i \"s/protected-mode yes/protected-mode no/g\" /usr/local/redis/etc/redis.conf sed -i \"s/daemonize no/daemonize yes/g\" /usr/local/redis/etc/redis.conf sed -i \"s/pidfile \\/var\\/run\\/redis_6379.pid/pidfile \\/usr\\/local\\/redis\\/redis.pid/g\" /usr/local/redis/etc/redis.conf sed -i \"s/dir \\.\\//dir \\/usr\\/local\\/redis\\/data/g\" /usr/local/redis/etc/redis.conf sed -i \"s/logfile \\\"\\\"/logfile \\\"\\/usr\\/local\\/redis\\/logs\\/redis.log\\\"/g\" /usr/local/redis/etc/redis.conf sed -i \"s/dbfilename dump.rdb/dbfilename dump.rdb/g\" /usr/local/redis/etc/redis.conf sed -i \"s/appendfilename \\\"appendonly.aof\\\"/appendfilename \\\"appendonly.aof\\\"/g\" /usr/local/redis/etc/redis.conf #PATH配置 echo \"export PATH=${PATH}:/usr/local/redis/bin\" \u003e\u003e/etc/profile source /etc/profile #启动redis服务 /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf #查看redis监听端口 netstat -tanp|grep redis ","date":"2022-05-09","objectID":"/redis/:0:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Redis 有哪些数据结构？ 如果你是 Redis 普通玩家，可能你的回答是如下五种数据结构： 字符串 String 字典 Hash 列表 List 集合 Set 有序集合 SortedSet 如果你是 Redis 中级玩家，还需要加上下面几种数据结构： HyperLogLog Geo Bitmap 如果你是 Redis 高端玩家，你可能玩过 Redis Module ，可以再加上下面几种数据结构： BloomFilter RedisSearch Redis-ML JSON 另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。 ","date":"2022-05-09","objectID":"/redis/:1:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Redis 的线程模型 redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。 文件事件处理器的结构包含 4 个部分： 多个 Socket 。 IO 多路复用程序。 文件事件分派器。 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。 多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 来看客户端与 redis 的一次通信过程： ","date":"2022-05-09","objectID":"/redis/:2:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"redis-single-thread-model 客户端 Socket01 向 Redis 的 Server Socket 请求建立连接，此时 Server Socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 Socket01，并将该 Socket01 的 AE_READABLE 事件与命令请求处理器关联。 假设此时客户端发送了一个 set key value 请求，此时 Redis 中的 Socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 Socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 Scket01 的 set key value 并在自己内存中完成 set key value 的设置。操作完成后，它会将 Scket01 的 AE_WRITABLE 事件与令回复处理器关联。 如果此时客户端准备好接收返回结果了，那么 Redis 中的 Socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 Socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。 这样便完成了一次通信。 ","date":"2022-05-09","objectID":"/redis/:2:1","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Redis 单线程模型也能效率这么高？ C 语言实现。 我们都知道，C 语言的执行速度非常快。 纯内存操作。 Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。 如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。 基于非阻塞的 IO 多路复用机制。 单线程，避免了多线程的频繁上下文切换问题。 Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销。 实际上，Redis 4.0 开始，也开始有了一些异步线程，用于处理一些耗时操作。例如说，异步线程，实现惰性删除（解决大 KEY 删除，阻塞主线程）和异步 AOF （解决磁盘 IO 紧张时，fsync 执行一次很慢）等等。 丰富的数据结构。 Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化。例如，压缩表，对短数据进行压缩存储；再再如，跳表，使用有序的数据结构加快读取的速度。 也因为 Redis 是单线程的，所以可以实现丰富的数据结构，无需考虑并发的问题。 ","date":"2022-05-09","objectID":"/redis/:3:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Redis 是单线程的，如何提高多核 CPU 的利用率？ 可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个 CPU ，你可以考虑一下分区。 ","date":"2022-05-09","objectID":"/redis/:4:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Redis 有几种持久化方式？ Redis 提供了两种方式，实现数据的持久化到硬盘。 1、【全量】RDB 持久化，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 2、【增量】AOF持久化，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 ","date":"2022-05-09","objectID":"/redis/:5:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"有哪几种数据“淘汰”策略？ Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。 Redis 提供了 6 种数据淘汰策略： volatile-lru volatile-ttl volatile-random allkeys-lru allkeys-random 【默认策略】no-enviction 具体的每种数据淘汰策略的定义，和如何选择讨论策略，可见 《Redis实战（二） 内存淘汰机制》 。 在 Redis 4.0 后，基于 LFU（Least Frequently Used）最近最少使用算法，增加了 2 种淘汰策略： volatile-lfu allkeys-lfu 🦅 Redis LRU 算法 另外，Redis 的 LRU 算法，并不是一个严格的 LRU 实现。这意味着 Redis 不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的 LRU 算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久未被访问时间)的那个。 Redis 没有使用真正实现严格的 LRU 算是的原因是，因为消耗更多的内存。然而对于使用 Redis 的应用来说，使用近似的 LRU 算法，事实上是等价的。 ","date":"2022-05-09","objectID":"/redis/:6:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"理解回收进程如何工作是非常重要的： 一个客户端运行了新的写命令，添加了新的数据。 Redis 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。 Redis 执行新命令。 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下（跌宕起伏）。 ","date":"2022-05-09","objectID":"/redis/:7:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。 一般需要在时间上加一个随机值，使得过期时间分散一些。 是调大 hz 参数，每次过期的 key 更多，从而最终达到避免一次过期过多。 这个定期的频率，由配置文件中的 hz 参数决定，代表了一秒钟内，后台任务期望被调用的次数。Redis 3.0.0 中的默认值是 10 ，代表每秒钟调用 10 次后台任务。 hz 调大将会提高 Redis 主动淘汰的频率，如果你的 Redis 存储中包含很多冷数据占用内存过大的话，可以考虑将这个值调大，但 Redis 作者建议这个值不要超过 100 。我们实际线上将这个值调大到 100 ，观察到 CPU 会增加 2% 左右，但对冷数据的内存释放速度确实有明显的提高（通过观察 keyspace 个数和 used_memory 大小）。 ","date":"2022-05-09","objectID":"/redis/:8:0","tags":null,"title":"Redis","uri":"/redis/"},{"categories":null,"content":"Mysql面试 ","date":"2022-04-26","objectID":"/mysql/:0:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是MySQL MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。在Java企业级开发中非常常用，因为 MySQL 是开源免费的，并且方便扩展。 ","date":"2022-04-26","objectID":"/mysql/:1:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"数据库三大范式是什么 第一范式:每个列都不可拆分 第二范式:在第一范式的基础上,非主键列完全依赖于主键,而不能是依赖于主键的一部分。 第三范式:在第二范式的基础上,非主键列只依赖于主键,不依赖于其他非主键。 ","date":"2022-04-26","objectID":"/mysql/:2:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql有关权限的表都有几个 这些表分别为user, db, table_priv, columns_priv和host。下面分别介绍一下这些表的结构和内容: user权限表:记录允许连接到服务器的用户账户信息,里面的权限是全局级的 db权限表:记录各个账号在各个数据库上的操作权限 table_priv权限表:记录数据表级的操作权限 columns_priv权限表:记录数据列级的操作权限 host权限表:配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。 ","date":"2022-04-26","objectID":"/mysql/:3:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql的binlog有几种录入格式?分别有什么区别 有三种格式 statement, row和mixed。 statement模式下,每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化,减少binlog日志量,节约了IO,提高性能。由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息,同时还有一些使用了函数之类的语句无法被记录复制。 row模式下,不记录sql语句上下文相关信息,仅保存哪条记录被修改。记录单元为每一行的改动,基本是可以全部记录下来但是由于很多操作,会导致大量的改动 mixed模式下,一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row ","date":"2022-04-26","objectID":"/mysql/:4:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql存储引擎MyISAM与InnoDB区别 常用的存储引擎有以下: Innodb引擎:Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。 MyISAM引擎:不提供事务的支持,也不支持行级锁和外键 MEMORY引擎:所有的数据都存在内存中,数据的处理速度快,但是安全性不高。 MyISAM与InnoDB区别 MyISAM Innodb 存储结构 每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB 存储空间 MyISAM可被压缩，存储空间较小 InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 可移植性、备份及恢复 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了 文件格式 数据和索引是分别存储的，数据.MYD，索引.MYI 数据和索引是集中存储的，.ibd 记录存储顺序 按记录插入顺序保存 按主键大小有序插入 外键 不支持 支持 事务 不支持 支持 锁支持（锁是避免资源争用的一个机制，MySQL锁对用户几乎是透明的） 表级锁定 行级锁定、表级锁定，锁定力度小并发能力高 SELECT MyISAM更优 INSERT、UPDATE、DELETE InnoDB更优 select count(*) myisam更快，因为myisam内部维护了一个计数器，可以直接调取。 索引的实现方式 B+树索引，myisam 是堆表 B+树索引，Innodb 是索引组织表 哈希索引 不支持 支持 全文索引 支持 不支持 ","date":"2022-04-26","objectID":"/mysql/:5:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"MyISAM索引与InnoDB索引的区别？ InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。 InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。 ","date":"2022-04-26","objectID":"/mysql/:6:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"InnoDB引擎的4大特性 插入缓冲（insert buffer) insert buffer是一种特殊的数据结构（B+ tree）并不是缓存的一部分，而是物理页，当受影响的索引页不在buffer pool时缓存 secondary index pages的变化，当buffer page读入buffer pool时，进行合并操作，这些操作可以是 INSERT, UPDATE, or DELETE operations (DML) 二次写(double write) 当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。 自适应哈希索引(ahi) Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升 预读(read ahead) 用于异步将磁盘的页读取到buffer pool中，预料这些页会马上被读取到。预读请求的所有页集中在一个范围内 ","date":"2022-04-26","objectID":"/mysql/:7:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"存储引擎选择 如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如OA自动化办公系统。 ","date":"2022-04-26","objectID":"/mysql/:8:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是索引 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分),它们包含着对数据表里所有记录的引用指针。 索引是一种数据结构。数据库索引,是数据库管理系统中一个排序的数据结构,以协助快速查询、更新数据库表中数据。索引的实现通常用B树及其变种B+树。 ","date":"2022-04-26","objectID":"/mysql/:9:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"索引有哪些优缺点 索引的优点 通过创建唯一索引可以保证数据库表中每一行数据的唯一性。 可以给所有的 MySQL 列类型设置索引。 在实现数据的参考完整性方面可以加速表与表之间的连接。 在使用分组和排序子句进行数据查询时也可以显著减少查询中分组和排序的时间 可以大大加快数据的检索速度,这也是创建索引的最主要的原因。 通过使用索引,可以在查询的过程中,使用优化隐藏器,提高系统的性能。 索引的缺点 创建索引以及维护索引要耗费时间,具体地,当对表中地数据进行增加、删除和修改地时候，索引也要动态地维护，会降低增删改查地效率; 索引也占用物理空间 ","date":"2022-04-26","objectID":"/mysql/:10:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"索引的数据结构(b树,hash) 索引的数据结构和具体存储引擎的实现有关,在mysql中使用较多的索引有Hash索引,B+树索引等,我们经常使用的InnoDB存储引擎的默认索引实现为:B+树索引。对于哈希索引来说,底层的数据结构就是哈希表,因此在绝大多数需求为单条记录查询的时候,可以选择哈希索引,查询性能最快;其余场景下,建议选择BTree索引。 ","date":"2022-04-26","objectID":"/mysql/:11:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"创建索引的原则 最左前缀匹配原则,组合索引非常重要的原则,mysql会一直向右匹配直到遇到范围查询(\u003e,\u003c,between,like)就停止匹配,比如a = 1 and b = 2 and c \u003e 3 and d = 4如果建立顺序的索引,d是用不到索引的,如果建立(a,d,b,c)的索引都可以用到,a,b,d的顺序可以任意调整。 较频繁的查询条件的字段采取创建索引 更新频繁的字段不适合创建索引 若是不能有效区分数据的列不适合做索引列(如性别,男女未知,最多三种) 尽量的扩展索引,不要新建索引。 定义有外键的数据列一定要建立索引。 对于定义为text、image和bit的数据类型的列不要建立索引。 ","date":"2022-04-26","objectID":"/mysql/:12:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"前缀索引 语法:index(field(10)),使用字段值的前10个字符建立索引,默认是使用字段的全部内容建立索引。 ","date":"2022-04-26","objectID":"/mysql/:13:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是最左前缀原则?什么是最左匹配原则 顾名思义,就是最左优先,在创建多列索引时,要根据业务需求,where子句中使用最频繁的一列放在最左边。 ","date":"2022-04-26","objectID":"/mysql/:14:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是聚簇索引?何时使用聚簇索引与非聚簇索引 聚簇索引:将数据存储与索引放到了一块,找到索引也就找到了数据 非聚簇索引:将数据存储于索引分开结构,索引结构的叶子节点指向了数据的对应行 ","date":"2022-04-26","objectID":"/mysql/:15:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"何时使用聚簇索引于非聚簇索引 ","date":"2022-04-26","objectID":"/mysql/:15:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"非聚簇索引一定会回表查询吗 不一定,如果查询语句所要求的字段全部命中了索引,就不必要回表查询。 ","date":"2022-04-26","objectID":"/mysql/:16:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是数据库事务 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 事务最经典也经常被拿出来说例子就是转账了。 假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。 ","date":"2022-04-26","objectID":"/mysql/:17:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"事务的四大特性 原子性: 事务时最小的执行单位,不允许分割。 一致性:执行事务前后,数据保持一致,多个事务对同一个数据读取的结果是相同的 隔离性:并发访问数据库时,一个用户的事务不被其他事务所干扰,各并发事务之间数据库是独立的; 持久性:一个事务被提交之后。它对数据库中数据的改变是持久的,即使数据库发生故障也不应该对其有任何的影响。 ","date":"2022-04-26","objectID":"/mysql/:18:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是脏读?幻读?不可重复读? 脏读:某个事务已更新一份数据,另一个事务在此时读取了另一份数据,由于某个原因,前一个RollBack了操作,则后一个事务所读取的数据会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询不一致,这可能是两次查询过程中插入了一个事务更新的原有的数据。 幻读:在一个事务的两次查询的列数不一致。 ","date":"2022-04-26","objectID":"/mysql/:19:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是事务的隔离级别?Mysql的默认隔离级别是什么? 为了达到事务的四大特性，数据库定义了4种不同的事务隔离级别，由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。 隔离级别 脏读 不可重复读 幻影读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 ","date":"2022-04-26","objectID":"/mysql/:20:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"对MySQL的锁了解吗 当数据库有并发事务的时候，可能会产生数据的不一致，这时候需要一些机制来保证访问的次序，锁机制就是这样的一个机制。 就像酒店的房间，如果大家随意进出，就会出现多人抢夺同一个房间的情况，而在房间上装上锁，申请到钥匙的人才可以入住并且将房间锁起来，其他人只有等他使用完毕才可以再次使用。 ","date":"2022-04-26","objectID":"/mysql/:21:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"隔离级别与锁的关系 在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突 在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁； 在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。 SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。 ","date":"2022-04-26","objectID":"/mysql/:22:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"按照锁的粒度分数据库锁有哪些?锁机制与InnoDB锁算法 在关系型数据库中，可以按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。 MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁 行级锁，表级锁和页级锁对比 行级锁 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 ","date":"2022-04-26","objectID":"/mysql/:23:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了 从锁的类别上来讲，有共享锁和排他锁。 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。 锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。 他们的加锁开销从大到小，并发能力也是从大到小。 ","date":"2022-04-26","objectID":"/mysql/:23:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"MySQL中InnoDB引擎的行锁是怎么实现的？ 答：InnoDB是基于索引来完成行锁 例: select * from tab_with_index where id = 1 for update; for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起 ","date":"2022-04-26","objectID":"/mysql/:23:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"InnoDB存储引擎的锁的算法有三种 Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 相关知识点： innodb对于行的查询使用next-key lock Next-locking keying为了解决Phantom Problem幻读问题 当查询的索引含有唯一属性时，将next-key lock降级为record key Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1 ","date":"2022-04-26","objectID":"/mysql/:23:3","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是死锁？怎么解决？ 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。 常见的解决死锁的方法 1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率； 3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率； 如果业务处理不好可以用分布式事务锁或者使用乐观锁 ","date":"2022-04-26","objectID":"/mysql/:23:4","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"数据库的乐观锁和悲观锁是什么？怎么实现的？ 数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。 两种锁的使用场景 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。 但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。 ","date":"2022-04-26","objectID":"/mysql/:23:5","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"视图 ","date":"2022-04-26","objectID":"/mysql/:24:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"为什么要使用视图？什么是视图？ 为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。所谓视图，本质上是一种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含一系列带有名称的列和行数据。但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。 视图使开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性。 ","date":"2022-04-26","objectID":"/mysql/:24:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"视图有哪些特点？ 视图的特点如下: 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。 视图是由基本表(实表)产生的表(虚表)。 视图的建立和删除不影响基本表。 对视图内容的更新(添加，删除和修改)直接影响基本表。 当视图来自多个基本表时，不允许添加和删除数据。 视图的操作包括创建视图，查看视图，删除视图和修改视图。 ","date":"2022-04-26","objectID":"/mysql/:24:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"视图的使用场景有哪些？ 视图根本用途：简化sql查询，提高开发效率。如果说还有另外一个用途那就是兼容老的表结构。 下面是视图的常见使用场景： 重用SQL语句； 简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节； 使用表的组成部分而不是整个表； 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限； 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 ","date":"2022-04-26","objectID":"/mysql/:24:3","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"视图的优点 查询简单化。视图能简化用户的操作 数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性 ","date":"2022-04-26","objectID":"/mysql/:24:4","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"视图的缺点 性能。数据库必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，即使是视图的一个简单查询，数据库也把它变成一个复杂的结合体，需要花费一定的时间。 修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的 这些视图有如下特征：1.有UNIQUE等集合操作符的视图。2.有GROUP BY子句的视图。3.有诸如AVG\\SUM\\MAX等聚合函数的视图。 4.使用DISTINCT关键字的视图。5.连接表的视图（其中有些例外） ","date":"2022-04-26","objectID":"/mysql/:24:5","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是游标？ 游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果，每个游标区都有一个名字。用户可以通过游标逐一获取记录并赋给主变量，交由主语言进一步处理。 ","date":"2022-04-26","objectID":"/mysql/:24:6","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"存储过程与函数 ","date":"2022-04-26","objectID":"/mysql/:25:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是存储过程？有哪些优缺点？ 存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需要创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。 优点 1）存储过程是预编译过的，执行效率高。 2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。 3）安全性高，执行存储过程需要有一定权限的用户。 4）存储过程可以重复使用，减少数据库开发人员的工作量。 缺点 1）调试麻烦，但是用 PL/SQL Developer 调试很方便！弥补这个缺点。 2）移植问题，数据库端代码当然是与数据库相关的。但是如果是做工程型项目，基本不存在移植问题。 3）重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、包将需要重新编译（不过也可以设置成运行时刻自动编译）。 4）如果在一个程序系统中大量的使用存储过程，到程序交付使用的时候随着用户需求的增加会导致数据结构的变化，接着就是系统的相关问题了，最后如果用户想维护该系统可以说是很难很难、而且代价是空前的，维护起来更麻烦。 ","date":"2022-04-26","objectID":"/mysql/:25:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"触发器 ","date":"2022-04-26","objectID":"/mysql/:26:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是触发器？触发器的使用场景有哪些？ 触发器是用户定义在关系表上的一类由事件驱动的特殊的存储过程。触发器是指一段代码，当触发某个事件时，自动执行这些代码。 使用场景 可以通过数据库中的相关表实现级联更改。 实时监控某张表中的某个字段的更改而需要做出相应的处理。 例如可以生成某些业务的编号。 注意不要滥用，否则会造成数据库及应用程序的维护困难。 大家需要牢记以上基础知识点，重点是理解数据类型CHAR和VARCHAR的差异，表存储引擎InnoDB和MyISAM的区别。 ","date":"2022-04-26","objectID":"/mysql/:26:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"MySQL中都有哪些触发器？ 在MySQL数据库中有如下六种触发器： Before Insert After Insert Before Update After Update Before Delete After Delete ","date":"2022-04-26","objectID":"/mysql/:26:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"常用SQL语句 ","date":"2022-04-26","objectID":"/mysql/:27:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"SQL语句主要分为哪几类 数据定义语言DDL（Data Ddefinition Language）CREATE，DROP，ALTER 主要为以上操作 即对逻辑结构等有操作的，其中包括表结构，视图和索引。 数据查询语言DQL（Data Query Language）SELECT 这个较为好理解 即查询操作，以select关键字。各种简单查询，连接查询等 都属于DQL。 数据操纵语言DML（Data Manipulation Language）INSERT，UPDATE，DELETE 主要为以上操作 即对数据进行操作的，对应上面所说的查询操作 DQL与DML共同构建了多数初级程序员常用的增删改查操作。而查询是较为特殊的一种 被划分到DQL中。 数据控制功能DCL（Data Control Language）GRANT，REVOKE，COMMIT，ROLLBACK 主要为以上操作 即对数据库安全性完整性等有操作的，可以简单的理解为权限控制等。 ","date":"2022-04-26","objectID":"/mysql/:27:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"超键、候选键、主键、外键分别是什么？ 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。 候选键：是最小超键，即没有冗余元素的超键。 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。 外键：在一个表中存在的另一个表的主键称此表的外键。 ","date":"2022-04-26","objectID":"/mysql/:27:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"SQL 约束有哪几种？ SQL 约束有哪几种？ NOT NULL: 用于控制字段的内容一定不能为空（NULL）。 UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。 PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。 FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 CHECK: 用于控制字段的值范围。 ","date":"2022-04-26","objectID":"/mysql/:27:3","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"六种关联查询 交叉连接（CROSS JOIN） 内连接（INNER JOIN） 外连接（LEFT JOIN/RIGHT JOIN） 联合查询（UNION与UNION ALL） 全连接（FULL JOIN） 交叉连接（CROSS JOIN） SELECT * FROM A,B(,C)或者SELECT * FROM A CROSS JOIN B (CROSS JOIN C)#没有任何关联条件，结果是笛卡尔积，结果集会很大，没有意义，很少使用内连接（INNER JOIN）SELECT * FROM A,B WHERE A.id=B.id或者SELECT * FROM A INNER JOIN B ON A.id=B.id多表中同时符合某种条件的数据记录的集合，INNER JOIN可以缩写为JOIN 1 内连接分为三类 等值连接：ON A.id=B.id 不等值连接：ON A.id \u003e B.id 自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid 外连接（LEFT JOIN/RIGHT JOIN） 左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照ON后的关联条件匹配右表，没有匹配到的用NULL填充，可以简写成LEFT JOIN 右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照ON后的关联条件匹配左表，没有匹配到的用NULL填充，可以简写成RIGHT JOIN 联合查询（UNION与UNION ALL） SELECT * FROM A UNION SELECT * FROM B UNION ... 1 就是把多个结果集集中在一起，UNION前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并 如果使用UNION ALL，不会合并重复的记录行 效率 UNION 高于 UNION ALL 全连接（FULL JOIN） MySQL不支持全连接 可以使用LEFT JOIN 和UNION和RIGHT JOIN联合使用 SELECT * FROM A LEFT JOIN B ON A.id=B.id UNIONSELECT * FROM A RIGHT JOIN B ON A.id=B.id 1 表连接面试题 有2张表，1张R、1张S，R表有ABC三列，S表有CD两列，表中各有三条记录。 R表 A B C a1 b1 c1 a2 b2 c2 a3 b3 c3 S表 C D c1 d1 c2 d2 c4 d3 交叉连接(笛卡尔积): select r.*,s.* from r,s A B C C D a1 b1 c1 c1 d1 a2 b2 c2 c1 d1 a3 b3 c3 c1 d1 a1 b1 c1 c2 d2 a2 b2 c2 c2 d2 a3 b3 c3 c2 d2 a1 b1 c1 c4 d3 a2 b2 c2 c4 d3 a3 b3 c3 c4 d3 内连接结果： select r.*,s.* from r inner join s on r.c=s.c A B C C D a1 b1 c1 c1 d1 a2 b2 c2 c2 d2 左连接结果： select r.*,s.* from r left join s on r.c=s.c A B C C D a1 b1 c1 c1 d1 a2 b2 c2 c2 d2 a3 b3 c3 右连接结果： select r.*,s.* from r right join s on r.c=s.c A B C C D a1 b1 c1 c1 d1 a2 b2 c2 c2 d2 c4 d3 全表连接的结果（MySql不支持，Oracle支持）： select r.*,s.* from r full join s on r.c=s.c A B C C D a1 b1 c1 c1 d1 a2 b2 c2 c2 d2 a3 b3 c3 c4 d3 ","date":"2022-04-26","objectID":"/mysql/:27:4","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"什么是子查询 条件：一条SQL语句的查询结果做为另一条查询语句的条件或查询结果 嵌套：多条SQL语句嵌套使用，内部的SQL查询语句称为子查询。 ","date":"2022-04-26","objectID":"/mysql/:27:5","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"子查询的三种情况 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 \u003c、 \u003e 等运算符 -- 查询工资最高的员工是谁？ select*fromemployeewheresalary=(selectmax(salary)fromemployee);12 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符 -- 查询工资最高的员工是谁？ select*fromemployeewheresalary=(selectmax(salary)fromemployee);12 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于where条件，用于select子句中做为子表 -- 1) 查询出2011年以后入职的员工信息 -- 2) 查询所有的部门信息，与上面的虚拟表中的信息比对，找出所有部门ID相等的员工。 select*fromdeptd,(select*fromemployeewherejoin_date\u003e'2011-1-1')ewheree.dept_id=d.id;-- 使用表连接： selectd.*,e.*fromdeptdinnerjoinemployeeeond.id=e.dept_idwheree.join_date\u003e'2011-1-1'123456 ","date":"2022-04-26","objectID":"/mysql/:27:6","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql中 in 和 exists 区别 mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。 如果查询的两个表大小相当，那么用in和exists差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。 not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。 ","date":"2022-04-26","objectID":"/mysql/:27:7","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"varchar与char的区别 char的特点 char表示定长字符串，长度是固定的； 如果插入数据的长度小于char的固定长度时，则用空格填充； 因为长度固定，所以存取速度要比varchar快很多，甚至能快50%，但正因为其长度固定，所以会占据多余的空间，是空间换时间的做法； 对于char来说，最多能存放的字符个数为255，和编码无关 varchar的特点 varchar表示可变长字符串，长度是可变的； 插入的数据是多长，就按照多长来存储； varchar在存取方面与char相反，它存取慢，因为长度不固定，但正因如此，不占据多余的空间，是时间换空间的做法； 对于varchar来说，最多能存放的字符个数为65532 总之，结合性能角度（char更快）和节省磁盘空间角度（varchar更小），具体情况还需具体来设计数据库才是妥当的做法。 ","date":"2022-04-26","objectID":"/mysql/:27:8","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"varchar(50)中50的涵义 最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。 ","date":"2022-04-26","objectID":"/mysql/:27:9","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"int(20)中20的涵义 是指显示字符的长度。20表示最大显示宽度为20，但仍占4字节存储，存储范围不变； 不影响内部存储，只是影响带 zerofill 定义的 int 时，前面补多少个 0，易于报表展示 ","date":"2022-04-26","objectID":"/mysql/:27:10","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql为什么这么设计 对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样； ","date":"2022-04-26","objectID":"/mysql/:27:11","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql中int(10)和char(10)以及varchar(10)的区别 int(10)的10表示显示的数据的长度，不是存储数据的大小；chart(10)和varchar(10)的10表示存储数据的大小，即表示存储多少个字符。 int(10) 10位的数据长度 9999999999，占32个字节，int型4位 char(10) 10位固定字符串，不足补空格 最多10个字符 varchar(10) 10位可变字符串，不足补空格 最多10个字符 char(10)表示存储定长的10个字符，不足10个就用空格补齐，占用更多的存储空间 varchar(10)表示存储10个变长的字符，存储多少个就是多少个，空格也按一个字符存储，这一点是和char(10)的空格不同的，char(10)的空格表示占位不算一个字符 ","date":"2022-04-26","objectID":"/mysql/:27:12","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"FLOAT和DOUBLE的区别是什么？ FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。 DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。 ","date":"2022-04-26","objectID":"/mysql/:27:13","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"drop、delete与truncate的区别 三者都表示删除，但是三者有一些差别： Delete Truncate Drop 类型 属于DML 属于DDL 属于DDL 回滚 可回滚 不可回滚 不可回滚 删除内容 表结构还在，删除表的全部或者一部分数据行 表结构还在，删除表中的所有数据 从数据库中删除表，所有的数据行，索引和权限也会被删除 删除速度 删除速度慢，需要逐行删除 删除速度快 删除速度最快 因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。 ","date":"2022-04-26","objectID":"/mysql/:27:14","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"UNION与UNION ALL的区别？ 如果使用UNION ALL，不会合并重复的记录行 效率 UNION 高于 UNION ALL ","date":"2022-04-26","objectID":"/mysql/:27:15","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"SQL优化 ","date":"2022-04-26","objectID":"/mysql/:28:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因？ 对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了explain命令来查看语句的执行计划。 我们知道，不管是哪种数据库，或者是哪种数据库引擎，在对一条SQL语句进行执行的过程中都会做很多相关的优化，对于查询语句，最重要的优化方式就是使用索引。 而执行计划，就是显示数据库引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，使用的索引的相关信息等。 执行计划包含的信息 id 有一组数字组成。表示一个查询中各个子查询的执行顺序; id相同执行顺序由上至下。 id不同，id值越大优先级越高，越先被执行。 id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。 select_type 每个子查询的查询类型，一些常见的查询类型。 id select_type description 1 SIMPLE 不包含任何子查询或union等查询 2 PRIMARY 包含子查询最外层查询就显示为 PRIMARY 3 SUBQUERY 在select或 where字句中包含的查询 4 DERIVED from字句中包含的查询 5 UNION 出现在union后的查询语句中 6 UNION RESULT 从UNION中获取结果集，例如上文的第三个例子 table 查询的数据表，当从衍生表中查数据时会显示 x 表示对应的执行计划id partitions 表分区、表创建的时候可以指定通过那个列进行表分区。 举个例子： createtabletmp(idintunsignednotnullAUTO_INCREMENT,namevarchar(255),PRIMARYKEY(id))engine=innodbpartitionbykey(id)partitions5;123456 type(非常重要，可以看到有没有走索引) 访问类型 ALL 扫描全表数据 index 遍历索引 range 索引范围查找 index_subquery 在子查询中使用 ref unique_subquery 在子查询中使用 eq_ref ref_or_null 对Null进行索引的优化的 ref fulltext 使用全文索引 ref 使用非唯一索引查找数据 eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。 possible_keys 可能使用的索引，注意不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为 NULL时就要考虑当前的SQL是否需要优化了。 key 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。 TIPS:查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中 key_length 索引长度 ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows 返回估算的结果集数目，并不是一个准确的值。 extra 的信息非常丰富，常见的有： Using index 使用覆盖索引 Using where 使用了用where子句来过滤结果集 Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。 Using temporary 使用了临时表 sql优化的目标可以参考阿里开发手册 【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。 说明： 1） consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 2） ref 指的是使用普通的索引（normal index）。 3） range 对索引进行范围检索。 反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫。 123456 ","date":"2022-04-26","objectID":"/mysql/:28:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"SQL的生命周期？ 应用服务器与数据库服务器建立一个连接 数据库进程拿到请求sql 解析并生成执行计划，执行 读取数据到内存并进行逻辑处理 通过步骤一的连接，发送结果到客户端 关掉连接，释放资源 ","date":"2022-04-26","objectID":"/mysql/:28:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"大表数据查询，怎么优化 优化shema、sql语句+索引； 第二加缓存，memcached, redis； 主从复制，读写分离； 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统； 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表； ","date":"2022-04-26","objectID":"/mysql/:28:3","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"超大分页怎么处理？ 超大的分页一般从两个方向上来解决. 数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select * from table where age \u003e 20 limit 1000000,10这种查询其实也是有可以优化的余地的. 这条语句需要load1000000数据然后基本上全部丢弃,只取10条当然比较慢. 当时我们可以修改为select * from table where id in (select id from table where age \u003e 20 limit 1000000,10).这样虽然也load了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快. 同时如果ID连续的好,我们还可以select * from table where id \u003e 1000000 limit 10,效率也是不错的,优化的可能性有许多种,但是核心思想都一样,就是减少load的数据. 从需求的角度减少这种请求…主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或者按照给定的路线走,这样可预测,可缓存)以及防止ID泄漏且连续被人恶意攻击. 解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可. 在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种. 【推荐】利用延迟关联或者子查询优化超多分页场景。说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。正例：先快速定位需要获取的id段，然后再关联：SELECTa.*FROM表1a,(selectidfrom表1where条件LIMIT100000,20)bwherea.id=b.id1234567 ","date":"2022-04-26","objectID":"/mysql/:28:4","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"mysql 分页 LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1) mysql\u003e SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15 1 为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为 -1： mysql\u003e SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last. 1 如果只给定一个参数，它表示返回最大的记录行数目： mysql\u003e SELECT * FROM table LIMIT 5; //检索前 5 个记录行 1 换句话说，LIMIT n 等价于 LIMIT 0,n。 ","date":"2022-04-26","objectID":"/mysql/:28:5","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"慢查询日志 用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。 开启慢查询日志 配置项：slow_query_log 可以使用show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF，可以使用set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。 设置临界时间 配置项：long_query_time 查看：show VARIABLES like 'long_query_time'，单位秒 设置：set long_query_time=0.5 实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉 查看日志，一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中 ","date":"2022-04-26","objectID":"/mysql/:28:6","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？ 在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。 慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？ 所以优化也是针对这三个方向来的， 首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。 分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。 ","date":"2022-04-26","objectID":"/mysql/:28:7","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"为什么要尽量设定一个主键？ 主键是数据库确保数据行在整张表唯一性的保障，即使业务上本张表没有主键，也建议添加一个自增长的ID列作为主键。设定了主键之后，在后续的删改查的时候可能更加快速以及确保操作数据范围安全。 ","date":"2022-04-26","objectID":"/mysql/:28:8","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"主键使用自增ID还是UUID？ 推荐使用自增ID，不要使用UUID。 因为在InnoDB存储引擎中，主键索引是作为聚簇索引存在的，也就是说，主键索引的B+树叶子节点上存储了主键索引以及全部的数据(按照顺序)，如果主键索引是自增ID，那么只需要不断向后排列即可，如果是UUID，由于到来的ID与原来的大小不确定，会造成非常多的数据插入，数据移动，然后导致产生很多的内存碎片，进而造成插入性能的下降。 总之，在数据量大一些的情况下，用自增主键性能会好一些。 关于主键是聚簇索引，如果没有主键，InnoDB会选择一个唯一键来作为聚簇索引，如果没有唯一键，会生成一个隐式的主键。 ","date":"2022-04-26","objectID":"/mysql/:28:9","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"字段为什么要求定义为not null？ null值会占用更多的字节，且会在程序中造成很多与预期不符的情况。 ","date":"2022-04-26","objectID":"/mysql/:28:10","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"如果要存储用户的密码散列，应该使用什么字段进行存储？ 密码散列，盐，用户身份证号等固定长度的字符串应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。 ","date":"2022-04-26","objectID":"/mysql/:28:11","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化查询过程中的数据访问 访问数据太多导致查询性能下降 确定应用程序是否在检索大量超过需要的数据，可能是太多行或列 确认MySQL服务器是否在分析大量不必要的数据行 避免犯如下SQL语句错误 查询不需要的数据。解决办法：使用limit解决 多表关联返回全部列。解决办法：指定列名 总是返回全部列。解决办法：避免使用SELECT * 重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存 是否在扫描额外的记录。解决办法： 使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。 改变数据库和表的结构，修改数据表范式 重写SQL语句，让优化器可以以更优的方式执行查询。 ","date":"2022-04-26","objectID":"/mysql/:28:12","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化长难的查询语句 一个复杂查询还是多个简单查询 MySQL内部每秒能扫描内存中上百万行数据，相比之下，响应数据给客户端就要慢得多 使用尽可能小的查询是好的，但是有时将一个大的查询分解为多个小的查询是很有必要的。 切分查询 将一个大的查询分为多个小的相同的查询 一次性删除1000万的数据要比一次删除1万，暂停一会的方案更加损耗服务器开销。 分解关联查询，让缓存的效率更高。 执行单个查询可以减少锁的竞争。 在应用层做关联更容易对数据库进行拆分。 查询效率会有大幅提升。 较少冗余记录的查询。 ","date":"2022-04-26","objectID":"/mysql/:28:13","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化特定类型的查询语句 count(*)会忽略所有的列，直接统计所有列数，不要使用count(列名) MyISAM中，没有任何where条件的count(*)非常快。 当有where条件时，MyISAM的count统计不一定比其它引擎快。 可以使用explain查询近似值，用近似值替代count(*) 增加汇总表 使用缓存 ","date":"2022-04-26","objectID":"/mysql/:28:14","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化关联查询 确定ON或者USING子句中是否有索引。 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。 ","date":"2022-04-26","objectID":"/mysql/:28:15","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化子查询 用关联查询替代 优化GROUP BY和DISTINCT 这两种查询据可以使用索引来优化，是最有效的优化方法 关联查询中，使用标识列分组的效率更高 如果不需要ORDER BY，进行GROUP BY时加ORDER BY NULL，MySQL不会再进行文件排序。 WITH ROLLUP超级聚合，可以挪到应用程序处理 ","date":"2022-04-26","objectID":"/mysql/:28:16","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化LIMIT分页 LIMIT偏移量大的时候，查询效率较低 可以记录上次查询的最大ID，下次查询时直接根据该ID来查询 ","date":"2022-04-26","objectID":"/mysql/:28:17","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化UNION查询 UNION ALL的效率高于UNION ","date":"2022-04-26","objectID":"/mysql/:28:18","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"优化WHERE子句 解题方法 对于此类考题，先说明如何定位低效SQL语句，然后根据SQL语句可能低效的原因做排查，先从索引着手，如果索引没有问题，考虑以上几个方面，数据访问的问题，长难查询句的问题还是一些特定类型优化的问题，逐一回答。 SQL语句优化的一些方法？ 1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： selectidfromtwherenumisnull-- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： selectidfromtwherenum=123 3.应尽量避免在 where 子句中使用!=或\u003c\u003e操作符，否则引擎将放弃使用索引而进行全表扫描。 4.应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： selectidfromtwherenum=10ornum=20-- 可以这样查询： selectidfromtwherenum=10unionallselectidfromtwherenum=20123 5.in 和 not in 也要慎用，否则会导致全表扫描，如： selectidfromtwherenumin(1,2,3)-- 对于连续的数值，能用 between 就不要用 in 了： selectidfromtwherenumbetween1and3123 6.下面的查询也将导致全表扫描：select id from t where name like ‘%李%’若要提高效率，可以考虑全文检索。 7.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： selectidfromtwherenum=@num-- 可以改为强制查询使用索引： selectidfromtwith(index(索引名))wherenum=@num123 8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： selectidfromtwherenum/2=100-- 应改为: selectidfromtwherenum=100*2123 9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： selectidfromtwheresubstring(name,1,3)=’abc’-- name以abc开头的id应改为: selectidfromtwherenamelike‘abc%’123 10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 ","date":"2022-04-26","objectID":"/mysql/:28:19","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"数据库优化 ","date":"2022-04-26","objectID":"/mysql/:29:0","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"为什么要优化 系统的吞吐量瓶颈往往出现在数据库的访问速度上 随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢 数据是存放在磁盘上的，读写速度无法和内存相比 优化原则：减少系统瓶颈，减少资源占用，增加系统的反应速度。 ","date":"2022-04-26","objectID":"/mysql/:29:1","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"数据库结构优化 一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。 需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。 将字段很多的表分解成多个表 对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。 因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 增加中间表 对于需要经常联合查询的表，可以建立中间表以提高查询效率。 通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。 增加冗余字段 设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。 表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。 注意： 冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。 ","date":"2022-04-26","objectID":"/mysql/:29:2","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"MySQL数据库cpu飙升到500%的话他怎么处理？ 当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的，如果不是，找出占用高的进程，并进行相关处理。 如果是 mysqld 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。 也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等 ","date":"2022-04-26","objectID":"/mysql/:29:3","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？ 当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下： 限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。； 读/写分离： 经典的数据库拆分方案，主库负责写，从库负责读； 缓存： 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存； 还有就是通过分库分表的方式进行优化，主要有垂直分表和水平分表 垂直分区： 根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 如下图所示，这样来说大家应该就更容易理解了。 垂直拆分的优点： 可以使得行数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂； 垂直分表 把主键和一些列放在一个表，然后把主键和另外的列放在另一个表中 适用场景 1、如果一个表中某些列常用，另外一些列不常用 2、可以使数据行变小，一个数据页能存储更多数据，查询时减少I/O次数 缺点 有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变，整个分表逻辑都会改变，扩展性较差 对于应用层来说，逻辑算法增加开发成本 管理冗余列，查询所有数据需要join操作 水平分区： 保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 水品拆分可以支持非常大的数据量。需要注意的一点是:分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。 水平拆分能够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨界点Join性能较差，逻辑复杂。 《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。 水平分表： 表很大，分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询次数 适用场景 1、表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。 2、需要把数据存放在多个介质上。 水平切分的缺点 1、给应用增加复杂度，通常查询时需要多个表名，查询所有数据都需UNION操作 2、在许多数据库应用中，这种复杂度会超过它带来的优点，查询时会增加读一个索引层的磁盘次数 下面补充一下数据库分片的两种常见方案： 客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 当当网的 Sharding-JDBC 、阿里的TDDL是两种比较常用的实现。 中间件代理： 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360的Atlas、网易的DDB等等都是这种架构的实现。 分库分表后面临的问题 事务支持 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。 跨库join 只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。 分库分表方案产品 跨节点的count,order by,group by以及聚合函数问题 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 数据迁移，容量规划，扩容等问题 来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 ID问题 一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由. 一些常见的主键生成策略 UUID 使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 Twitter的分布式自增ID算法Snowflake 在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。 跨分片的排序分页 般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示： ","date":"2022-04-26","objectID":"/mysql/:29:4","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"MySQL的复制原理以及流程 主从复制：将主数据库中的DDL和DML操作通过二进制日志（BINLOG）传输到从数据库上，然后将这些日志重新执行（重做）；从而使得从数据库的数据与主数据库保持一致。 主从复制的作用 主数据库出现问题，可以切换到从数据库。 可以进行数据库层面的读写分离。 可以在从数据库上进行日常备份。 MySQL主从复制解决的问题 数据分布：随意开始或停止复制，并在不同地理位置分布数据备份 负载均衡：降低单个服务器的压力 高可用和故障切换：帮助应用程序避免单点失败 升级测试：可以用更高版本的MySQL作为从库 MySQL主从复制工作原理 在主库上把数据更高记录到二进制日志 从库将主库的日志复制到自己的中继日志 从库读取中继日志的事件，将其重放到从库数据中 基本原理流程，3个线程以及之间的关联 主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中； 从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中； 从：sql执行线程——执行relay log中的语句； 复制过程 Binary log：主数据库的二进制日志 Relay log：从服务器的中继日志 第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。 第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。 第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。 ","date":"2022-04-26","objectID":"/mysql/:29:5","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"读写分离有哪些解决方案？ 读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。 方案一 使用mysql-proxy代理 优点：直接实现读写分离和负载均衡，不用修改代码，master和slave用一样的帐号，mysql官方不建议实际生产中使用 缺点：降低性能， 不支持事务 方案二 使用AbstractRoutingDataSource+aop+annotation在dao层决定数据源。 如果采用了mybatis， 可以将读写分离放在ORM层，比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。 plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。 方案三 使用AbstractRoutingDataSource+aop+annotation在service层决定数据源，可以支持事务. 缺点：类内部方法通过this.xx()方式相互调用时，aop不会进行拦截，需进行特殊处理。 ","date":"2022-04-26","objectID":"/mysql/:29:6","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"备份计划，mysqldump以及xtranbackup的实现原理 (1)备份计划 视库的大小来定，一般来说 100G 内的库，可以考虑使用 mysqldump 来做，因为 mysqldump更加轻巧灵活，备份时间选在业务低峰期，可以每天进行都进行全量备份(mysqldump 备份出来的文件比较小，压缩之后更小)。 100G 以上的库，可以考虑用 xtranbackup 来做，备份速度明显要比 mysqldump 要快。一般是选择一周一个全备，其余每天进行增量备份，备份时间为业务低峰期。 (2)备份恢复时间 物理备份恢复快，逻辑备份恢复慢 这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考 20G的2分钟（mysqldump） 80G的30分钟(mysqldump) 111G的30分钟（mysqldump) 288G的3小时（xtra) 3T的4小时（xtra) 逻辑导入时间一般是备份时间的5倍以上 (3)备份恢复失败如何处理 首先在恢复之前就应该做足准备工作，避免恢复的时候出错。比如说备份之后的有效性检查、权限检查、空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。 (4)mysqldump和xtrabackup实现原理 mysqldump mysqldump 属于逻辑备份。加入–single-transaction 选项可以进行一致性备份。后台进程会先设置 session 的事务隔离级别为 RR(SET SESSION TRANSACTION ISOLATION LEVELREPEATABLE READ)，之后显式开启一个事务(START TRANSACTION /*!40100 WITH CONSISTENTSNAPSHOT */)，这样就保证了该事务里读到的数据都是事务事务时候的快照。之后再把表的数据读取出来。如果加上–master-data=1 的话，在刚开始的时候还会加一个数据库的读锁(FLUSH TABLES WITH READ LOCK),等开启事务后，再记录下数据库此时 binlog 的位置(showmaster status)，马上解锁，再读取表的数据。等所有的数据都已经导完，就可以结束事务 Xtrabackup: xtrabackup 属于物理备份，直接拷贝表空间文件，同时不断扫描产生的 redo 日志并保存下来。最后完成 innodb 的备份后，会做一个 flush engine logs 的操作(老版本在有 bug，在5.6 上不做此操作会丢数据)，确保所有的 redo log 都已经落盘(涉及到事务的两阶段提交 概念，因为 xtrabackup 并不拷贝 binlog，所以必须保证所有的 redo log 都落盘，否则可能会丢最后一组提交事务的数据)。这个时间点就是 innodb 完成备份的时间点，数据文件虽然不是一致性的，但是有这段时间的 redo 就可以让数据文件达到一致性(恢复的时候做的事 情)。然后还需要 flush tables with read lock，把 myisam 等其他引擎的表给备份出来，备份完后解锁。这样就做到了完美的热备。 ","date":"2022-04-26","objectID":"/mysql/:29:7","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"数据表损坏的修复方式有哪些？ 使用 myisamchk 来修复，具体步骤： 1）修复前将mysql服务停止。 2）打开命令行方式，然后进入到mysql的/bin目录。 3）执行myisamchk –recover 数据库所在路径/*.MYI 使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库） InnoDB和MyISAM的最大不同点有两个：一，InnoDB支持事务(transaction)；二，默认采用行级锁。加锁可以保证事务的一致性，可谓是有人(锁)的地方，就有江湖(事务) mysql 行锁 行锁的劣势：开销大；加锁慢；会出现死锁 行锁的优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强 加锁的方式：自动加锁。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；对于普通SELECT语句，InnoDB不会加任何锁；当然我们也可以显示的加锁： 共享锁：select * from tableName where … + lock in share more 排他锁：select * from tableName where … + for update ","date":"2022-04-26","objectID":"/mysql/:29:8","tags":null,"title":"Mysql","uri":"/mysql/"},{"categories":null,"content":"Golang精编100题 能力模型 级别 模型 初级 primary: 熟悉基本语法，能够看懂代码的意图； 在他人指导下能够完成用户故事的开发，编写的代码符合CleanCode规范； 中级 intermediate: 能够独立完成用户故事的开发和测试； 能够嗅出代码的坏味道，并知道如何重构达成目标； 高级 senior: 能够开发出高质量高性能的代码； 能够熟练使用高级特性，开发编程框架或测试框架； ","date":"2022-04-20","objectID":"/100%E9%A2%98/:0:0","tags":null,"title":"100题","uri":"/100%E9%A2%98/"},{"categories":null,"content":"选择题 1. 【初级】下面属于关键字的是（） A. func B. def C. struct D. class 参考答案：AC 2. 【初级】定义一个包内全局字符串变量，下面语法正确的是（） A. var str string B. str := \"\" C. str = \"\" D. var str = \"\" 参考答案：AD 【初级】通过指针变量 p 访问其成员变量 name，下面语法正确的是（） A. p.name B. (*p).name C. (\u0026p).name D. p-\u003ename 参考答案：AB 4. 【初级】关于接口和类的说法，下面说法正确的是（） A. 一个类只需要实现了接口要求的所有函数，我们就说这个类实现了该接口 B. 实现类的时候，只需要关心自己应该提供哪些方法，不用再纠结接口需要拆得多细才合理 C. 类实现接口时，需要导入接口所在的包 D. 接口由使用方按自身需求来定义，使用方无需关心是否有其他模块定义过类似的接口 参考答案：ABD 5. 【初级】关于字符串连接，下面语法正确的是（） A. str := ‘abc’ + ‘123’ B. str := \"abc\" + \"123\" C. str ：= '123' + \"abc\" D. fmt.Sprintf(\"abc%d\", 123) 参考答案：BD 【初级】关于协程，下面说法正确是（） A. 协程和线程都可以实现程序的并发执行 B. 线程比协程更轻量级 C. 协程不存在死锁问题 D. 通过channel来进行协程间的通信 参考答案：AD 【中级】关于init函数，下面说法正确的是（） A. 一个包中，可以包含多个init函数 B. 程序编译时，先执行导入包的init函数，再执行本包内的init函数 C. main包中，不能有init函数 D. init函数可以被其他函数调用 参考答案：AB 【初级】关于循环语句，下面说法正确的有（） A. 循环语句既支持for关键字，也支持while和do-while B. 关键字for的基本使用方法与C/C++中没有任何差异 C. for循环支持continue和break来控制循环，但是它提供了一个更高级的break，可以选择中断哪一个循环 D. for循环不支持以逗号为间隔的多个赋值语句，必须使用平行赋值的方式来初始化多个变量 参考答案：CD 【中级】对于函数定义： func add(args …int) int { sum :=0 for _,arg := range args {undefined sum += arg } returnsum } 下面对add函数调用正确的是（） A. add(1, 2) B. add(1, 3, 7) C. add([]int{1, 2}) D. add([]int{1, 3, 7}…) 参考答案：ABD 【初级】关于类型转化，下面语法正确的是（） A. type MyInt int var i int = 1 var jMyInt = i B. type MyIntint var i int= 1 var jMyInt = (MyInt)i C. type MyIntint var i int= 1 var jMyInt = MyInt(i) D. type MyIntint var i int= 1 var jMyInt = i.(MyInt) 参考答案：C 【初级】关于局部变量的初始化，下面正确的使用方式是（） A. var i int = 10 B. var i = 10 C. i := 10 D. i = 10 参考答案：ABC 【初级】关于const常量定义，下面正确的使用方式是（） A. const Pi float64 = 3.14159265358979323846 const zero= 0.0 B. const ( size int64= 1024 eof = -1 ) C. const ( ERR_ELEM_EXISTerror = errors.New(“element already exists”) ERR_ELEM_NT_EXISTerror = errors.New(“element not exists”) ) D. const u, vfloat32 = 0, 3 const a,b, c = 3, 4, “foo” 参考答案：ABD 【初级】关于布尔变量b的赋值，下面错误的用法是（） A. b = true B. b = 1 C. b = bool(1) D. b = (1 == 2) 参考答案：BC 【中级】下面的程序的运行结果是（） func main() { if (true) { defer fmt.Printf(“1”) } else { defer fmt.Printf(“2”) } fmt.Printf(“3”) } A. 321 B. 32 C. 31 D. 13 参考答案：C 【初级】关于switch语句，下面说法正确的有（） A. 条件表达式必须为常量或者整数 B. 单个case中，可以出现多个结果选项 C. 需要用break来明确退出一个case D. 只有在case中明确添加fallthrough关键字，才会继续执行紧跟的下一个case 参考答案：BD 【中级】 golang中没有隐藏的this指针，这句话的含义是（） A. 方法施加的对象显式传递，没有被隐藏起来 B. golang沿袭了传统面向对象编程中的诸多概念，比如继承、虚函数和构造函数 C. golang的面向对象表达更直观，对于面向过程只是换了一种语法形式来表达 D. 方法施加的对象不需要非得是指针，也不用非得叫this 参考答案：ACD 【中级】 golang中的引用类型包括（） A. 数组切片 B. map C. channel D. interface 参考答案：ABCD 【中级】 golang中的指针运算包括（） A. 可以对指针进行自增或自减运算 B. 可以通过“\u0026”取指针的地址 C. 可以通过“*”取指针指向的数据 D. 可以对指针进行下标运算 参考答案：BC 【初级】关于main函数（可执行程序的执行起点），下面说法正确的是（） A. main函数不能带参数 B. main函数不能定义返回值 C. main函数所在的包必须为main包 D. main函数中可以使用flag包来获取和解析命令行参数 参考答案：ABCD 【中级】下面赋值正确的是（） A. var x = nil B. var x interface{} = nil C. var x string = nil D. var x error = nil 参考答案：BD 【中级】关于整型切片的初始化，下面正确的是（） A. s := make([]int) B. s := make([]int, 0) C. s := make([]int, 5, 10) D. s := []int{1, 2, 3, 4, 5} 参考答案：BCD 【中级】从切片中删除一个元素，下面的算法实现正确的是（） A. func (s *Slice)Remove(value interface{})error { for i, v := range *s { if isEqual(value, v) {undefined if i== len(*s) - 1 {undefined *s = (*s)[:i] }else {undefined *s = append((*s)[:i],(*s)[i + 2:]...) } return nil } } return ERR_ELEM_NT_EXIST } B. func (s*Slice)Remove(value interface{}) error { for i, v:= range *s { if isEqual(value, v) {undefined *s =append((*s)[:i],(*s)[i + 1:]) return nil } } returnERR_ELEM_NT_EXIST } C. func (s*Slice)Remove(value interface{}) error { for i, v:= range *s { if isEqual(value, v) {undefined delete(*s, v) return nil } } returnERR_ELEM_NT_EXIST } D. func (s*Slice)Remove(value interface{}) error { for i, v:= range *s { if isEqual(value, v) {undefined *s =append((*s)[:i],(*s)[i + 1:]...) return nil } } returnERR_ELEM_NT_EXIST } 参考答案：D 【初级】对于局部变量整型切片x的赋值，下面定义正确的是（） A. x := []int{ 1, 2, 3, 4, 5, 6, } B. x :=[]int{ 1, 2, 3, 4, 5, 6 } C. x :=[]int{ 1, 2, 3, 4, 5, 6} D. x :=[]int{1, 2, 3, 4, 5, 6,} 参考答案：ACD 【初级】关于变量的自增和自减操作，下面语句正确的是（） A. i := 1 i++ B. i := 1 j = i++ C. i := 1 ++i D. i ","date":"2022-04-20","objectID":"/100%E9%A2%98/:1:0","tags":null,"title":"100题","uri":"/100%E9%A2%98/"},{"categories":null,"content":"GMP模型 ","date":"2022-04-12","objectID":"/gmp/:0:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"M M代表内核级线程,一个M就是一个线程,goroutine就是跑在M之上的;M是一个很大的结构,里面维护了小对象内存cache、当前执行的goroutine、随机数发生器 等等。M的PC寄存器存储着指向G的函数。 type m struct { g0 *g // 带有调度栈的goroutine gsignal *g // 处理信号的goroutine tls [6]uintptr mstartfn func() curg *g //当前运行的goroutine caughtsig guintptr p puintptr //关联p和执行的go代码 nextp puintptr id int32 mallocing int32 // 状态 spinning bool // m是否out of work blocked bool // m是否被阻塞 inwb bool // m是否在执行写屏蔽 printlock int8 incgo bool //m在执行cgo吗 fastrand uint32 ncgocall uint64 // cgo调用的总数 ncgo int32 // 当前cgo调用的数目 park note alllink *m // 用于链接allm schedlink muintptr mcache *mcache // 当前m的内存缓存 lockedg *g // 锁定g在当前m上执行，而不会切换到其他m createstack [32]uintptr // thread创建的栈 } ","date":"2022-04-12","objectID":"/gmp/:1:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"G G代表一个goroutine,它有一个自己的栈,instrtuction pointer和其他的信息(正在等待的channel等等),用于调度。 type g struct { stack stack //描述了真实的内存,包括上下界 m *m // 当前的m sced gobuf // goroutine切换时,用于保存g的上下文 param unsafe.Pointer // 用于传递参数, 睡眠时其他goroutine可以设置param, 唤醒时该goroutine可以获取 atomicstatus uint32 stackLock uint32 goid int64 //goroutine的ID waitsince int64 // g被阻塞的大体时间 lockedm *m // G被锁定只在这个m上运行 } type gobuf struct { sp uintptr pc uintptr g guintptr ctxt unsafe.Pointer ret sys.Uintreg lr uintptr bp uinptr } 保存了当前的栈指针、计数器、当然还有g自身,这里记录自身g的指针是为了快速访问到goroutine中的信息。 ","date":"2022-04-12","objectID":"/gmp/:2:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"P P代表Processor,逻辑处理器,它的主要用途是用来执行goroutine的,所以它也维护了一个goroutine队列,里面存储了所有需要它来执行的goroutine,P/M需要进行绑定,构成一个执行单元。 type p struct { lock mutex id int32 status uint32 // 状态可以为pidle/prunning/... link puintptr schedtick uint32 //每调度一次加1 syscalltick uint32 //每调度一次系统调用加1 m muintptr // 回链到关联的m mcache *mcache racectx uintptr goidcache uint64 //goroutine的ID的缓存 goidcacheend uint64 // 可运行的goroutine的队列 runqhead uint32 runqtail uint32 runq [256]guintptr runnext guintptr // 下一个运行的g sudogcache []*sudog sudogbuf [128]*sudog palloc persistentAlloc pad [sys.CacheLineSize]byte } ","date":"2022-04-12","objectID":"/gmp/:2:1","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"Sched Sched代表调度器,它维护有存储M和G的队列以及调度器的一些状态信息等。 type schedt struct { goidgen uint64 lastpoll uint64 lock mutex midle muintptr // idle状态的m nmidle int32 // idle状态的m个数 nmidlelocked int32 // lockde状态的m个数 mcount int32 // 创建的m的总数 maxmcount int32 // m允许的最大个数 ngsys uint32 // 系统中goroutine的数目，会自动更新 pidle puintptr // idle的p npidle uint32 nmspinning uint32 // 全局的可运行的g队列 runqhead guintptr runqtail guintptr runqsize int32 // dead的G的全局缓存 gflock mutex gfreeStack *g gfreeNoStack *g ngfree int32 // sudog的缓存中心 sudoglock mutex sudogcache *sudog } ","date":"2022-04-12","objectID":"/gmp/:3:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"GMP调度 新创建的Goroutine会存放在Global全局队列中,等待Go调度器进行调度,随后Goroutine被分配给其中的一个逻辑处理器P,并放到这个逻辑处理器对应的Local本地运行队列中,最终等待被逻辑处理器P执行即可。在M与P绑定后,M会不断从P的Local队列中无锁地取出G,并切换到G的堆栈执行,当P的Local队列中没有G时,再从Global队列中获取一个G,当Global队列中也没有待运行的G时,则尝试从其他的P窃取部分G来执行相当于P之间的负载均衡。 从上图可以看到,有2个物理线程M,每一个M都拥有一个处理器P,每一个也都有一个正在运行的goroutine。P的数量可以通过GOMAXPROCS()设置,它其实也就代表了真正的并发度,即有多少个goroutine可以同时运行。 图中灰色的那些goroutine并没有运行,而是处于ready的就绪态,正在等待被调度。P维护着这个队列(称之为runqueue),Go语言里,启动一个goroutine很容易:go function 就行,所以每有一个go语句被执行,runqueue中队列就在其末尾加入一个goroutine,在下一个调度点,就从runqueue中取出一个goroutine执行。 golang GMP模式（golang 的调度模式） CSP（communicating sequential processes）并发模型。不同于传统的多线程通过共享内存来通信，CSP讲究的是“以通信的方式来共享内存”。不要以共享内存的方式来通信，相反，要通过通信来共享内存。 M指的是Machine，一个M直接关联了一个内核线程。 P指的是”processor”，代表了M所需的上下文环境，也是处理用户级代码逻辑的处理器。 G指的是Goroutine，其实本质上也是一种轻量级的线程。 M关联了一个内核线程，通过调度器P（上下文）的调度，可以连接1个或者多个G,相当于把一个内核线程切分成了了N个用户线程，M和P是一对一关系（但是实际调度中关系多变），通过P调度N个G（P和G是一对多关系），实现内核线程和G的多对多关系（M:N），通过这个方式，一个内核线程就可以起N个Goroutine，同样硬件配置的机器可用的用户线程就成几何级增长，并发性大幅提高。 ","date":"2022-04-12","objectID":"/gmp/:4:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"PMG中切换正在等待或者阻塞的协程 ","date":"2022-04-12","objectID":"/gmp/:5:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"gopark函数 gopark函数在协程的实现上扮演着非常重要的角色，用于协程的切换，协程切换的原因一般有以下几种情况： 系统调用； channel读写条件不满足； 抢占式调度时间片结束； gopark函数做的主要事情分为两点： 解除当前goroutine的m的绑定关系，将当前goroutine状态机切换为等待状态； 调用一次schedule()函数，在局部调度器P发起一轮新的调度。 下面我们来研究一下gopark函数是怎么实现协程切换的。 先看看源码： func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) { if reason != waitReasonSleep { checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy } mp := acquirem() gp := mp.curg status := readgstatus(gp) if status != _Grunning \u0026\u0026 status != _Gscanrunning { throw(\"gopark: bad g status\") } mp.waitlock = lock mp.waitunlockf = *(*unsafe.Pointer)(unsafe.Pointer(\u0026unlockf)) gp.waitreason = reason mp.waittraceev = traceEv mp.waittraceskip = traceskip releasem(mp) // can't do anything that might move the G between Ms here. mcall(park_m) } 源码里面最重要的一行就是调用 mcall(park_m) 函数，park_m 是一个函数指针。mcall 在golang需要进行协程切换时被调用，做的主要工作是： 切换当前线程的堆栈从g的堆栈切换到g0的堆栈； 并在g0的堆栈上执行新的函数fn(g)； 保存当前协程的信息( PC/SP存储到g-\u003esched)，当后续对当前协程调用goready函数时候能够恢复现场； mcall函数执行原理 mcall的函数原型是： func mcall(fn func(*g)) 这里函数fn的参数g指的是在调用mcall之前正在运行的协程。 我们前面说到，mcall的主要作用是协程切换，它将当前正在执行的协程状态保存起来，然后在m-\u003eg0 的堆栈上调用新的函数。 在新的函数内会将之前运行的协程放弃，然后调用一次schedule()来挑选新的协程运行。 ( 也就是在fn函数里面会调用一次schedule()函数进行一次scheduler的重新调度，让m去运行其余的goroutine ) mcall函数是通过汇编实现的，在asm_amd64.s里面有64位机的实现，源码如下： // func mcall(fn func(*g)) // Switch to m-\u003eg0's stack, call fn(g). // Fn must never return. It should gogo(\u0026g-\u003esched) // to keep running g. TEXT runtime·mcall(SB), NOSPLIT, $0-8 //DI中存储参数fn MOVQ fn+0(FP), DI get_tls(CX) // 获取当前正在运行的协程g信息 // 将其状态保存在g.sched变量 MOVQ g(CX), AX // save state in g-\u003esched MOVQ 0(SP), BX // caller's PC MOVQ BX, (g_sched+gobuf_pc)(AX) LEAQ fn+0(FP), BX // caller's SP MOVQ BX, (g_sched+gobuf_sp)(AX) MOVQ AX, (g_sched+gobuf_g)(AX) MOVQ BP, (g_sched+gobuf_bp)(AX) // switch to m-\u003eg0 \u0026 its stack, call fn MOVQ g(CX), BX MOVQ g_m(BX), BX MOVQ m_g0(BX), SI CMPQ SI, AX // if g == m-\u003eg0 call badmcall JNE 3(PC) MOVQ $runtime·badmcall(SB), AX JMP AX MOVQ SI, g(CX) // g = m-\u003eg0 // 切换到m-\u003eg0堆栈 MOVQ (g_sched+gobuf_sp)(SI), SP // sp = m-\u003eg0-\u003esched.sp // 参数AX为之前运行的协程g PUSHQ AX MOVQ DI, DX MOVQ 0(DI), DI // 在m-\u003eg0堆栈上执行函数fn CALL DI POPQ AX MOVQ $runtime·badmcall2(SB), AX JMP AX RET 上面的汇编代码我也不是很懂，但是能够大致能够推断出主要做的事情： 保存当前goroutine的状态(PC/SP)到g-\u003esched中，方便下次调度； 切换到m-\u003eg0的栈； 然后g0的堆栈上调用fn； 回到gopark函数里面，我们知道mcall会切换到m-\u003eg0的栈，然后执行park_m函数 下面看一下park_m函数源码： func park_m(gp *g) { // g0 _g_ := getg() if trace.enabled { traceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip) } //线程安全更新gp的状态，置为_Gwaiting casgstatus(gp, _Grunning, _Gwaiting) // 移除gp与m的绑定关系 dropg() if _g_.m.waitunlockf != nil { fn := *(*func(*g, unsafe.Pointer) bool)(unsafe.Pointer(\u0026_g_.m.waitunlockf)) ok := fn(gp, _g_.m.waitlock) _g_.m.waitunlockf = nil _g_.m.waitlock = nil if !ok { if trace.enabled { traceGoUnpark(gp, 2) } casgstatus(gp, _Gwaiting, _Grunnable) execute(gp, true) // Schedule it back, never returns. } } // 重新做一次调度 schedule() } park_m函数主要做的几件事情就是： 线程安全更新goroutine的状态，置为_Gwaiting 等待状态； 解除goroutine与OS thread的绑定关系； 调用schedule()函数，调度器会重新调度选择一个goroutine去运行； schedule函数里面主要调用路径就是： schedule()–\u003eexecute()–\u003egogo() gogo函数的作用正好相反，用来从gobuf中恢复出协程执行状态并跳转到上一次指令处继续执行。因此，其代码也相对比较容易理解，当然，其实现也是通过汇编代码实现的。 ","date":"2022-04-12","objectID":"/gmp/:5:1","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"goready函数： goready函数相比gopark函数来说简单一些，主要功能就是唤醒某一个goroutine，该协程转换到runnable的状态，并将其放入P的local queue，等待调度。 func goready(gp *g, traceskip int) { // 切换到g0的栈 systemstack(func() { ready(gp, traceskip, true) }) } 该函数主要就是切换到g0的栈空间然后执行ready函数。 下面我们看看ready函数源码(删除非主流程代码)： // Mark gp ready to run. func ready(gp *g, traceskip int, next bool) { status := readgstatus(gp) // Mark runnable. _g_ := getg()//g0 _g_.m.locks++ // disable preemption because it can be holding p in a local var if status\u0026^_Gscan != _Gwaiting { dumpgstatus(gp) throw(\"bad g-\u003estatus in ready\") } //设置gp状态为runnable，然后加入到P的可运行local queue; casgstatus(gp, _Gwaiting, _Grunnable) runqput(_g_.m.p.ptr(), gp, next) if atomic.Load(\u0026sched.npidle) != 0 \u0026\u0026 atomic.Load(\u0026sched.nmspinning) == 0 { wakep() } _g_.m.locks-- if _g_.m.locks == 0 \u0026\u0026 _g_.preempt { // restore the preemption request in Case we've cleared it in newstack _g_.stackguard0 = stackPreempt } } 该文章主要详细具体的介绍Goroutine调度器过程及原理，可以对Go调度器的详细调度过程有一个清晰的理解，花 费4天时间作了30+张图(推荐收藏)，包括如下几个章节。 本章节含视频版: 第一章 Golang调度器的由来 第二章 Goroutine调度器的GMP模型及设计思想 第三章 Goroutine调度场景过程全图文解析 一、Golang“调度器”的由来？ (1) 单进程时代不需要调度器 我们知道，一切的软件都是跑在操作系统上，真正用来干活(计算)的是CPU。早期的操作系统每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程，就是“单进程时代” 一切的程序只能串行发生。 早期的单进程操作系统，面临2个问题： 1.单一的执行流程，计算机只能一个任务一个任务处理。 2.进程阻塞所带来的CPU时间浪费。 那么能不能有多个进程来宏观一起来执行多个任务呢？ 后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来，CPU就不浪费了。 (2)多进程/线程时代有了调度器需求 在多进程/多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞cpu可以立刻切换到其他进程中去执行，而且调度cpu的算法可以保证在运行的进程都可以被分配到cpu的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。 但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU虽然利用起来了，但如果进程过多，CPU有很大的一部分都被用来进行进程调度了。 怎么才能提高CPU的利用率呢？ 但是对于Linux操作系统来讲，cpu对进程的态度和线程的态度是一样的。 很明显，CPU调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。 (3)协程来提高CPU利用率 多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4GB[32位操作系统], 而线程也要大约4MB)。 大量的进程/线程出现了新的问题 高内存占用 调度的高消耗CPU 好了，然后工程师们就发现，其实一个线程分为“内核态“线程和”用户态“线程。 一个“用户态线程”必须要绑定一个“内核态线程”，但是CPU并不知道有“用户态线程”的存在，它只知道它运行的是一个“内核态线程”(Linux的PCB进程控制块)。 这样，我们再去细化去分类一下，内核线程依然叫“线程(thread)”，用户线程叫“协程(co-routine)\". ​ 看到这里，我们就要开脑洞了，既然一个协程(co-routine)可以绑定一个线程(thread)，那么能不能多个协程(co-routine)绑定一个或者多个线程(thread)上呢。 ​ 之后，我们就看到了有3中协程和线程的映射关系： N:1关系 N个协程绑定1个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上 缺点： 某个程序用不了硬件的多核加速能力 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。 1:1 关系 1个协程绑定1个线程，这种最容易实现。协程的调度都由CPU完成了，不存在N:1缺点， 缺点： 协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了。 M:N关系 M个协程绑定1个线程，是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。 ​ 协程跟线程是有区别的，线程由CPU调度是抢占式的，协程由用户态调度是协作式的，一个协程让出CPU后，才执行下一个协程。 ​ (4)Go语言的协程goroutine Go为了提供更容易使用的并发方法，使用了goroutine和channel。goroutine来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被runtime调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。 Go中，协程被称为goroutine，它非常轻量，一个goroutine只占几KB，并且这几KB就足够goroutine运行完，这就能在有限的内存空间内支持大量goroutine，支持了更多的并发。虽然一个goroutine的栈只占几KB，但实际是可伸缩的，如果需要更多内容，runtime会自动为goroutine分配。 Goroutine特点： 占用内存更小（几kb） 调度更灵活(runtime调度) (5)被废弃的goroutine调度器 ​ 好了，既然我们知道了协程和线程的关系，那么最关键的一点就是调度协程的调度器的实现了。 Go目前使用的调度器是2012年重新设计的，因为之前的调度器性能存在问题，所以使用4年就被废弃了，那么我们先来分析一下被废弃的调度器是如何运作的？ 大部分文章都是会用G来表示Goroutine，用M来表示线程，那么我们也会用这种表达的对应关系。 下面我们来看看被废弃的golang调度器是如何实现的？ M想要执行、放回G都必须访问全局G队列，并且M有多个，即多线程访问同一资源需要加锁进行保证互斥/同步，所以全局G队列是有互斥锁进行保护的。 老调度器有几个缺点： 创建、销毁、调度G都需要每个M获取锁，这就形成了激烈的锁竞争。 M转移G会造成延迟和额外的系统负载。比如当G中包含创建新协程的时候，M创建了G’，为了继续执行G，需要把G’交给M’执行，也造成了很差的局部性，因为G’和G是相关的，最好放在M上执行，而不是其他M’。 系统调用(CPU在M之间的切换)导致频繁的线程阻塞和取消阻塞操作增加了系统开销。 二、Goroutine调度器的GMP模型的设计思想 面对之前调度器的问题，Go设计了新的调度器。 在新调度器中，除了M(thread)和G(goroutine)，又引进了P(Processor)。 Processor，它包含了运行goroutine的资源，如果线程想运行goroutine，必须先获取P，P中还包含了可运行的G队列。 (1)GMP模型 在Go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。 全局队列（Global Queue）：存放等待运行的G。 P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G’时，G’优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。 Goroutine调度器和OS调度器是通过M结合起来的，每个M都代表了1个内核线程，OS调度器负责把内核线程分配到CPU的核上执行。 ","date":"2022-04-12","objectID":"/gmp/:6:0","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"有关P和M的个数问题 1、P的数量： 由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。 2、M的数量: go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug中的SetMaxThreads函数，设置M的最大数量 一个M阻塞了，会创建新的M。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。 ","date":"2022-04-12","objectID":"/gmp/:6:1","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":null,"content":"P和M何时会被创建 1、P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。 2、M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。 (2)调度器的设计策略 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。 1）work stealing机制 ​ 当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。 2）hand off机制 ​ 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。 利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行。 抢占：在coroutine中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方。 全局G队列：在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。 (3) go func() 调度流程 从上图我们可以分析出几个结论： ​ 1、我们通过 go func()来创建一个goroutine； ​ 2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中； ​ 3、G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行； ​ 4、一个M调度G执行的过程是一个循环机制； ​ 5、当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P； ​ 6、当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。 (4)调度器的生命周期 特殊的M0和G0 M0 M0是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G， 在之后M0就和其他的M一样了。 G0 G0是每次启动一个M都会第一个创建的 goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。 我们来跟踪一段代码 package main import \"fmt\" func main() { fmt.Println(\"Hello world\") } 接下来我们来针对上面的代码对调度器里面的结构做一个分析。 也会经历如上图所示的过程： runtime创建最初的线程m0和goroutine g0，并把2者关联。 调度器初始化：初始化m0、栈、垃圾回收，以及创建和初始化由GOMAXPROCS个P构成的P列表。 示例代码中的main函数是main.main，runtime中也有1个main函数——runtime.main，代码经过编译后，runtime.main会调用main.main，程序启动时会为runtime.main创建goroutine，称它为main goroutine吧，然后把main goroutine加入到P的本地队列。 启动m0，m0已经绑定了P，会从P的本地队列获取G，获取到main goroutine。 G拥有栈，M根据G中的栈信息和调度信息设置运行环境 M运行G G退出，再次回到M获取可运行的G，这样重复下去，直到main.main退出，runtime.main执行Defer和Panic处理，或调用runtime.exit退出程序。 调度器的生命周期几乎占满了一个Go程序的一生，runtime.main的goroutine执行之前都是为调度器做准备工作，runtime.main的goroutine运行，才是调度器的真正开始，直到runtime.main结束而结束。 (5)可视化GMP编程 有2种方式可以查看一个程序的GMP的数据。 方式1：go tool trace trace记录了运行时的信息，能提供可视化的Web页面。 简单测试代码：main函数创建trace，trace会运行在单独的goroutine中，然后main打印\"Hello World\"退出。 trace.go package main import ( \"os\" \"fmt\" \"runtime/trace\" ) func main() { //创建trace文件 f, err := os.Create(\"trace.out\") if err != nil { panic(err) } defer f.Close() //启动trace goroutine err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() //main fmt.Println(\"Hello World\") } 运行程序 $ go run trace.go Hello World 会得到一个trace.out文件，然后我们可以用一个工具打开，来分析这个文件。 $ go tool trace trace.out 2020/02/23 10:44:11 Parsing trace... 2020/02/23 10:44:11 Splitting trace... 2020/02/23 10:44:11 Opening browser. Trace viewer is listening on http://127.0.0.1:33479 我们可以通过浏览器打开http://127.0.0.1:33479网址，点击view trace 能够看见可视化的调度流程。 G信息 点击Goroutines那一行可视化的数据条，我们会看到一些详细的信息。 一共有两个G在程序中，一个是特殊的G0，是每个M必须有的一个初始化的G，这个我们不必讨论。 其中G1应该就是main goroutine(执行main函数的协程)，在一段时间内处于可运行和运行的状态。 M信息 点击Threads那一行可视化的数据条，我们会看到一些详细的信息。 一共有两个M在程序中，一个是特殊的M0，用于初始化使用，这个我们不必讨论。 P信息 G1中调用了main.main，创建了trace goroutine g18。G1运行在P1上，G18运行在P0上。 这里有两个P，我们知道，一个P必须绑定一个M才能调度G。 我们在来看看上面的M信息。 我们会发现，确实G18在P0上被运行的时候，确实在Threads行多了一个M的数据，点击查看如下： 多了一个M2应该就是P0为了执行G18而动态创建的M2. 方式2：Debug trace package main import ( \"fmt\" \"time\" ) func main() { for i := 0; i \u003c 5; i++ { time.Sleep(time.Second) fmt.Println(\"Hello World\") } } 编译 $ go build trace2.go 通过Debug方式运行 $ GODEBUG=schedtrace=1000 ./trace2 SCHED 0ms: gomaxprocs=2 idleprocs=0 threads=4 spinningthreads=1 idlethreads=1 runqueue=0 [0 0] Hello World SCHED 1003ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0] Hello World SCHED 2014ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0] Hello World SCHED 3015ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0] Hello World SCHED 4023ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0] Hello World SCHED：调试信息输出标志字符串，代表本行是goroutine调度器的输出； 0ms：即从程序启动到输出这行日志的时间； gomaxprocs: P的数量，本例有2个P, 因为默认的P的属性是和cpu核心数量默认一致，当然也可","date":"2022-04-12","objectID":"/gmp/:6:2","tags":null,"title":"GMP","uri":"/gmp/"},{"categories":["面试"],"content":"空切片和nil切片 问题： package main import ( \"fmt\" \"reflect\" \"unsafe\" ) func main() { var s1 []int // nil切片 s2 := make([]int,0) // 空切片 s4 := make([]int,0) // 空切片 fmt.Printf(\"s1 pointer:%+v, s2 pointer:%+v, s4 pointer:%+v, \\n\", *(*reflect.SliceHeader)(unsafe.Pointer(\u0026s1)),*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s2)),*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s4))) fmt.Printf(\"%v\\n\", (*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s1))).Data==(*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s2))).Data) fmt.Printf(\"%v\\n\", (*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s2))).Data==(*(*reflect.SliceHeader)(unsafe.Pointer(\u0026s4))).Data) } nil切片和空切片指向的地址一样吗？这个代码会输出什么？ 答： nil切片和空切片指向的地址不一样。nil空切片引用数组指针地址为0（无指向任何实际地址） 空切片的引用数组指针地址是有的，且固定为一个值 s1 pointer:{Data:0 Len:0 Cap:0}, s2 pointer:{Data:824634207952 Len:0 Cap:0}, s4 pointer:{Data:824634207952 Len:0 Cap:0}, false //nil切片和空切片指向的数组地址不一样 true //两个空切片指向的数组地址是一样的，都是824634207952 解释 切片的数据结构： type SliceHeader struct { Data uintptr //引用数组指针地址 Len int // 切片的目前使用长度 Cap int // 切片的容量 } nil切片和空切片最大的区别在于指向的数组引用地址是不一样的。 所有的空切片指向的数组引用地址都是一样的 ","date":"2022-04-11","objectID":"/%E7%A9%BA%E5%88%87%E7%89%87%E5%92%8Cnil%E5%88%87%E7%89%87/:0:0","tags":["面试"],"title":"空切片和nil切片","uri":"/%E7%A9%BA%E5%88%87%E7%89%87%E5%92%8Cnil%E5%88%87%E7%89%87/"},{"categories":["面试"],"content":"Channel 概念： Go中的channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的） 使用场景： 停止信号监听 定时任务 生产方和消费方解耦 控制并发数 底层数据结构： 通过var声明或者make函数创建的channel变量是一个存储在函数栈帧上的指针，占用8个字节，指向堆上的hchan结构体 源码包中src/runtime/chan.go定义了hchan的数据结构： type hchan struct { closed uint32 // channel是否关闭的标志 elemtype *_type // channel中的元素类型 // channel分为无缓冲和有缓冲两种。 // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组 // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移 // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置 buf unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区） qcount uint // 循环数组中的元素数量 dataqsiz uint // 循环数组的长度 elemsize uint16 // 元素的大小 sendx uint // 下一次写下标的位置 recvx uint // 下一次读下标的位置 // 尝试读取channel或向channel写入数据而被阻塞的goroutine recvq waitq // 读等待队列 sendq waitq // 写等待队列 lock mutex //互斥锁，保证读写channel时不存在并发竞争问题 } 等待队列： 双向链表，包含一个头结点和一个尾结点 每个节点是一个sudog结构体变量，记录哪个协程在等待，等待的是哪个channel，等待发送/接收的数据在哪里 type waitq struct { first *sudog last *sudog } type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer c *hchan ... } 操作： 创建 使用 make(chan T, cap) 来创建 channel，make 语法会在编译时，转换为 makechan64 和 makechan func makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\"makechan: size out of range\")) } return makechan(t, int(size)) } 创建channel 有两种，一种是带缓冲的channel，一种是不带缓冲的channel // 带缓冲 ch := make(chan int, 3) // 不带缓冲 ch := make(chan int) 创建时会做一些检查: 元素大小不能超过 64K 元素的对齐大小不能超过 maxAlign 也就是 8 字节 计算出来的内存是否超过限制 创建时的策略: 如果是无缓冲的 channel，会直接给 hchan 分配内存 如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址 如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址 发送 发送操作，编译时转换为runtime.chansend函数 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool 阻塞式： 调用chansend函数，并且block=true ch \u003c- 10 非阻塞式： 调用chansend函数，并且block=false select { case ch \u003c- 10: ... default } 向 channel 中发送数据时大概分为两大块：检查和数据发送，数据发送流程如下： 如果 channel 的读等待队列存在接收者goroutine 将数据直接发送给第一个等待的 goroutine， 唤醒接收的 goroutine 如果 channel 的读等待队列不存在接收者goroutine 如果循环数组buf未满，那么将会把数据发送到循环数组buf的队尾 如果循环数组buf已满，这个时候就会走阻塞发送的流程，将当前 goroutine 加入写等待队列，并挂起等待唤醒 接收 发送操作，编译时转换为runtime.chanrecv函数 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) 阻塞式： 调用chanrecv函数，并且block=true \u003cch v := \u003cch v, ok := \u003cch // 当channel关闭时，for循环会自动退出，无需主动监测channel是否关闭，可以防止读取已经关闭的channel,造成读到数据为通道所存储的数据类型的零值 for i := range ch { fmt.Println(i) } 非阻塞式： 调用chanrecv函数，并且block=false select { case \u003c-ch: ... default } 向 channel 中接收数据时大概分为两大块，检查和数据发送，而数据接收流程如下： 如果 channel 的写等待队列存在发送者goroutine 如果是无缓冲 channel，直接从第一个发送者goroutine那里把数据拷贝给接收变量，唤醒发送的 goroutine 如果是有缓冲 channel（已满），将循环数组buf的队首元素拷贝给接收变量，将第一个发送者goroutine的数据拷贝到 buf循环数组队尾，唤醒发送的 goroutine 如果 channel 的写等待队列不存在发送者goroutine 如果循环数组buf非空，将循环数组buf的队首元素拷贝给接收变量 如果循环数组buf为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并挂起等待唤醒 关闭 关闭操作，调用close函数，编译时转换为runtime.closechan函数 close(ch) func closechan(c *hchan) 案例分析： package main import ( \"fmt\" \"time\" \"unsafe\" ) func main() { // ch是长度为4的带缓冲的channel // 初始hchan结构体重的buf为空，sendx和recvx均为0 ch := make(chan string, 4) fmt.Println(ch, unsafe.Sizeof(ch)) go sendTask(ch) go receiveTask(ch) time.Sleep(1 * time.Second) } // G1是发送者 // 当G1向ch里发送数据时，首先会对buf加锁，然后将task存储的数据copy到buf中，然后sendx++，然后释放对buf的锁 func sendTask(ch chan string) { taskList := []string{\"this\", \"is\", \"a\", \"demo\"} for _, task := range taskList { ch \u003c- task //发送任务到channel } } // G2是接收者 // 当G2消费ch的时候，会首先对buf加锁，然后将buf中的数据copy到task变量对应的内存里，然后recvx++,并释放锁 func receiveTask(ch chan string) { for { task := \u003c-ch //接收任务 fmt.Println(\"received\", task) //处理任务 } } 总结 hchan结构体的主要组成部分有四个： 用来保存goroutine之间传递数据的循环数组：buf 用来记录此循环数组当前发送或接收数据的下标值：sendx和recvx 用于保存向该chan发送和从该chan接收数据被阻塞的goroutine队列： sendq 和 recvq 保证channel写入和读取数据时线程安全的锁：lock ","date":"2022-04-11","objectID":"/channel/:0:0","tags":["面试"],"title":"Channel","uri":"/channel/"},{"categories":["面试"],"content":"对未初始化的的chan进行读写，会怎么样？为什么？ 答： 写未初始化的 chan package main // 写未初始化的chan func main() { var c chan int c \u003c- 1 } // 输出结果 fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan send (nil chan)]: main.main() /Users/admin18/go/src/code.byted.org/linzhaolun/repos/main.go:6 +0x36 写读未初始化的 chan package main import \"fmt\" // 读未初始化的chan func main() { var c chan int num, ok := \u003c-c fmt.Printf(\"读chan的协程结束, num=%v, ok=%v\\n\", num, ok) } // 输出结果 fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan receive (nil chan)]: main.main() /Users/admin18/go/src/code.byted.org/linzhaolun/repos/main.go:6 +0x46 为什么对未初始化的 chan 就会阻塞呢？ 对于写的情况 //在 src/runtime/chan.go中 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不能阻塞，直接返回 false，表示未发送成功 if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") } // 省略其他逻辑 } 未初始化的 chan 此时是等于 nil，当它不能阻塞的情况下，直接返回 false，表示写 chan 失败 当 chan 能阻塞的情况下，则直接阻塞 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2), 然后调用 throw(s string) 抛出错误，其中 waitReasonChanSendNilChan 就是刚刚提到的报错 “chan send (nil chan)” 对于读的情况 //在 src/runtime/chan.go中 func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { //省略逻辑... if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } //省略逻辑... } 未初始化的 chan 此时是等于 nil，当它不能阻塞的情况下，直接返回 false，表示读 chan 失败 当 chan 能阻塞的情况下，则直接阻塞 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2), 然后调用 throw(s string) 抛出错误，其中 waitReasonChanReceiveNilChan 就是刚刚提到的报错 “chan receive (nil chan)” ","date":"2022-04-11","objectID":"/channel/:1:0","tags":["面试"],"title":"Channel","uri":"/channel/"},{"categories":["面试"],"content":"1.for select时，如果通道已经关闭会怎么样？如果select中只有一个case呢？ 答： for循环select时，如果其中一个case通道已经关闭，则每次都会执行到这个case。 如果select里边只有一个case，而这个case被关闭了，则会出现死循环。 package _for import ( \"fmt\" \"testing\" \"time\" ) //问题：for select时，如果通道已经关闭会怎么样？如果select中只有一个case呢？ //结果：当未有值时，由于缓存为0，\u003c-ch 没数据，则一直走default，当有值输入后，但是在通道关闭后，这个通道一直能读出内容。 func TestForCase(t *testing.T) { ch := make(chan int) go func() { time.Sleep(time.Second * 1) ch \u003c- 1 close(ch) }() for { select { case a, ok := \u003c-ch: fmt.Printf(\"fmt:%d time:%v %v \\t\\n\", a, time.Now(), ok) time.Sleep(500 * time.Millisecond) default: fmt.Println(\"咩有读出来\") time.Sleep(500 * time.Millisecond) } } } 结果: === RUN TestForCase 咩有读出来 咩有读出来 fmt:1 time:2022-04-11 23:01:15.691889 +0800 CST m=+1.005903641 true fmt:0 time:2022-04-11 23:01:16.193244 +0800 CST m=+1.507252014 false fmt:0 time:2022-04-11 23:01:16.694997 +0800 CST m=+2.008997910 false ","date":"2022-04-11","objectID":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/:1:0","tags":["面试"],"title":"面试题","uri":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/"},{"categories":["面试"],"content":"2.怎么样才能不读关闭后通道 func TestForCase2(t *testing.T) { ch := make(chan int) go func() { time.Sleep(time.Second * 1) ch \u003c- 1 close(ch) }() for { select { case a, ok := \u003c-ch: fmt.Printf(\"fmt:%d time:%v %v \\t\\n\", a, time.Now(), ok) time.Sleep(500 * time.Millisecond) if !ok { ch = nil //把关闭后的通道复值为nil，则select读取则会阻塞 } default: fmt.Println(\"咩有读出来\") time.Sleep(500 * time.Millisecond) } } } === RUN TestForCase2 咩有读出来 咩有读出来 咩有读出来 fmt:1 time:2022-04-11 23:16:03.751807 +0800 CST m=+1.506454927 true fmt:0 time:2022-04-11 23:16:04.253248 +0800 CST m=+2.007888277 false 咩有读出来 咩有读出来 咩有读出来 ","date":"2022-04-11","objectID":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/:2:0","tags":["面试"],"title":"面试题","uri":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/"},{"categories":["面试"],"content":"3.如果select里只有一个已经关闭的case，会怎么样？ func TestForCase2(t *testing.T) { ch := make(chan int) go func() { time.Sleep(time.Second * 1) ch \u003c- 1 close(ch) }() for { select { case a, ok := \u003c-ch: fmt.Printf(\"fmt:%d time:%v %v \\t\\n\", a, time.Now(), ok) time.Sleep(500 * time.Millisecond) if !ok { ch = nil //把关闭后的通道复值为nil，则select读取则会阻塞 } //default: // fmt.Println(\"咩有读出来\") // time.Sleep(500 * time.Millisecond) } } } === RUN TestForCase2 fmt:1 time:2022-04-11 23:19:03.189441 +0800 CST m=+1.003139137 true fmt:0 time:2022-04-11 23:19:03.693051 +0800 CST m=+1.506741808 false fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan receive]: testing.(*T).Run(0xc000001500, 0x11a0fe9, 0xc, 0x11a94f0, 0x62544600) /usr/local/Cellar/go/1.15.5/libexec/src/testing/testing.go:1169 +0x676 总结 select中如果任意某个通道有值可读时，它就会被执行，其他被忽略。 如果没有default字句，select将有可能阻塞，直到某个通道有值可以运行，所以select里最好有一个default，否则将有一直阻塞的风险。 ","date":"2022-04-11","objectID":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/:3:0","tags":["面试"],"title":"面试题","uri":"/for-select%E6%97%B6%E5%A6%82%E6%9E%9C%E9%80%9A%E9%81%93%E5%B7%B2%E7%BB%8F%E5%85%B3%E9%97%AD%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7/"},{"categories":["面试"],"content":"零拷贝 传统的I/O操作基本上要分为四步： 磁盘文件读入操作系统 操作系统读到用户进程 用户进程写到操作系统 操作系统写入磁盘文件 零拷贝就是指，传输一个文件的时候，不需要把文件读到用户进程再处理，而是直接把文件读到操作系统一个内存区，然后再移动到操作系统的另一个内存区，最后写入文件。 这样一来，步骤变成这样： 磁盘文件读入操作系统 操作系统把数据写入操作系统另一个区域 操作系统写入磁盘文件 虽然只少了一步，但是这里不仅减少了数据移动的时间损耗，而且减少了系统调用的次数，因此大大缩短了时间。 数据拷贝 数据拷贝的模式，每一次拷贝我都打上了序号 DMA控制器将数据从磁盘拷贝到内核缓冲区，这是第1次拷贝（DMA拷贝） CPU将数据从内核缓冲区复制到应用程序缓冲区，这是第2次拷贝（CPU拷贝）（内核态=\u003e用户态） CPU将数据从应用程序缓冲区复制到Socket缓冲区，这是第3次拷贝（CPU拷贝） DMA控制器将数据从Socket缓冲区拷贝到网卡，这是第4次拷贝（DMA拷贝）（用户态=\u003e内核态） 由上述信息可得：一共经历了四次拷贝，其中两次是CPU拷贝，两次是DMA拷贝;经历了两次的状态切换（我就拷贝个数据怎么这么麻烦） MMAP mmap主要是 内存映射 这项技术的出现，下面这段关于内存映射的介绍摘自网络 内存映射文件技术是操作系统提供的一种新的文件数据存取机制，利用内存映射文件技术，系统可以在内存空间中为文件保留一部分空间，并将文件映射到这块保留空间，一旦文件被映射后，操作系统将管理页映射缓冲以及高速缓冲等任务，而不需要调用分配、释放内存块和文件输入/输出的API函数，也不需要自己提供任何缓冲算法。 使用内存映射文件处理存储于磁盘上的文件时，将不必再对文件执行I/O 操作，这意味着在对文件进行处理时将不必再为文件申请并分配缓存，所有的文件缓存操作均由系统直接管理，由于取消了将文件数据加载到内存、数据从内存到文件的回写以及释放内存块等步骤，使得内存映射文件在处理大数据量的文件时能起到相当重要的作用。 通过mmap这项技术，我们可以实现了避免将数据拷贝出内核空间了，但是仍然存在一次CPU拷贝，CPU是非常珍贵的资源，并且这个mmap的模式除了CPU这次拷贝之外（其实在mmap出现的时候还是很棒的，不过我们现在有了新的认知了），还存在着另外一个问题，就是可能出现碎片问题跟多进程下同时操作文件时可能产生引发coredump的signal。 碎片问题主要是体现在，拷贝的时候，可能是小文件，如果是大文件就会大大降低这种碎片问题的出现。（碎片问题主要是我们查内存还有很多，但是申请大内存会有申请失败的情况出现，原理可以自行查看，主要是顺序分配内存与整块分配内存相关的） 当对文件进行了内存映射，然后调用 write() 系统调用，如果此时其他的进程截断了这个文件，那么 write() 系统调用将会被总线错误信号 SIGBUS 中断，因为此时正在执行的是一个错误的存储访问。该信号的默认行为是杀死进程和转储核心。（源于操作系统对于进程的内存保护机制） ","date":"2022-04-11","objectID":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/:0:0","tags":["面试"],"title":"零拷贝","uri":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"categories":["面试"],"content":"「当然上面所说存在的两个问题是可以通过其他方法解决的」 ","date":"2022-04-11","objectID":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/:1:0","tags":["面试"],"title":"零拷贝","uri":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"categories":["面试"],"content":"①「对SIGBUS捕捉处理」 对SIGBUS 信号进行简单处理并返回，这样，write() 系统调用在它被中断之前就返回已经写入的字节数目，errno 会被设置成 success。（说白了就是让程序不会出现coredump）「缺点」：它不能反映出产生这个问题的根源所在，因为 BIGBUS 信号只是显示某进程发生了一些很严重的错误。 ","date":"2022-04-11","objectID":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/:1:1","tags":["面试"],"title":"零拷贝","uri":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"categories":["面试"],"content":"②「文件租借锁」 当进程尝试打开一个被租借锁保护的文件时，该进程会被阻塞，同时，在一定时间内拥有该文件租借锁的进程会收到一个信号。收到信号之后，拥有该文件租借锁的进程会首先更新文件，从而保证了文件内容的一致性，接着，该进程释放这个租借锁。如果拥有租借锁的进程在一定的时间间隔内没有完成工作，内核就会自动删除这个租借锁或者将该锁进行降级，从而允许被阻塞的进程继续工作。「注意」：文件租借锁需要在对文件进行内存映射之前设置。 sendfile 前面几次到Socket当中我们都是把完整的数据拷贝带Socket缓冲区当中，但是经过思考，反正数据是最终拷贝到网卡当中，也就是Socket缓冲区又是一个中间者而已，我们何不想个方法，能把数据直接拷贝到网卡，这个就是我们的sendfile了，我们拷贝去socket缓冲区只拷贝了文件描述符跟数据长度，然后直接采用DMA收集拷贝内核缓冲区的数据到网卡当中。 ","date":"2022-04-11","objectID":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/:1:2","tags":["面试"],"title":"零拷贝","uri":"/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"},{"categories":null,"content":"etcd的使用实例 etcd有两个版本的接口，v2和v3，且两个版本不兼容，v2已经停止了支持，v3性能更好。 注意 ：etcdctl默认使用v2版本，如果想使用v3版本，可通过环境变量ETCDCTL_API=3进行设置 etcd 有如下的使用场景： 服务发现（Service Discovery） 消息发布与订阅 负载均衡 分布式通知与协调 分布式锁 分布式队列 集群监控于Leader竞选。 一、服务发现 etcd 的常见使用场景之一就是服务发现。实现思路如下：先准备 etcd 服务端，服务端的程序在第一次启动之后会连接到 etcd 服务器并设置一个格式为 ip:port 的键值对，并绑定一个 lease。之后的服务端内部维护一个定时器，每隔一段时间就更新服务端注册中心的 lease 的 TTL。另外一个组件就是服务发现组件，discovery 会 watch 服务端的 key。每次该 key 变化时，discovery 就可以检测到时间并做出对应的操作。代码的实现如下： // server.go package main import ( \"context\" \"crypto/md5\" \"encoding/json\" \"errors\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client stopSignal = make(chan struct{}, 1) srvKey string ) var ( serv = flag.String(\"name\", \"hello\", \"service name\") port = flag.Int(\"port\", 30000, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func Register(endpoints string, config *SvConfig, interval time.Duration, ttl int) error { // 解析服务端的值 srvValue, _ := json.Marshal(config) srvKey = fmt.Sprintf(\"%s/%x\", prefix, md5.Sum(srvValue)) var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(endpoints, \",\"), DialTimeout: time.Second * 2, }) if err != nil { return fmt.Errorf(\"register service failed: %v\", err) } go func() { timer := time.NewTicker(interval) for { resp, _ := client.Grant(context.TODO(), int64(ttl)) _, err = client.Get(context.TODO(), srvKey) if err != nil { // 捕获 key 不存在的场合 if errors.Is(err, rpctypes.ErrKeyNotFound) { _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) if err != nil { log.Printf(\"register service %s at %s:%d\\n\", config.Name, config.Host, config.Port) } } } else { // 如果key存在就更新ttl _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) } select { case \u003c-stopSignal: return case \u003c-timer.C: } } }() return err } func Unregister() error { stopSignal \u003c- struct{}{} stopSignal = make(chan struct{}, 1) _, err := client.Delete(context.TODO(), srvKey) return err } func main() { flag.Parse() // 绑定服务地址和端口 lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", *port)) if err != nil { panic(err) } config := \u0026SvConfig{ Name: *serv, Host: \"127.0.0.1\", Port: *port, } Register(*endpoint, config, time.Second*10, 15) ch := make(chan os.Signal, 1) signal.Notify(ch, syscall.SIGTERM, syscall.SIGINT, syscall.SIGKILL, syscall.SIGHUP, syscall.SIGQUIT) go func() { \u003c-ch Unregister() os.Exit(1) }() log.Printf(\"service %s start at %d\", *serv, *port) // server todo for { lis.Accept() } } // discovery.go package main import ( \"context\" \"encoding/json\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client ) var ( port = flag.Int(\"port\", 30001, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func watcher() error { var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(*endpoint, \",\"), DialTimeout: time.Second * 3, }) if err != nil { return fmt.Errorf(\"connect etcd cluster failed: %v\", err.Error()) } go func() { resp := client.Watch(context.TODO(), prefix, clientv3.WithPrefix()) for ch := range resp { for _, event := range ch.Events { switch event.Type { case clientv3.EventTypePut: if event.IsCreate() { srv := parseSrv(event.Kv.Value) log.Printf(\"discovery service %s at %s:%d\", srv.Name, srv.Host, srv.Port) } case clientv3.EventTypeDelete: log.Printf(\"delete service %s\", event.Kv.Key) } } } }() return err } func parseSrv(text []byte) *SvConfig { svc := \u0026SvConfig{} json.Unmarshal(text, \u0026svc) return svc } func main() { flag.Parse() // 绑定服务地址和端口 li","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:0:0","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"查询数据 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:0","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"按key值查询 etcdctl get name1 name1 james ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:1","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"不显示key只限制values etcdctl get --print-value-only name1 james ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:2","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"按key前缀查找 etcdctl get --prefix name name1 james name11 alice name12 seli name2 jetty name3 tom name4 cris ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:3","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"按key的字节排序的前缀查找 \u003e= etcdctl get --from-key name2 name2 jetty name3 tom name4 cris ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:4","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"按key的字节排序区间查找 \u003c= value \u003c etcdctl get name1 name3 name1 james name11 alice name12 seli name2 jetty ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:5","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"查找所有key etcdctl get --from-key \"\" avg_age 25 name1 james name11 alice name12 seli name2 jetty name3 tom name4 cris ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:1:6","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除数据 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:0","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除key name11 etcdctl del name11 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:1","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除key name12时并返回被删除的键值对 etcdctl del --prev-kv name12 1 name12 seli ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:2","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除指定字节排序起始值后的key etcdctl del --prev-kv --from-key name3 2 name3 tom name4 cris ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:3","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除指定前缀的key etcdctl del --prev-kv --prefix name 2 name1 james name2 jetty ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:4","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"删除所有数据 etcdctl del --prefix \"\" 9 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:2:5","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"更新数据 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:3:0","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"直接用put即可 etcdctl put avg_age 30 etcdctl get --prefix \"\" avg_age 30 ","date":"2022-04-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:3:1","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"MangoDB的基础 MongoDB是一个基于分布式文件存储的数据库。默认端口为27017 ","date":"2022-04-08","objectID":"/mangodb%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/:0:0","tags":null,"title":"Mangodb的基础使用","uri":"/mangodb%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"},{"categories":["微信支付"],"content":"微信支付V3 整理整体流程 ","date":"2022-04-08","objectID":"/payment/:0:0","tags":["HS"],"title":"微信支付的接口","uri":"/payment/"},{"categories":null,"content":"日志 // 日志记录到文件 func (d *Handler) LoggerToFile() gin.HandlerFunc { return func(c *gin.Context) { // 开始时间 startTime := time.Now() // 处理请求 c.Next() // 结束时间 endTime := time.Now() // 执行时间 latencyTime := endTime.Sub(startTime) // 请求方式 reqMethod := c.Request.Method // 请求路由 reqUri := c.Request.RequestURI // 状态码 statusCode := c.Writer.Status() // 请求IP clientIP := c.ClientIP() //// 日志格式 //fmt.Printf(\"%s [INFO] %s %s %3d %13v %15s \\r\\n\", // startTime.Format(\"2006-01-02 15:04:05\"), // reqMethod, // reqUri, // statusCode, // latencyTime, // clientIP, //) log.Infof(\"%s %s %3d %13v %15s\", reqMethod, reqUri, statusCode, latencyTime, clientIP) if c.Request.Method != \"GET\" \u0026\u0026 c.Request.Method != \"OPTIONS\" \u0026\u0026 conf.Conf.LoggerConfig.EnabledDB { d.SetDBOperLog(c, clientIP, statusCode, reqUri, reqMethod, latencyTime) } } } 自定义异常处理 func (d *Handler) CustomError(c *gin.Context) { defer func() { if err := recover(); err != nil { if c.IsAborted() { c.Status(200) } switch errStr := err.(type) { case string: p := strings.Split(errStr, \"#\") if len(p) == 3 \u0026\u0026 p[0] == \"CustomError\" { statusCode, e := strconv.Atoi(p[1]) if e != nil { break } c.Status(statusCode) fmt.Println( time.Now().Format(\"2006-01-02 15:04:05\"), \"[ERROR]\", c.Request.Method, c.Request.URL, statusCode, c.Request.RequestURI, c.ClientIP(), p[2], ) c.JSON(http.StatusOK, gin.H{ \"code\": statusCode, \"msg\": p[2], }) } default: panic(err) } } }() c.Next() } 请求id func (d *Handler) RequestId() gin.HandlerFunc { return func(c *gin.Context) { // Check for incoming header, use it if exists requestId := c.Request.Header.Get(\"X-Request-Id\") // Create request id with UUID4 if requestId == \"\" { u4 := uuid.NewV4() requestId = u4.String() } // Expose it for use in the application c.Set(\"X-Request-Id\", requestId) // Set X-Request-Id header c.Writer.Header().Set(\"X-Request-Id\", requestId) c.Next() } } nocache // NoCache is a middleware function that appends headers // to prevent the client from caching the HTTP response. func (d *Handler) NoCache(c *gin.Context) { c.Header(\"Cache-Control\", \"no-cache, no-store, max-age=0, must-revalidate, value\") c.Header(\"Expires\", \"Thu, 01 Jan 1970 00:00:00 GMT\") c.Header(\"Last-Modified\", time.Now().UTC().Format(http.TimeFormat)) c.Next() } 跨域 //Options is a middleware function that appends headers // for options requests and aborts then exits the middleware // chain and ends the request. func (d *Handler) Options(c *gin.Context) { if c.Request.Method != \"OPTIONS\" { c.Next() } else { c.Header(\"Access-Control-Allow-Origin\", \"*\") c.Header(\"Access-Control-Allow-Methods\", \"GET,POST,PUT,PATCH,DELETE,OPTIONS\") c.Header(\"Access-Control-Allow-Headers\", \"lang,X-DEVICE-ID,X-APP-VERSION,X-CHANNEL,authorization, origin, content-type, accept,X-TENANT-CODE,sign,time\") c.Header(\"Allow\", \"HEAD,GET,POST,PUT,PATCH,DELETE,OPTIONS\") c.Header(\"Content-Type\", \"application/json\") c.AbortWithStatus(200) } } Secure // Secure is a middleware function that appends security // and resource access headers. func (d *Handler) Secure(c *gin.Context) { c.Header(\"Access-Control-Allow-Origin\", \"*\") //c.Header(\"X-Frame-Options\", \"DENY\") c.Header(\"X-Content-Type-Options\", \"nosniff\") c.Header(\"X-XSS-Protection\", \"1; mode=block\") if c.Request.TLS != nil { c.Header(\"Strict-Transport-Security\", \"max-age=31536000\") } // Also consider adding Content-Security-Policy headers // c.Header(\"Content-Security-Policy\", \"script-src 'self' https://cdnjs.cloudflare.com\") } 限流 func (d *Handler) Limiter(ctx *gin.Context) { now := time.Now().UnixNano() key := \"REDIS_LIMITER\" userCntKey := fmt.Sprint(constant.ImApiRedisPrefix, ctx.ClientIP(), \":\", key) //五秒限流 var limit int64 = 10 dura := time.Second * 60 //删除有序集合中的五秒之前的数据 d.Dao.Redis.ZRemRangeByScore(ctx, userCntKey, \"0\", fmt.Sprint(now-(dura.Nanoseconds()))).Result() reqs, _ := d.Dao.Redis.ZCard(ctx, userCntKey).Result() if reqs \u003e= limit { ctx.AbortWithStatusJSON(http.StatusTooManyRequests, gin.H{ \"status\": http.StatusTooManyRequests, \"message\": \"too many request\", }) return } ctx.N","date":"2022-02-08","objectID":"/gin/:0:0","tags":null,"title":"gin 常用中间件","uri":"/gin/"},{"categories":null,"content":"Aix添加和删除Iscsi存储卷 Aix为6.1版本 使用iscsi存储 首先需要创建一个iscsi target，并共享到IBM Aix上。 ","date":"2021-12-03","objectID":"/aix1/:0:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"检查iscsi是否被安装 $ lslpp -L | grep -i iscsi devices.common.IBM.iscsi.rte 6.1.5.0 C F Common iSCSI Files devices.iscsi.disk.rte 6.1.5.0 C F iSCSI Disk Software ... ","date":"2021-12-03","objectID":"/aix1/:1:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"配置iscsi $ vi /etc/iscsi/targets ... # 添加target 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup ","date":"2021-12-03","objectID":"/aix1/:2:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"重新扫盘 $ cfgmgr -l iscsi0 cfgmgr: 0514-621 WARNING: The following device packages are required for device support but are not currently installed. devices.iscsi.array ","date":"2021-12-03","objectID":"/aix1/:3:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"查看iscsi盘 $ lsdev -Cc disk | grep iSCSI hdisk18 Available Other iSCSI Disk Drive ","date":"2021-12-03","objectID":"/aix1/:4:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建物理卷 $ chdev -l hdisk18 -a pv=yes ","date":"2021-12-03","objectID":"/aix1/:5:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建vg $ mkvg -y wbrt_portal_bg hdisk18 ","date":"2021-12-03","objectID":"/aix1/:6:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建lv $ mklv -t jfs2 -y wbrt_portal_bl wbrt_portal_bg 700 注:lv的大小可以使用命令 $ lsvg wbrt_portal_bg | grep \"TOTAL PPs\" | awk -F' ' '{ print $6}' 703 但不要全部使用，需要一些剩余空间。 ","date":"2021-12-03","objectID":"/aix1/:7:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建挂载目录 $ mkdir /mnt/iscsi ","date":"2021-12-03","objectID":"/aix1/:8:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"格式化并挂载 $ crfs -v jfs2 -m /mnt/iscsi -d wbrt_portal_bl $ mount /mnt/iscsi 删除存储盘 ","date":"2021-12-03","objectID":"/aix1/:9:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"卸载磁盘 $ umount /mnt/iscsi ","date":"2021-12-03","objectID":"/aix1/:10:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"lv $ rmlv wbrt_portal_bl ","date":"2021-12-03","objectID":"/aix1/:11:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除文件系统 $ rmfs -r /dev/wbrt_portal_bl ","date":"2021-12-03","objectID":"/aix1/:12:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除vg $ reducevg -d wbrt_portal_bg hdisk18 ","date":"2021-12-03","objectID":"/aix1/:13:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除物理盘 $ rmdev -dl hdisk18 -R ","date":"2021-12-03","objectID":"/aix1/:14:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除iscsi target $ vi /etc/iscsi/targets ... # 添加target # 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup 重读磁盘 $ cfgmgr -l iscsi0 ","date":"2021-12-03","objectID":"/aix1/:15:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"C++友元 友元说明 相对于其他的编程语言，“友元”是C++中特别的一种语法。那它有什么作用呢？ 其实“友元”就是提供一种访问类私有部分的的方法。如果没有“友元”，我们只能通过类本身提供的公有方法来访问，但相对地，这样限制太高了，所以“友元”就是一种的在类的封装性和实用性中很好的“折中”方式。 C++中的友元有三种： 友元函数 友元类 友元成员函数 C++中使用关键字friend来定义。 友元函数 这里直接用代码来说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p(\"xingyys\", \"123456\"); getPerson(p); return 0; } 这个例子还是比较简单的，只要在指定的方法中添加关键字就可以实现了。 友元类 在来一个例子说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Tv { private: int state; int volume; int maxchannel; int channel; int mode; int input; public: // 在这里指定谁是他的友元 friend class Remote; enum { Off, On }; enum { MinVal, MaxVal = 20 }; enum { Antenna, Cable }; enum { TV, DVD }; Tv(int s = Off, int mc = 125) : state(s), volume(5), maxchannel(mc), channel(2), mode(Cable), input(TV) {} void onoff() { state = (state == On) ? Off : On; } bool ison() const { return state == On; } bool volup(); bool voldown(); void chanup(); void chandown(); void set_mode() { mode = (mode == Antenna) ? Cable : Antenna; } void set_input() { input = (input == TV) ? DVD : TV; } void settings() const; }; class Remote { private: int mode; public: Remote(int m = Tv::TV) : mode(m) {} bool volup(Tv \u0026t) { return t.volup(); } bool voldown(Tv \u0026t) { return t.voldown(); } void onoff(Tv \u0026t) { t.onoff(); } void chanup(Tv \u0026t) { t.chanup(); } void chandown(Tv \u0026t) { t.chandown(); } void set_chan(Tv \u0026t, int c) { t.channel = c; } void set_mode(Tv \u0026t) { t.set_mode(); } void set_input(Tv \u0026t) { t.set_input(); } }; bool Tv::volup() { if (volume \u003c MaxVal) { volume++; return true; } else { return false; } } bool Tv::voldown() { if (volume \u003e MinVal) { volume--; return true; } else { return false; } } void Tv::chanup() { if (channel \u003c maxchannel) channel++; else channel = 1; } void Tv::chandown() { if (channel \u003e 1) channel--; else channel = maxchannel; } void Tv::settings() const { using std::cout; using std::endl; cout \u003c\u003c \"TV is \" \u003c\u003c (state == Off ? \"Off\" : \"On\") \u003c\u003c endl; if (state == On) { cout \u003c\u003c \"Volume setting = \" \u003c\u003c volume \u003c\u003c endl; cout \u003c\u003c \"Channel setting = \" \u003c\u003c channel \u003c\u003c endl; cout \u003c\u003c \"Mode = \" \u003c\u003c (mode == Antenna ? \"antenna\" : \"cable\") \u003c\u003c endl; cout \u003c\u003c \"Input = \" \u003c\u003c (input == TV ? \"TV\" : \"DVD\") \u003c\u003c endl; } } int main() { using std::cout; Tv s42; cout \u003c\u003c \"Initial setting for 42\\\"TV:\\n\"; s42.settings(); s42.onoff(); s42.chanup(); cout \u003c\u003c \"\\nAdjusted setting for 42\\\"TV:\\n\"; s42.chanup(); cout \u003c\u003c \"\\nAdjusted settings for 42\\\"TV:\\n\"; s42.settings(); Remote grey; grey.set_chan(s42, 10); grey.volup(s42); grey.volup(s42); cout \u003c\u003c \"\\n42\\\"setting after using remote:\\n\"; s42.settings(); Tv s58(Tv::On); s58.set_mode(); grey.set_chan(s58, 28); cout \u003c\u003c \"\\n58\\\"settings:\\n\"; s58.settings(); return 0; } 友元成员函数 #include \u003ciostream\u003e#include \u003cstring\u003e class Person; class Point { public: void getPerson(Person \u0026p); }; class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void Point::getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void Point::getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p (\"xingyys\", \"123456\"); Point pt; pt.getPerson(p); return 0; } 补充 不能定义类的对象。 可以用于定义指向这个类型的指针或引用。 用于声明(不是定义)，使用该类型作为形参类型或者函数的返回值类型。 友元关系不能被继承。 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明 ","date":"2021-12-03","objectID":"/c-%E5%8F%8B%E5%85%83/:0:0","tags":null,"title":"C++友元","uri":"/c-%E5%8F%8B%E5%85%83/"},{"categories":null,"content":"CentOS7 安装 qemu-5.2.0 本文介绍在 CentOS7.9 上编译安装 qemu-5.2.0 安装 Python3 编译安装 qemu-5.2.0 依赖 Python3.6 及以上的版本。所以首先安装 Python3.6。这里选择编译安装。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:0:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"下载 Python3.6.12 从 Python 官网下载 Python3.6.12 源码包： wget https://www.python.org/ftp/python/3.6.12/Python-3.6.12.tar.xz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:1:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"解压 tar -xvf Python-3.6.12.tar.gz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:2:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"安装 openssl pip 下载是需要 ssl 支持，所以下载 openssl yum install -y openssl openssl-devel zlib-devel bzip2-devel bzip2 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:3:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"编译安装 cd Python-3.6.12 ./configure --prefix=/usr/local/python3 --enable-optimizations make -j8 build_all \u0026\u0026 make -j8 install ","date":"2021-12-03","objectID":"/centos7_install_qemu/:4:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"设置软链接 ln -s /usr/local/python3/bin/python3 /usr/bin/python3 ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:5:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"验证 # python3 Python 3.6.12 (default, Dec 27 2020, 07:52:33) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e 安装 ninja qemu-5.2.0 编译时使用构建工具 ninja 下载 ninja git clone git://github.com/ninja-build/ninja.git \u0026\u0026 cd ninja ./configure.py --bootstrap cp ninja /usr/bin/ 使用 ninja --version, 验证 ninja 版本: # ninja --version 1.10.2.git 编译安装 qemu-5.2.0 完成以上步骤之后就可以开始安装qemu了。其实可以通过 yum 安装，但是会缺少一些二进制文件。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:6:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"安装依赖 首先安装 qemu-5.2.0 所需的依赖，这里追加一个小提示： CentOS7 编译安装软件时经常需要安装对应的依赖。编译过程中如果发现缺少依赖，则编译后报错并退出，这时候就需要安装依赖包。以qemu-5.2.0安装为例，编译时提示缺少 glib2 包。这时候不是下载 glib2，而是下载对应的开发包，CentOS里是 glib2-devel，Ubuntu 下则是 glib2-dev。 yum install -y pkgconfig-devel glib2-devel pixman-devel 这里提供的依赖可能补全，编译过程中如果提示缺少依赖，请根据以上给出的提示安装对应依赖。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:7:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"下载 qemu-5.2.0 在 qemu 官网下载源码包 wget https://download.qemu.org/qemu-5.2.0.tar.xz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:8:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"编译安装 tar xvJf qemu-5.2.0.tar.xz cd qemu-5.2.0 ./configure --enable-debug --target-list=x86_64-softmmu --enable-kvm make \u0026\u0026 make install ","date":"2021-12-03","objectID":"/centos7_install_qemu/:9:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"验证 # qemu- qemu-edid qemu-img qemu-nbd qemu-storage-daemon qemu-ga qemu-io qemu-pr-helper qemu-system-x86_64 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:10:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"CentOS下kvm安装 注：运行kvm保证机器支持虚拟化且在bios中开启。 准备工作 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:0:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"清除iptables规则 # CentOS6 service iptables stop; service iptables save # CentOS7 systemctl stop firewalld ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:1:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"关闭selinux sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config setenforce 0 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:2:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"检测系统是否支持虚拟化 grep -Ei 'vmx|svm' /proc/cpuinfo 如果有输出内容，则支持，其中intel cpu支持会有vmx，amd cpu支持会有svm 安装 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:3:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"执行安装命令 yum install -y kvm virt-* libvirt bridge-utils qemu-img 说明： kvm:软件包中含有KVM内核模块，它在默认linux内核中提供kvm管理程序 libvirt:安装虚拟机管理工具，使用virsh等命令来管理和控制虚拟机。 bridge-utils:设置网络网卡桥接。 virt-*:创建、克隆虚拟机命令，以及图形化管理工具virt-manager qemu-img:安装qemu组件，使用qemu命令来创建磁盘等。 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:4:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"检查kvm模块是否加载 lsmod |grep kvm 结果输出： kvm_intel 55496 3 kvm 337772 1 kvm_intel 如果没有，需要执行，还没有就重启一下试试 modprobe kvm-intel ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:5:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"配置网卡 cd /etc/sysconfig/network-scripts/ cp ifcfg-eth0 ifcfg-br0 编辑eth0 DEVICE=eth0 HWADDR=00:0C:29:55:A7:0A TYPE=Ethernet UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none BRIDGE=br0 编辑br0 DEVICE=br0 #HWADDR=00:0C:29:55:A7:0A TYPE=Bridge #UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=192.168.11.17 NETMASK=255.255.255.0 GATEWAY=192.168.11.1 DNS1=202.106.0.20 记得重启网卡：/etc/init.d/network restart br0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet addr:192.168.11.17 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:141326 errors:0 dropped:0 overruns:0 frame:0 TX packets:90931 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:456024940 (434.8 MiB) TX bytes:10933593 (10.4 MiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:341978 errors:0 dropped:0 overruns:0 frame:0 TX packets:90946 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:468848861 (447.1 MiB) TX bytes:10934699 (10.4 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) virbr0 Link encap:Ethernet HWaddr 52:54:00:14:EF:D5 inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:6:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"启动服务 /etc/init.d/libvirtd start /etc/init.d/messagebus restart 此时可以查看网络接口列表 $ brctl show bridge name bridge id STP enabled interfaces br0 8000.000c2955a70a no eth0 virbr0 8000.52540014efd5 yes virbr0-nic 创建虚拟机 创建一个存储虚拟机虚拟磁盘的目录，该目录所在分区必须足够大 mkdir /data/ 执行命令： virt-install \\ --name ping \\ --ram 512 \\ --disk path=/data/ping.img,size=20 \\ --vcpus 1 \\ --os-type linux \\ --os-variant rhel6 \\ --network bridge=br0 \\ --graphics none \\ --console pty,target_type=serial \\ --location 'http://mirrors.163.com/centos/6.8/os/x86_64/' \\ --extra-args 'console=ttyS0,115200n8 serial' 说明： –name 指定虚拟机的名字 –ram 指定内存分配多少 –disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –vcpus 指定分配cpu几个 –os-type 指定系统类型为linux –os-variant 指定系统版本 –network 指定网络类型 –graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 –console 指定控制台类型 –location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS 之后就出现： 开始安装...... 搜索文件 .treeinfo...... | 720 B 00:00 ... 搜索文件 vmlinuz...... | 7.7 MB 00:02 ... 搜索文件 initrd.img...... | 63 MB 00:23 ... 创建存储文件 ping.img | 30 GB 00:00 创建域...... | 0 B 00:00 连接到域 ping Escape character is ^] 然后就是我们非常熟悉的OK or Next 了 ，只不过这个过程是文本模式，如果想使用图形，只能开启vnc啦 最后安装完，reboot就进入刚刚创建的虚拟机了。要想退回到宿主机，ctrl + ] 即可。 virsh list 可以列出当前的子机列表。 virsh start ping 开启子机 virsh console ping 可以进入指定的子机 使用python管理API ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:7:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装相关包 yum install libvirt-devel ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:8:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装python的libvirt库 pip install libvirt-python libvirt ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:9:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"测试 import libvirt conn = libvirt.open(\"qemu:///system\") ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:10:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"远程管理 直接上述安装还只能在本地使用python管理。如果还需要远程管理的话还要额外的配置。 修该配置文件/etc/libvirt/libvirtd.conf ###/etc/libvirt/libvirtd.conf listen_tls = 0　#禁用tls登录 listen_tcp = 1　#启用tcp方式登录 tcp_port = \"16509\"　#tcp端口16509 listen_addr = \"0.0.0.0\" unix_sock_group = \"libvirtd\" unix_sock_rw_perms = \"0770\" auth_unix_ro = \"none\" auth_unix_rw = \"none\" auth_tcp = \"none\"　#TCP不使用认证 max_clients = 1024　#最大总的连接客户数1024 min_workers = 50　#libvirtd启动时，初始的工作线程数目 max_workers = 200　#同上，最大数目 max_requests = 1000　#最大同时支持的RPC调用，必须大于等于max_workers max_client_requests = 200　#每个客户端支持的最大连接数 修改配置文件/etc/sysconfig/libvirtd： LIBVIRTD_ARGS=\"--listen\" 重启服务后libvirtd会绑定在16509端口 在远程的机器上安装python库 yum install libvirt-devel python-devel # 要先安装libvirt-devel包，因为libvirt-python依赖于libvirt-devel pip install libvirt libvirt-python 测试代码： import libvirt conn = libvirt.open(\"qemu+tcp://192.168.11.17/system\") 没有报错，安装完毕。 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:11:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"Containerd源码分析 从 Kubernetes 1.22 开始，k8s 的容器运行是默认替换成 containerd。有必要深入了解 containerd 的内部实现原理。本篇通过分析 containerd 的代码深入理解其内部原理。 使用的版本为 containerd 1.5。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"配置环境 下载 containerd 源码: git clone github.com/containerd/containerd 启动 goland 的远程调试功能 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:1:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"入口 先来从 main 函数来看启动流程。从以下目录结构中可以看出来，containerd 项目目录中包含一个守护进程和对应的执行工具。 cmd ├── containerd // containerd CRI 实现，对外提供容器服务，对内和 containerd-shim-runc 通讯 ├── containerd-shim ├── containerd-shim-runc-v1 // 负责和 runc 通信，管理容器实例 ├── containerd-shim-runc-v2 // v2 版本 ├── containerd-stress ├── ctr // containerd 客户端命令行工具 ├── gen-manpages └── protoc-gen-gogoctrd 以下是它们之间的调用流程图: ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:2:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"containerd containerd 本身是一个命令行工具实现，入口文件为 cmd/containerd/main.go func main() { app := command.App() if err := app.Run(os.Args); err != nil { fmt.Fprintf(os.Stderr, \"containerd: %s\\n\", err) os.Exit(1) } } ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"command app containerd 包含三个子命令: configCommand: 输出 containerd 默认配置文件 publishCommand: 向 containerd 服务发布一个事件 ociHook: 启动一个 oci 钩子 app.Action 中定义了 containerd 的启动流程： ... app.Action = func(context *cli.Context) error { ... // 加载配置文件 configPath := context.GlobalString(\"config\") ... // 通过配置文件创建 server，server 中包含 ttrpc、grpc、tcp、metrics server, err := server.New(ctx, config) ... ... // 启动 ttrpc 服务 serve(ctx, tl, server.ServeTTRPC) ... if config.GRPC.TCPAddress != \"\" { l, err := net.Listen(\"tcp\", config.GRPC.TCPAddress) if err != nil { return errors.Wrapf(err, \"failed to get listener for TCP grpc endpoint\") } // 启动 tcp 服务 serve(ctx, l, server.ServeTCP) } ... // 启动 grpc 服务 serve(ctx, l, server.ServeGRPC) ... return nil } ... 再来看 server.New，它创建 containerd 服务: func New(ctx context.Context, config *srvconfig.Config) (*Server, error) { ... // 从配置文件中加载插件 plugins, err := LoadPlugins(ctx, config) if err != nil { return nil, err } ... // 循环确认插件类型，并解析。 for _, p := range plugins { id := p.URI() reqID := id if config.GetVersion() == 1 { reqID = p.ID } log.G(ctx).WithField(\"type\", p.Type).Infof(\"loading plugin %q...\", id) initContext := plugin.NewContext( ctx, p, initialized, config.Root, config.State, ) initContext.Events = s.events initContext.Address = config.GRPC.Address initContext.TTRPCAddress = config.TTRPC.Address // load the plugin specific configuration if it is provided if p.Config != nil { pc, err := config.Decode(p) if err != nil { return nil, err } initContext.Config = pc } result := p.Init(initContext) if err := initialized.Add(result); err != nil { return nil, errors.Wrapf(err, \"could not add plugin result to plugin set\") } instance, err := result.Instance() if err != nil { if plugin.IsSkipPlugin(err) { log.G(ctx).WithError(err).WithField(\"type\", p.Type).Infof(\"skip loading plugin %q...\", id) } else { log.G(ctx).WithError(err).Warnf(\"failed to load plugin %s\", id) } if _, ok := required[reqID]; ok { return nil, errors.Wrapf(err, \"load required plugin %s\", id) } continue } delete(required, reqID) // check for grpc services that should be registered with the server if src, ok := instance.(plugin.Service); ok { grpcServices = append(grpcServices, src) } if src, ok := instance.(plugin.TTRPCService); ok { ttrpcServices = append(ttrpcServices, src) } if service, ok := instance.(plugin.TCPService); ok { tcpServices = append(tcpServices, service) } s.plugins = append(s.plugins, result) } // 注册服务 // register services after all plugins have been initialized for _, service := range grpcServices { if err := service.Register(grpcServer); err != nil { return nil, err } } for _, service := range ttrpcServices { if err := service.RegisterTTRPC(ttrpcServer); err != nil { return nil, err } } for _, service := range tcpServices { if err := service.RegisterTCP(tcpServer); err != nil { return nil, err } } return s, nil } 由此可知，containerd 中的服务都是通过插件加载的，插件的加载代码统一存放在 cmd/containerd/containerd 目录下的 builtins*.go 文件中。 其中包含以下几种服务: container content diff images events introspection leases namespaces snapshots tasks ttrpc version 具体的代码存放在 services 目录下，接下来我们来看 images 和 container 这两个最重要的服务。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:1","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"镜像操作 containerd 作为 docker 的替代者，理所当然的需要实现 docker 的核心功能 OCI。images 服务包含: Get : 通过名称获取单个镜像 List : 获取镜像列表 Create : 创建一个镜像 Update : 更新镜像 Delete : 通过名称删除镜像 具体代码请看 services/images/local.go: // 初始化，注册成插件 func init() { plugin.Register(\u0026plugin.Registration{ Type: plugin.ServicePlugin, // 插件类型 ID: services.ImagesService, // 插件名称 Requires: []plugin.Type{ plugin.MetadataPlugin, // 依赖的插件 plugin.GCPlugin, }, InitFn: func(ic *plugin.InitContext) (interface{}, error) { // 初始化方法 m, err := ic.Get(plugin.MetadataPlugin) // 获取 plugin.MetadataPlugin 插件，作为存储，内部使用 bblot 实现 if err != nil { return nil, err } g, err := ic.Get(plugin.GCPlugin) // GC 插件，用于资源回收 if err != nil { return nil, err } return \u0026local{ store: metadata.NewImageStore(m.(*metadata.DB)), publisher: ic.Events, // 内部的订阅发布模型 gc: g.(gcScheduler), // gc 调度器 }, nil }, }) } // images 服务的具体实现 type local struct { store images.Store // 内部存储器 gc gcScheduler // gc 调度器 publisher events.Publisher // 内部的订阅发布模型 } var _ imagesapi.ImagesClient = \u0026local{} ... 这里我们可以把 images 的操作分为读取和修改两组。Get 和 List 为读取操作，就是从数据库中读取相关记录。 ... func (l *local) Get(ctx context.Context, req *imagesapi.GetImageRequest, _ ...grpc.CallOption) (*imagesapi.GetImageResponse, error) { image, err := l.store.Get(ctx, req.Name) if err != nil { return nil, errdefs.ToGRPC(err) } imagepb := imageToProto(\u0026image) return \u0026imagesapi.GetImageResponse{ Image: \u0026imagepb, }, nil } func (l *local) List(ctx context.Context, req *imagesapi.ListImagesRequest, _ ...grpc.CallOption) (*imagesapi.ListImagesResponse, error) { images, err := l.store.List(ctx, req.Filters...) if err != nil { return nil, errdefs.ToGRPC(err) } return \u0026imagesapi.ListImagesResponse{ Images: imagesToProto(images), }, nil } ... Create、Update 和 Delete 是修改操作，核心是通过 events.Publisher 发布事件对应的事件 // services/images/local.go func (l *local) Create(ctx context.Context, req *imagesapi.CreateImageRequest, _ ...grpc.CallOption) (*imagesapi.CreateImageResponse, error) { ... if err := l.publisher.Publish(ctx, \"/images/create\", \u0026eventstypes.ImageCreate{ Name: resp.Image.Name, Labels: resp.Image.Labels, }); err != nil { return nil, err } ... return \u0026resp, nil } 而真正处理该事件的订阅者则是 containerd 实现的 CRI 接口服务 。 // pkg/cri/server/service.go ... // criService implements CRIService. type criService struct { ... } ... cri 启动时，订阅 containerd 事件，并启动事件处理协程: // pkg/cri/server/service.go // Run starts the CRI service. func (c *criService) Run() error { logrus.Info(\"Start subscribing containerd event\") c.eventMonitor.subscribe(c.client) ... // Start event handler. logrus.Info(\"Start event monitor\") eventMonitorErrCh := c.eventMonitor.start() ... } eventMonitor.start() 内部处理逻辑如下: func (em *eventMonitor) start() \u003c-chan error { ... go func() { defer close(errCh) for { select { case e := \u003c-em.ch: logrus.Debugf(\"Received containerd event timestamp - %v, namespace - %q, topic - %q\", e.Timestamp, e.Namespace, e.Topic) if e.Namespace != constants.K8sContainerdNamespace { logrus.Debugf(\"Ignoring events in namespace - %q\", e.Namespace) break } id, evt, err := convertEvent(e.Event) if err != nil { logrus.WithError(err).Errorf(\"Failed to convert event %+v\", e) break } if em.backOff.isInBackOff(id) { logrus.Infof(\"Events for %q is in backoff, enqueue event %+v\", id, evt) em.backOff.enBackOff(id, evt) break } if err := em.handleEvent(evt); err != nil { logrus.WithError(err).Errorf(\"Failed to handle event %+v for %s\", evt, id) em.backOff.enBackOff(id, evt) } case err := \u003c-em.errCh: ... case \u003c-backOffCheckCh: ... } } }() return errCh } namespace 不为 k8s.io 时事件都会被忽略。 criService 一共处理五类事件: TaskExit TaskOOM ImageCreate ImageUpdate ImageDelete // pkg/cri/server/event.go // handleEvent handles a containerd event. func (em *eventMonitor) handleEvent(any interface{}) error { ... switch e := any.(type) { case *eventtypes.TaskExit: ... case *eventtypes.TaskOOM: ... case *eventtypes.ImageCreate: logrus.Infof(\"ImageCreate event %+v\", e) return em.c.updateImage(ctx, e.Name) case *eventtypes.ImageUpdate: logrus.Infof(\"ImageUpdate event %+v\", e) return e","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"容器操作 介绍完镜像操作后，接下来就是关于容器部分的操作。以下我们通过一段代码来探究 containerd 内部的容器管理方式: package main import ( \"context\" \"log\" \"syscall\" \"github.com/containerd/containerd\" \"github.com/containerd/containerd/cio\" \"github.com/containerd/containerd/namespaces\" \"github.com/containerd/containerd/oci\" ) func main() { client, err := containerd.New(\"/run/containerd/containerd.sock\", containerd.WithDefaultNamespace(\"default\")) if err != nil { log.Fatal(err) } defer client.Close() ctx := context.Background() log.Println(\"get image\") img, err := client.GetImage(ctx, \"docker.io/library/redis:alpine3.14\") if err != nil { log.Fatal(err) } log.Println(\"new container\") ctx = namespaces.WithNamespace(ctx, \"default\") c, err := client.NewContainer(ctx, \"redis\", containerd.WithNewSnapshot(\"redis-rootfs\", img), containerd.WithNewSpec(oci.WithImageConfig(img)), ) if err != nil { log.Fatalf(\"new container: %v\", err) } defer c.Delete(ctx) log.Println(\"new task\") task, err := c.NewTask(ctx, cio.NewCreator(cio.WithStdio)) if err != nil { log.Fatal(err) } pid := task.Pid() log.Printf(\"redis running in pid=%d\\n\", pid) err = task.Start(ctx) if err != nil { log.Fatalf(\"start task: %v\", err) } err = task.Kill(ctx, syscall.SIGINT) if err != nil { log.Fatalf(\"kill task: %v\", err) } for { status, _ := task.Status(ctx) if status.Status == containerd.Stopped { break } } _, err = task.Delete(ctx) if err != nil { log.Fatalf(\"delete task: %v\", err) } } containerd 中创建一个容器之后，如果要运行这个容器，就需要创建一个 task 用来管理容器的生命周期。可以理解为 task 就是 containerd 的运行时。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"创建 创建容器如下: // services/containers/local.go func (l *local) Create(ctx context.Context, req *api.CreateContainerRequest, _ ...grpc.CallOption) (*api.CreateContainerResponse, error) { var resp api.CreateContainerResponse if err := l.withStoreUpdate(ctx, func(ctx context.Context) error { container := containerFromProto(\u0026req.Container) created, err := l.Store.Create(ctx, container) if err != nil { return err } resp.Container = containerToProto(\u0026created) return nil }); err != nil { return \u0026resp, errdefs.ToGRPC(err) } if err := l.publisher.Publish(ctx, \"/containers/create\", \u0026eventstypes.ContainerCreate{ ID: resp.Container.ID, Image: resp.Container.Image, Runtime: \u0026eventstypes.ContainerCreate_Runtime{ Name: resp.Container.Runtime.Name, Options: resp.Container.Runtime.Options, }, }); err != nil { return \u0026resp, err } return \u0026resp, nil } 逻辑很简单，就是保存数据到内部存储中，再发布创建容器的事件。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:1","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"启动 启动容器需要先创建一个 task，使用 task 来管理容器 // services/tasks/local.go ... func (l *local) Create(ctx context.Context, r *api.CreateTaskRequest, _ ...grpc.CallOption) (*api.CreateTaskResponse, error) { ... // 创建容器运行时 c, err := rtime.Create(ctx, r.ContainerID, opts) if err != nil { return nil, errdefs.ToGRPC(err) } if err := l.monitor.Monitor(c); err != nil { return nil, errors.Wrap(err, \"monitor task\") } return \u0026api.CreateTaskResponse{ ContainerID: r.ContainerID, Pid: c.PID(), }, nil } // runtime/v2/manager.go // Create a new task func (m *TaskManager) Create(ctx context.Context, id string, opts runtime.CreateOpts) (_ runtime.Task, retErr error) { // 在磁盘上新建一个约束目录 bundle, err := NewBundle(ctx, m.root, m.state, id, opts.Spec.Value) ... // 创建启动一个 containerd-shim-runc-v2 管理容器运行时 shim, err := m.startShim(ctx, bundle, id, opts) ... // 创建一个 task t, err := shim.Create(ctx, opts) ... // 添加 task if err := m.tasks.Add(ctx, t); err != nil { return nil, errors.Wrap(err, \"failed to add task\") } return t, nil } 内部维护一个 TaskManager 来管理 tasks // runtime/v2/manager.go // TaskManager manages v2 shim's and their tasks type TaskManager struct { root string state string containerdAddress string containerdTTRPCAddress string tasks *runtime.TaskList events *exchange.Exchange containers containers.Store } containerd 服务和 containerd-shim-runc-v2 使用 ttrpc 通讯。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:2","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"停止 如何停止一个容器呢? // services/tasks/local.go func (l *local) Kill(ctx context.Context, r *api.KillRequest, _ ...grpc.CallOption) (*ptypes.Empty, error) { t, err := l.getTask(ctx, r.ContainerID) if err != nil { return nil, err } p := runtime.Process(t) if r.ExecID != \"\" { if p, err = t.Process(ctx, r.ExecID); err != nil { return nil, errdefs.ToGRPC(err) } } if err := p.Kill(ctx, r.Signal, r.All); err != nil { return nil, errdefs.ToGRPC(err) } return empty, nil } // runtime/v2/shim.go func (s *shim) Kill(ctx context.Context, signal uint32, all bool) error { if _, err := s.task.Kill(ctx, \u0026task.KillRequest{ ID: s.ID(), Signal: signal, All: all, }); err != nil { return errdefs.FromGRPC(err) } return nil } 从 containerd tasks 服务中获取 tasks 信息，然后通过 ttrpc 连接 containerd-shim-runc-v2 并杀死进程。 containerd-shim-runc-v2 支持以下接口 Create Delete Exec State Pause Resume Kill Pids CloseIO CheckPoint Update ResizePty ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:3","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"插件机制 containerd 内部服务都是通过插件方式注册。注册插件代码如下: // services/server/tasks/local.go func init() { plugin.Register(\u0026plugin.Registration{ Type: plugin.ServicePlugin, ID: services.TasksService, Requires: tasksServiceRequires, InitFn: initFunc, }) timeout.Set(stateTimeout, 2*time.Second) } containerd 内部维护一个全局插件列表: // plugin/plugin.go var register = struct { sync.RWMutex r []*Registration }{} 对外提供三种方法: Load : 通过路径加载插件 Register : 注册插件 Graph : 遍历插件列表 注册的插件在 containerd 服务启动时初始化: // services/server/server.go // New creates and initializes a new containerd server func New(ctx context.Context, config *srvconfig.Config) (*Server, error) { ... for _, p := range plugins { id := p.URI() reqID := id if config.GetVersion() == 1 { reqID = p.ID } log.G(ctx).WithField(\"type\", p.Type).Infof(\"loading plugin %q...\", id) // 新建插件上下文结构体 initContext := plugin.NewContext( ctx, p, initialized, config.Root, config.State, ) initContext.Events = s.events initContext.Address = config.GRPC.Address initContext.TTRPCAddress = config.TTRPC.Address // 加载配置参数 if p.Config != nil { pc, err := config.Decode(p) if err != nil { return nil, err } initContext.Config = pc } // 插件初始化 result := p.Init(initContext) if err := initialized.Add(result); err != nil { return nil, errors.Wrapf(err, \"could not add plugin result to plugin set\") } // 获取插件实例 instance, err := result.Instance() if err != nil { if plugin.IsSkipPlugin(err) { log.G(ctx).WithError(err).WithField(\"type\", p.Type).Infof(\"skip loading plugin %q...\", id) } else { log.G(ctx).WithError(err).Warnf(\"failed to load plugin %s\", id) } if _, ok := required[reqID]; ok { return nil, errors.Wrapf(err, \"load required plugin %s\", id) } continue } delete(required, reqID) // 根据插件类型，加载成不同的服务 if src, ok := instance.(plugin.Service); ok { grpcServices = append(grpcServices, src) } if src, ok := instance.(plugin.TTRPCService); ok { ttrpcServices = append(ttrpcServices, src) } if service, ok := instance.(plugin.TCPService); ok { tcpServices = append(tcpServices, service) } s.plugins = append(s.plugins, result) } ... return s, nil } 插件初始化函数需要 InitContext。 // InitContext is used for plugin inititalization type InitContext struct { Context context.Context Root string State string Config interface{} Address string TTRPCAddress string Events *exchange.Exchange Meta *Meta // plugins can fill in metadata at init. plugins *Set } InitContext 中携带的 plugins 变量指向全局插件集合。结构体中保存插件初始化所需的参数，包括 Root : containerd 项目的根目录，从配置文件中获取。（默认为 /var/lib/containerd） State : containerd 运行过程中数据的存放目录，从配置文件中获取，(默认为 /run/containerd) Config : 配置文件 Address : gRPC 地址 TTRPCAddress: ttrpc 地址 Events: 全局的订阅发布模型 // plugin/context.go // Plugin represents an initialized plugin, used with an init context. type Plugin struct { Registration *Registration // registration, as initialized Config interface{} // config, as initialized Meta *Meta instance interface{} err error // will be set if there was an error initializing the plugin } 每个服务使用 Plugin 封装，插件的信息保存到 Registration 中: // plugin/plugin.go // Registration contains information for registering a plugin type Registration struct { // Type of the plugin Type Type // ID of the plugin ID string // Config specific to the plugin Config interface{} // Requires is a list of plugins that the registered plugin requires to be available Requires []Type // InitFn is called when initializing a plugin. The registration and // context are passed in. The init function may modify the registration to // add exports, capabilities and platform support declarations. InitFn func(*InitContext) (interface{}, error) // Disable the plugin from loading Disable bool } Registration 包含插件类型，插件ID，配置参数，依赖的其他插件类型，初始化函数。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:6:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"Dblink 查询所有触发器 select*fromuser_triggers; 根据名称禁用触发器 altertriggerLOGMNRGGC_TRIGGERdisable; 查询所有 job select*fromuser_jobs; 根据 id 禁用 job BEGINdbms_job.broken(4001,true);END; 禁用 oracle dblink altersystemsetopen_links=0sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=0sid='$sid'scope=spfile; 启用 oracle dblink altersystemsetopen_links=4sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=4sid='$sid'scope=spfile; ","date":"2021-12-03","objectID":"/dblink/:0:0","tags":null,"title":"Dblink","uri":"/dblink/"},{"categories":null,"content":"Docker容器和网络架构设计 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:0:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"常用的容器化技术 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Chroot 特点: 改变正在运行的进程和它的子进程根目录。 经chroot设置根目录的程序，不能够对这个指定根目录之外的文件进行访问和读取，也不能写操作。 原理: 修改PCB实现限制功能 (PCB: process control block) 缺点: 隔离文件系统 但是无法限制 CPU, 内存, 网络端口号的命名空间 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:1","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Jails 特点： 基于Chroot的操作系统层虚拟化技术。 只能访问某个部分的文件系统，但是FreeBSD jail机制限制了在软件监狱中运作的行程，不能够影响操作系统的其他部分 场景： 虚拟化 安全性 易维护 缺点: 使用复杂 隔离级别较弱 出现沙盒概念 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:2","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Linux vserver / openVZ 特点: 类似Jails机制，可以对计算机系统上的资源（文件系统、网络地址、内存）进行分区 Linux操作系统级虚拟化技术，它通过Linux内核补丁形式进行虚拟化、隔离、资源管理和状态检查 优点: 资源隔离性(CPU超卖，内存共享) 缺点: 隔离级别较弱 进一步强化沙盒概念。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:3","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"LXC 特点: linux 自带功能，几乎没有额外的性能损耗。 轻量级的 “虚拟化 “方法，同时运行多个虚拟单元。 容器是用内核控制组（cgroups）和内核命名空间来隔离的。 优势 通过容器隔离应用程序和操作系统 通过LXC实时管理资源的分配，提供近乎原生的性能。 通过cgroups控制网络接口和应用容器内的资源。 缺陷 所有LXC容器都使用相同的内核。 只能在Linux操作系统运行。 LXC 并不安全，安全性取决于主机系统。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:4","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"cgroup 和 namespace Cgroups: 用于限制和隔离一组进程对系统资源的使用 对不同资源的具体管理是由各个子系统分工完成的 Namespace: 内核全局资源的封装 每个namespace是一份独立的资源 不同进程在各自namespace中对同一种资源的使用互不干扰 常用的namespace有IPC、Network、Mount、PID、User和UTC  ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:5","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"docker 的架构和原理 容器技术的目标 提高系统资源利用率 提高进程运行稳定性 docker 之前的解决方案: 虚拟化解决方案 软件虚拟化 硬件虚拟化 虚拟化方案提高了进程稳定性，一定程度提高了资源利用率。但仍然有很大程度的资源浪费(虚拟化成本) 容器化解决方案:在操作系统层面实现资源隔离 OpenVZ LXC Process Container(cgroups) 均衡了资源利用率和稳定性。 稳定性比虚拟化差，但资源利用率比虚拟化高，适合分布式环境。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:2:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Docker 网络架构和原理 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"网络基础知识 Lan/VLan/VXLan: LAN (Local Area Network)本地局域网 VLAN(Virtual Local Area Network)虚拟本地局域网 VXLAN(Virtual eXtensible Local Area Network) 在一套物理网络设备上虚拟出多个二层网络 VXLAN: VLAN ID数量限制 交换机MAC地址表限制 灵活的虚机部署和部署 复用网络链路 桥接: 从一个网卡设备发出的以太帧，原封不动地到达另外一个网卡设备。 将多个广播域组合成一个广播域，在链路层允许设备互联。 桥接与路由的区别: 分割广播域 桥接无法控制广播在不同物理接口之间的穿梭。广播嘈杂，对主机的干扰程度严重。 路由可以将某些主机放在一个广播域，将另外一些主机放在另外的广播域。 控制网络流量 不同协议类型的物理接口，只能使用路由。 二层封装方式不一样，桥接无法解析数据。路由器可以替换二层数据帧 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:1","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"docker 跨主机互访方案 Bridge Host Overlay Flannel ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:2","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Flask与Vue的token认证 后端使用flask设计基于token认证方式的restful接口，前端使用vue.js全家桶，利用axios通讯。 感谢两篇文章的作者： http://www.cnblogs.com/vovlie/p/4182814.html https://segmentfault.com/a/1190000008383094?_ea=1639495 源码链接：https://github.com/xingyys/flaskvue 后端Flask Flask采用token认证方式，主要思路是通过/api/login登录获取token，然后使用token调用各个接口。 所用到框架的库： flask flask-cors：flask跨域 flask-sqlachemy: flask数据库orm flask-httpauth：flask的auth认证 passlib: python密码解析库 itsdangerous ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:0:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"后端结构图 flask/ ├── app # 主目录 │ ├── __init__.py │ ├── __init__.pyc │ ├── models.py # 数据库 │ ├── models.pyc │ ├── views.py # 视图 │ └── views.pyc ├── config.py # 配置信息 ├── config.pyc ├── db_create.py # 创建数据库 ├── db_migrate.py # 更新数据库 ├── db_repository │ ├── __init__.py │ ├── __init__.pyc │ ├── manage.py │ ├── migrate.cfg │ ├── README │ └── versions │ ├── 008_migration.py │ ├── 008_migration.pyc │ ├── 009_migration.py │ ├── 009_migration.pyc │ ├── __init__.py │ └── __init__.pyc ├── index.html └── run.py # app的运行文件 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:1:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"具体实现 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"系统初始化app/__init__.py # -*- coding:utf-8 -*- from flask import Flask from flask_sqlalchemy import SQLAlchemy from flask_httpauth import HTTPBasicAuth from flask_cors import CORS app = Flask(__name__) # flask的跨域解决 CORS(app) app.config.from_object('config') db = SQLAlchemy(app) auth = HTTPBasicAuth() from . import models, views ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:1","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"配置文件config.py import os basedir = os.path.abspath(os.path.dirname(__file__)) SQLALCHEMY_DATABASE_URI = \"mysql://root:123456@127.0.0.1/rest\" SQLALCHEMY_MIGRATE_REPO = os.path.join(basedir, 'db_repository') SQLALCHEMY_TRACK_MODIFICATIONS = True BASEDIR = basedir # 安全配置 CSRF_ENABLED = True SECRET_KEY = 'jklklsadhfjkhwbii9/sdf\\sdf' 环境中使用mysql数据库，版本为mariadb 10.1.22。创建rest表 $ mysql -uroot -p xxxxxx $ create database rest default charset utf8; ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:2","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"创建数据库表app/models.py # -*- coding:utf-8 -*- from app import db, app from passlib.apps import custom_app_context from itsdangerous import TimedJSONWebSignatureSerializer as Serializer, SignatureExpired, BadSignature class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(32), index=True) password = db.Column(db.String(128)) # 密码加密 def hash_password(self, password): self.password = custom_app_context.encrypt(password) # 密码解析 def verify_password(self, password): return custom_app_context.verify(password, self.password) # 获取token，有效时间10min def generate_auth_token(self, expiration = 600): s = Serializer(app.config['SECRET_KEY'], expires_in = expiration) return s.dumps({ 'id': self.id }) # 解析token，确认登录的用户身份 @staticmethod def verify_auth_token(token): s = Serializer(app.config['SECRET_KEY']) try: data = s.loads(token) except SignatureExpired: return None # valid token, but expired except BadSignature: return None # invalid token user = User.query.get(data['id']) return user 创建数据库users表： $ python db_create.py $ python db_migrate.py ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:3","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"视图app/views.py from app import app, db, auth from flask import render_template, json, jsonify, request, abort, g from app.models import * @app.route(\"/\") @auth.login_required def index(): return jsonify('Hello, %s' % g.user.username) @app.route('/api/users', methods = ['POST']) def new_user(): username = request.json.get('username') password = request.json.get('password') if username is None or password is None: abort(400) # missing arguments if User.query.filter_by(username = username).first() is not None: abort(400) # existing user user = User(username = username) user.hash_password(password) db.session.add(user) db.session.commit() return jsonify({ 'username': user.username }) @auth.verify_password def verify_password(username_or_token, password): if request.path == \"/api/login\": user = User.query.filter_by(username=username_or_token).first() if not user or not user.verify_password(password): return False else: user = User.verify_auth_token(username_or_token) if not user: return False g.user = user return True @app.route('/api/login') @auth.login_required def get_auth_token(): token = g.user.generate_auth_token() return jsonify(token) 用户注册后密码加密存储，确认用户身份时密码解密。需要认证的api上添加@auth.login_required，它会在调用接口之前调用@auth.verify_password下的方法(此方法唯一)如verify_password。根据请求的路径选择不同的认证方式。 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:4","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"测试 使用curl命令测试接口 注册用户: $ curl -i -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"123456\"}' http://127.0.0.1:5000/api/register HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 26 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:33:46 GMT { \"username\": \"admin\" } 查看数据库： MariaDB [rest]\u003e select * from users\\G; *************************** 1. row *************************** id: 1 username: admin password: $6$rounds=656000$etV4F3xLL0dwflX8$mLFX9l5dumBnQFtajGmey346viGuQ4bxR7YhQdKtB/nQH9ij2e3HHMEBPj.ef/o//4o9P2Wd3Y7dxQfjwR2hY/ 1 row in set (0.00 sec) 获取token： curl -i -u admin:123456 -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/api/login HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 125 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:37:01 GMT \"eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ\" 使用token调用api： $ curl -i -u eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ:unused -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/ HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 15 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:38:22 GMT \"Hello, admin\" 基于token的Flask api成功！！！！ 前端Vue.js 前端使用vue的全家桶，axios前后端通讯，axios拦截器，localStorage保存token 所使用的框架和库： vue2.0 iview2.X axios vuex vue-router ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:5","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"具体实现 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"main.js // 初始化axios axios.defaults.baseURL = 'http://127.0.0.1:5000' axios.defaults.auth = { username: '', password: '', } // axios.interceptors.request.use((config) =\u003e { // console.log(config) // return config; // }, (error) =\u003e { // return Promise.reject(error) // }) // axios拦截器，401状态时跳转登录页并清除token axios.interceptors.response.use((response) =\u003e { return response; }, (error) =\u003e { if (error.response) { switch (error.response.status) { case 401: store.commit('del_token') router.push('/login') } } return Promise.reject(error.response.data) }) // 路由跳转 router.beforeEach((to, from, next) =\u003e { if (to.meta.required) { // 检查localStorage if (localStorage.token) { store.commit('set_token', localStorage.token) // 添加axios头部Authorized axios.defaults.auth = { username: store.state.token, password: store.state.token, } // iview的页面加载条 iView.LoadingBar.start(); next() } else { next({ path: '/login', }) } } else { iView.LoadingBar.start(); next() } }) router.afterEach((to, from, next) =\u003e { iView.LoadingBar.finish(); }) ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:1","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"路由 export default new Router({ routes: [{ path: '/', name: 'index', component: Index, meta: { required: true, } }, { path: '/login', name: 'login', component: Login, }] }) 路由添加meta字段，作为需要认证路由的标志 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:2","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"vuex export default new Vuex.Store({ state: { token: '' }, mutations: { set_token(state, token) { state.token = token localStorage.token = token }, del_token(state) { state.token = '' localStorage.removeItem('token') } } }) vuex中保存token，同时修改删除token和localStorage.token ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:3","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"登录和登出 登录： handleSubmit(name, form) { this.$refs[name].validate((valid) =\u003e { if (valid) { // 用户名密码简单验证后添加到axios的auth中 this.$axios.defaults.auth = { username: form.username, password: form.password, } this.$axios.get('/api/login').then(response =\u003e { this.$Message.success(\"提交成功\") let data = response.data // 保存token this.$store.commit('set_token', data) this.$router.push('/') }).catch(error =\u003e { this.$Message.error(error.status) }) } else { this.$Message.error('表单验证失败!'); } }) } 登出： logout() { this.$store.commit('del_token') this.$router.push('/login') } 删除token并跳转到登录页 flask和vue的token认证就完成了！！！！ ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:4","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"Go 结合 etcd 关于 etcd 的安装和介绍看 这里 。官方的实例可以看 这里 一、连接 首先是关于 golang 如何连接 etcd ，先是简单的连接。 package main import ( \"github.com/coreos/etcd/clientv3\" \"log\" \"time\" ) func connect() { cli, err := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 还有带 https 和 开启用户验证的连接 func connectTlsAuth() { tlsInfo := transport.TLSInfo{ CertFile: \"/tmp/cert.pem\", KeyFile: \"/tmp/key.pem\", TrustedCAFile: \"/tmp/ca.pem\", } tlsConfig, err := tlsInfo.ClientConfig() if err != nil { log.Fatal(\"parse tls config file: \" + err.Error()) } cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, DialTimeout: time.Second * 3, TLS: tlsConfig, Username: \"root\", Password: \"root\", }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 二、KV 操作 ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:0:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.1 简单的 curd 在连接基础上，接下来就可以对key做操作了。对key做 curd func kv() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl put foo 1 _, err := cli.Put(ctx, \"foo\", \"1\") if err != nil { log.Fatal(\"put key:\" + err.Error()) } // etcdctl get foo --prefix // 带参数的请求 resp, err := cli.Get(ctx, \"foo\", clientv3.WithPrefix()) if err != nil { log.Fatal(\"get key: \" + err.Error()) } for _, v := range resp.Kvs { log.Printf(\"get %s =\u003e %s\\n\", v.Key, string(v.Value)) } kvcli := clientv3.NewKV(cli) // etcdctl del foo _, err = kvcli.Delete(ctx, \"foo\") if err != nil { log.Fatal(\"delete key: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:1:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.2 事务 使用事务如下： func txn() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() kvc := clientv3.NewKV(cli) _, err := kvc.Put(ctx, \"foo\", \"xyz\") if err != nil { log.Fatal(\"put key: \" + err.Error()) } _, err = kvc.Txn(ctx). // txn value comparisons are lexical If(clientv3.Compare(clientv3.Value(\"foo\"), \"\u003e\", \"abc\")). // the \"Then\" runs, since \"xyz\" \u003e \"abc\" Then(clientv3.OpPut(\"foo\", \"XYZ\")). // the \"Else\" does not run Else(clientv3.OpPut(\"foo\", \"ABC\")). Commit() if err != nil { log.Fatal(\"run txn: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:2:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 批量操作 批量指定操作 func do() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() ops := []clientv3.Op{ clientv3.OpPut(\"key1\", \"123\"), clientv3.OpGet(\"key1\"), clientv3.OpPut(\"key2\", \"456\"), } for _, op := range ops { if _, err := cli.Do(ctx, op); err != nil { log.Fatal(err.Error()) } } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:3:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 watch 监视key func watch() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() go func() { timer := time.NewTicker(time.Second) for { select { case \u003c-timer.C: // change foo value every second _, _ = cli.Put(context.TODO(), \"foo\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo1\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo2\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo3\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo4\", time.Now().String()) } } }() //rch := cli.Watch(ctx, \"foo\") rch := cli.Watch(ctx, \"foo\", clientv3.WithPrefix()) //rch := cli.Watch(ctx, \"foo\", clientv3.WithRange(\"foo4\")) for wresp := range rch { for _, ev := range wresp.Events { fmt.Printf(\"%s %q: %q\\n\", ev.Type, ev.Kv.Key, ev.Kv.Value) } } } func watchWithProcessNotify() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() rch := cli.Watch(ctx, \"foo\", clientv3.WithProgressNotify()) wresp := \u003c- rch fmt.Printf(\"wresp.Header.Revision: %d\\n\", wresp.Header.Revision) fmt.Println(\"wresp.IsProgressNotify:\", wresp.IsProgressNotify()) } 三、lease ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:4:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.1 创建 lease func grant() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl lease grant 5 // grant lease 5s resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } // after 5 seconds, the key 'foo' will be removed _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(\"put key with lease: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:5:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.2 删除 lease func revoke() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } // revoking lease expires the key attached to its lease ID _, err = cli.Revoke(ctx, resp.ID) if err != nil { log.Fatal(err) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:6:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 续租 func keepAlive() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } ch, err := cli.KeepAlive(ctx, resp.ID) if err != nil { log.Fatal(err.Error()) } ka := \u003c- ch fmt.Println(\"ttl:\", ka.TTL) // 官方提示：多数情况下使用 KeepAlive 来代替 KeepAliveOnce kaa, err := cli.KeepAliveOnce(ctx, resp.ID) if err != nil { log.Fatal(err) } fmt.Println(\"ttl:\", kaa.TTL) } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:7:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.4 查询 lease func leases() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() _, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 10) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 15) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } resp, err := cli.Lease.Leases(ctx) if err != nil { log.Fatal(err) } for _, lease := range resp.Leases { ttl, err := cli.Lease.TimeToLive(ctx, lease.ID, clientv3.WithAttachedKeys()) if err == nil { fmt.Printf(\"lease: %d, ttl: %d, grantedTTL: %d\\n\", ttl.ID, ttl.TTL, ttl.GrantedTTL) } } } 四、访问控制 func auth() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() auth := clientv3.NewAuth(cli) // create role if _, err := auth.RoleAdd(ctx, \"root\"); err != nil { log.Fatal(err) } // create role if _, err := auth.UserAdd(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } // grant role root to user root if _, err := auth.UserGrantRole(ctx, \"root\", \"root\"); err != nil { log.Fatal(err) } if _, err := auth.UserChangePassword(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } if _, err := auth.RoleAdd(ctx, \"guest\"); err != nil { log.Fatal(err) } if _, err := auth.UserAdd(ctx, \"xingyys\", \"\"); err != nil { log.Fatal(err) } if _, err := auth.UserGrantRole(ctx, \"xingyys\", \"guest\"); err != nil { log.Fatal(err) } // 不知道为什么，需要在grant后更新密码 // 否则密码无效 if _, err := auth.UserChangePassword(ctx, \"xingyys\", \"123\"); err != nil { log.Fatal(err) } // 添加指定key的访问权限 // read, write, readwrite if _, err := auth.RoleGrantPermission(ctx, \"guest\", \"foo\", \"zoo\", clientv3.PermissionType(clientv3.PermReadWrite)); err != nil { log.Fatal(err) } if _, err := auth.AuthEnable(ctx); err != nil { log.Fatal(err) } authCli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, Username: \"xingyys\", Password: \"123\", }) defer authCli.Close() _, _ = authCli.Put(ctx, \"foo\", \"1\") resp, _ := authCli.Get(ctx, \"foo\") for _, v := range resp.Kvs { log.Printf(\"%s =\u003e %q\\n\", v.Key, v.Value) } _, err := authCli.Txn(ctx). If(clientv3.Compare(clientv3.Value(\"zoo1\"), \"\u003e\", \"abc\")). Then(clientv3.OpPut(\"zoo1\", \"XYZ\")). Else(clientv3.OpPut(\"zoo1\", \"ABC\")). Commit() log.Println(err) } 五、集群 func member() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() cluster := clientv3.NewCluster(cli) resp, err := cluster.MemberList(ctx) if err != nil { log.Fatal(err) } for _, member := range resp.Members { fmt.Printf(\"ID: %d | Name: %s | ClientURL: %q | PeerURL: %q\\n\", member.ID, member.Name, member.ClientURLs, member.PeerURLs) } //_, _ = cluster.MemberAdd(ctx, []string{\"192.168.10.10:2370\", \"192.168.10.11:2379\"}) //_, _ = cluster.MemberRemove(ctx, // id) //_, _ = cluster.MemberUpdate(ctx, // id, // peer) } 六、并发 ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:8:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.1 锁 func lock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquired lock for s1 if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") m2Locked := make(chan struct{}) go func() { defer close(m2Locked) // wait util s1 is locks /lock if err := m2.Lock(context.TODO()); err != nil { log.Fatal(err) } }() if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"release lock for s1\") \u003c-m2Locked fmt.Println(\"acquired lock for s2\") } func tryLock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquire lock for s1 if err = m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") if err = m2.TryLock(context.TODO()); err == nil { log.Fatal(\"should not acquire lock\") } if err == concurrency.ErrLocked { fmt.Println(\"cannot acquire lock for s2, as already locked in another session\") } if err = m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"released lock for s1\") if err = m2.TryLock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s2\") } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:9:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.2 领导选举 func election() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // create two separate sessions for election competition s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() e1 := concurrency.NewElection(s1, \"/my-election/\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() e2 := concurrency.NewElection(s2, \"/my-election/\") // create competing candidates, with e1 initially losing to e2 var wg sync.WaitGroup wg.Add(2) electc := make(chan *concurrency.Election, 2) go func() { defer wg.Done() // delay candidacy so e2 wins first time.Sleep(3 * time.Second) if err := e1.Campaign(context.Background(), \"e1\"); err != nil { log.Fatal(err) } electc \u003c- e1 }() go func() { defer wg.Done() if err := e2.Campaign(context.Background(), \"e2\"); err != nil { log.Fatal(err) } electc \u003c- e2 }() cctx, cancel := context.WithCancel(context.TODO()) defer cancel() e := \u003c-electc fmt.Println(\"completed first election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) // resign so next candidate can be elected if err := e.Resign(context.TODO()); err != nil { log.Fatal(err) } e = \u003c-electc fmt.Println(\"completed second election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) wg.Wait() } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:10:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.3 软件事务内存 func stm() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // set up \"accounts\" totalAccounts := 5 for i := 0; i \u003c totalAccounts; i++ { k := fmt.Sprintf(\"accts/%d\", i) if _, err = cli.Put(context.TODO(), k, \"100\"); err != nil { log.Fatal(err) } } exchange := func(stm concurrency.STM) error { from, to := rand.Intn(totalAccounts), rand.Intn(totalAccounts) if from == to { // nothing to do return nil } // read values fromK, toK := fmt.Sprintf(\"accts/%d\", from), fmt.Sprintf(\"accts/%d\", to) fromV, toV := stm.Get(fromK), stm.Get(toK) fromInt, toInt := 0, 0 fmt.Sscanf(fromV, \"%d\", \u0026fromInt) fmt.Sscanf(toV, \"%d\", \u0026toInt) // transfer amount xfer := fromInt / 2 fromInt, toInt = fromInt-xfer, toInt+xfer // write back stm.Put(fromK, fmt.Sprintf(\"%d\", fromInt)) stm.Put(toK, fmt.Sprintf(\"%d\", toInt)) return nil } // concurrently exchange values between accounts var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() if _, serr := concurrency.NewSTM(cli, exchange); serr != nil { log.Fatal(serr) } }() } wg.Wait() // confirm account sum matches sum from beginning. sum := 0 accts, err := cli.Get(context.TODO(), \"accts/\", clientv3.WithPrefix()) if err != nil { log.Fatal(err) } for _, kv := range accts.Kvs { v := 0 fmt.Sscanf(string(kv.Value), \"%d\", \u0026v) sum += v } fmt.Println(\"account sum is\", sum) } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:11:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"Golang使用json格式实现增删查改 需求和思路 在一般的小项目或者一个小软件,例如客户端之类的小程序中,可能会需要数据的持久化.但是使用一般的数据库(Mysql)之类的不合适.使用sqlite3这种嵌入式的是个较好的方法,但是Go语言中sqlite3的库是C语言的,Cgo不支持跨平台编译.正是由于这种需求,才想到使用json格式将数据直接保存在文件中. 具体的思路是怎么样呢? 在Go语言中如果要将数据转化成json格式的话,有两种格式 struct 和 map. 如果同时需要增删查改功能的话,将map作为中间格式是比较合适的.接下来我们就来实现它. 查询操作 这种操作的实现比较简单,直接将文件中的数据读取出来,使用json库反序列化就可以了. 代码如下 : type Product struct { Name string `json:\"name\"` Num int `json:\"num\"` } func findAll() { ps := make([]Product, 0) data, err := ioutil.ReadFile(\"./index.json\") if err != nil { log.Fatal(err) } // 这里参数要指定为变量的地址 err = json.Unmarshal(data, \u0026ps) if err != nil { log.Fatal(err) } fmt.Println(ps) } 添加操作 添加的实现实在查询的基础上的,我们需要先查询文件中的数据库,并转化为map格式,再将struct也转化为map格式(这里要使用反射),合并map,json序列化,最后保存在文件中.代码如下: func create() { fields := make([]map[string]interface{}, 0) p1 := \u0026Product{ Name: \"Blog\", Num: 2, } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 data, _ := ioutil.ReadFile(\"./index.json\") err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") field[key] = field2.Interface() } // 合并map fields = append(fields, field) // 写入文件 out, _ := json.Marshal(fields) _ = ioutil.WriteFile(\"./index.json\", out, 0755) } 条件查询 思路: 将struct转化为map,根据输入的条件查询.查询的结果转化为struct.代码如下: func FindOne() { product := \u0026Product{} p1 := \u0026Product{ Name: \"John\", Num: 23, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field[key] = float64(field2.Interface().(uint)) case reflect.Uint8: field[key] = float64(field2.Interface().(uint8)) case reflect.Uint16: field[key] = float64(field2.Interface().(uint16)) case reflect.Uint32: field[key] = float64(field2.Interface().(uint32)) case reflect.Uint64: field[key] = float64(field2.Interface().(uint64)) case reflect.Float32: field[key] = float64(field2.Interface().(float32)) case reflect.Float64: field[key] = field2.Interface() default: field[key] = field2.Interface() } } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 // 数据转化为map时,数值类型的统一变成float64 data, _ := ioutil.ReadFile(\"./index.json\") fields := make([]map[string]interface{}, 0) err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 查询的条件 columns := []string{\"name\", \"num\"} length := len(columns) for _, item := range fields { for i := 0; i \u003c length; i++ { // 这里的比较需要改进 if item[columns[i]] != field[columns[i]] { break } if i == length-1 { field = item goto OVER } } } OVER: fmt.Println(field) out, _ := json.Marshal(field) _ = json.Unmarshal(out, \u0026product) fmt.Println(product) } 修改操作 修改操作在查询操作的基础上实现, 修改操作需要有一个id值,能确定元素的唯一性.代码如下: func Update() { p1 := \u0026Product{ Id: \"2bbec87025968879c3c9682abe3bf730\", Name: \"John_e\", Num: 100, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field","date":"2021-12-03","objectID":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/:0:0","tags":null,"title":"Golang使用json格式实现增删查改","uri":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/"},{"categories":null,"content":"golang打包和解包 打包 // 打包 func Compress(destPath, srcDir string) error { // 压缩文件路径 fw, err := os.Create(destPath) if err != nil { return err } defer fw.Close() // gzip writer gw := gzip.NewWriter(fw) defer gw.Close() // tar writer tw := tar.NewWriter(gw) defer tw.Close() // 读取要压缩的目录 dir, err := os.Open(srcDir) if err != nil { return err } defer dir.Close() // 读取目录内容 files, err := dir.Readdir(0) if err != nil { return err } for _, file := range files { if file.IsDir() { continue } // 路径补全 filePath := path.Join(dir.Name(), file.Name()) fread, err := os.Open(filePath) if err != nil { continue } // 获取文件头部信息 h := \u0026tar.Header{} h.Name = file.Name() h.Size = file.Size() h.Mode = int64(file.Mode()) h.ModTime = file.ModTime() err = tw.WriteHeader(h) if err == nil { // 开始压缩，这里等于忽略错误 io.Copy(tw, fread) } // 记得关闭文件 fread.Close() } return nil } 解包 // 解压 func DeCompress(srcPath, destDir string) error { // 解压包的路径 fread, err := os.Open(srcPath) if err != nil { return err } defer fread.Close() // 检测目标路径是否存在 _, err = os.Stat(destDir) if err != nil { return err } // gzip reader gr, err := gzip.NewReader(fread) if err != nil { return err } defer gr.Close() // tr reader tr := tar.NewReader(gr) for { // 获取下一个文件 h, err := tr.Next() // 读取完毕 if err == io.EOF { break } if err != nil { continue } fw, err := os.OpenFile(path.Join(destDir, h.Name), os.O_CREATE|os.O_WRONLY, 0644) if err == nil { io.Copy(fw, tr) fw.Close() } } return nil } ","date":"2021-12-03","objectID":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/:0:0","tags":null,"title":"golang打包和解包","uri":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/"},{"categories":null,"content":"Golang监控进程流量 链接 libpcap ","date":"2021-12-03","objectID":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/:0:0","tags":null,"title":"Golang监控进程流量","uri":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/"},{"categories":null,"content":"Golang跨平台编译 golang cgo 到 Windows 的交叉编译 本篇记录在 MaxOS 下 cgo 交叉编译的解决方案。因为在项目中使用 go-sqlite3 ，编译 go-sqlite3 中需要使用到 cgo。在 MacOS 下编译 Go 原生 Linux 和 Windows 的程序使用以下命令： # 交叉编译到 linux GOOS=linux GOARCH=amd64 go build main.go # 交叉编译到 windows GOOS=windows GOARCH=amd64 go build -o main.exe main.go 如果使用 cgo 的话，还需要添加 CGO_ENABLED 参数： CGO_ENABLED=1 GOOS=windows GOARCH=amd64 go build -o main.exe main.go 但是这种编译 go-sqlite3 的代码会出现以下错误： # runtime/cgo gcc_libinit_windows.c:7:10: fatal error: 'windows.h' file not found 因为 Windows 中使用 MinGW，MacOS 下如果交叉编译需要安装 C/C++ 交叉编译工具： brew install FiloSottile/musl-cross/musl-cross brew install mingw-w64 安装完工具之后就可以使用命令： CGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build -a -v -o store.exe store/sqlite.exe 注意参数： CXX=x86_64-w64-mingw32-g++ ，如果缺少这个参数时，可能会出现错误： # runtime/cgo gcc: error: unrecognized command line option ‘-mthreads’; did you mean ‘-pthread’? ","date":"2021-12-03","objectID":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/:0:0","tags":null,"title":"Golang跨平台编译","uri":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"GPRC 实战 注意：当项目中使用了etcd的组件，注意版本控制。etcd低版本的需要grpc v1.2.6 GRPC 简介 grpc 是由 google 开发的一款开源，高性能 rpc（远程进程调用协议）使用 Protocol Buffers 作为数据交换格式。 GRPC 安装 golang 使用 grpc 要安装 grpc-go, protoc 和 对应的插件。 ","date":"2021-12-03","objectID":"/grpc1/:0:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"安装grpc-go go get -u github.com/golang/protobuf/{proto,protoc-gen-go} go get -u google.golang.org/grpc 如果是国内用户无法连接到 google.golang.org 的话可以使用 VPN。或者直接从 github.com 直接下载源代码再编译安装 git clone https://github.com/grpc/grpc-go.git $GOPATH/src/google.golang.org/grpc go get -u google.golang.org/grpc ","date":"2021-12-03","objectID":"/grpc1/:1:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"安装 protoc golang 要使用 grpc，还需要使用 protoc 工具。因为 golang 不能直接识别 .proto 文件，需要使用 protoc 工具将 .proto 转化成 golang 代码。下面介绍几个平台下安装 protobuf 的方法。 ","date":"2021-12-03","objectID":"/grpc1/:2:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"macos macos 下安装直接使用 brew 命令即可。 brew install protobuf ","date":"2021-12-03","objectID":"/grpc1/:2:1","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"linux linux 下需要先从 github.com 下载 protobuf 源码或者二进制文件，下载地址。二进制安装的话就下载 protobuf-all-*.tar.gz 包，解压后进入生成的目录。之后执行命令： make \u0026\u0026 make install ","date":"2021-12-03","objectID":"/grpc1/:2:2","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"windows 下载 protobuf.all-*.zip 包，解压后再配置环境变量，将 protobuf\\bin 配置到 $PATH 变量中。 GRPC使用 ","date":"2021-12-03","objectID":"/grpc1/:2:3","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"新建项目 新建一个 grpc 项目，如下: ../sample └── pb └── echo.proto echo.proto 的内容为: syntax = \"proto3\"; // protobuf 语法版本，默认为 proto2 // // 这个是注释 // .proto 所在的包路径 package sample.pb;option go_package = \"pb\";// EchoRequest grpc 请求报文格式. message EchoRequest { string message = 1;}// EchoResponse grpc 响应报文格式. message EchoResponse { string message = 1;}// 定义 Echo 服务. service Echo { // UnaryEcho 一元请求. rpc UnaryEcho(EchoRequest) returns (EchoResponse) {} // ServerStreamingEcho 服务端 stream 请求. rpc ServerStreamingEcho(EchoRequest) returns (stream EchoResponse) {} // ClientStreamingEcho 客户端 stream 请求. rpc ClientStreamingEcho(stream EchoRequest) returns (EchoResponse) {} // BidirectionalStreamingEcho 双向 stream. rpc BidirectionalStreamingEcho(stream EchoRequest) returns (stream EchoResponse) {}} 执行以下命令将 .proto 转化为 golang 代码: cd sample # protoc -I\u003cimport路径\u003e \u003c...-I$PATH\u003e --go_out=plugins=grpc:\u003c输出路径\u003e *.proto protoc -I. --go_out=plugins=grpc:. pb/echo.proto 简单描述下 protoc 命令的功能。 -I : *.proto 中导入的包的路径，导入的路径为全路径格式。. 表示当前路径。 –go_out=plugins=grpc: ：指定 _.proto 输出的格式和路径，生成 _.go 文件的路径为 和 *.proto 的拼接。执行成功后成为文件 echo.pb.go 文件: ../sample └── pb ├── echo.pb.go └── echo.proto ","date":"2021-12-03","objectID":"/grpc1/:3:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"Server package main import ( \"context\" \"errors\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" \"net\" ) type server struct { pb.EchoServer } // 简单请求 func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: \"echo: \" + request.Message}, nil } // 服务端流式 func (s *server) ServerStreamingEcho(request *pb.EchoRequest, stream pb.Echo_ServerStreamingEchoServer) error { _ = stream.Send(\u0026pb.EchoResponse{Message: \"hello\"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \" \"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \"client\"}) return nil } // 客户端流式 func (s *server) ClientStreamingEcho(stream pb.Echo_ClientStreamingEchoServer) error { for { recv, err := stream.Recv() // block 直到有数据输出 if errors.Is(err, io.EOF) { // 表示消息传输完毕 break } if err != nil { log.Printf(\"recv error: %v\", err) return err } // client 断开连接 log.Printf(\"recv data: %v\", recv.Message) } // SendAndClose 只存在于客户端 stream 请求 // 发送完关闭 stream return stream.SendAndClose(\u0026pb.EchoResponse{Message: \"bye\"}) } // 双向流式 func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 如果服务端 stream 方法退出，客户端请求也直接断开 for { recv, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv error: %v\", err) return err } if recv.Message == \"bye\" { log.Printf(\"client send done!\") break } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + recv.Message}); err != nil { log.Printf(\"send message error: %v\", err) return err } } return nil } func main() { addr := \"127.0.0.1:50001\" // grpc 为 http2 请求，传输层协议为 tcp lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"binding at %v: %v\", addr, err) } gRPCServer := grpc.NewServer() pb.RegisterEchoServer(gRPCServer, \u0026server{}) if err := gRPCServer.Serve(lis); err != nil { log.Fatalf(\"start grpc: %v\", err) } } ","date":"2021-12-03","objectID":"/grpc1/:4:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"Client package main import ( \"context\" \"errors\" \"fmt\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" ) // 简单请求 func unaryEcho(cli pb.EchoClient, msg string) { recv, err := cli.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"unaryEcho %v\", err) } log.Println(\"recv data =\u003e \" + recv.Message) } // 服务端流式 func serverStreamingEcho(cli pb.EchoClient, msg string) { stream, err := cli.ServerStreamingEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"serverStreamingEcho %v\", err) } ctx := stream.Context() for { select { case \u003c-ctx.Done(): log.Println(\"serverStreamingEcho done!\") break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err == nil { log.Println(\"serverStreaming reply =\u003e \", msg.Message) } } } // 客户端流式 func clientStreamingEcho(cli pb.EchoClient) { stream, err := cli.ClientStreamingEcho(context.Background()) if err != nil { log.Printf(\"connect client Streaming: %v\\n\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"hello\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \" \"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"world\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } if recv, err := stream.CloseAndRecv(); err == nil { fmt.Printf(\"recv data: %v\\n\", recv.Message) } } // 双向流式 func bidirectionalStreamingEcho(cli pb.EchoClient) { stream, err := cli.BidirectionalStreamingEcho(context.Background()) if err != nil { log.Printf(\"bidirectionalStreamingEcho error: %v\\n\", err) return } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 1\"}) recv, err := stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 2\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 3\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"bye\"}) stream.CloseSend() } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext(ctx, addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"connect %v: %v\", addr, err) } cli := pb.NewEchoClient(conn) unaryEcho(cli, \"hello\") serverStreamingEcho(cli, \"hello\") clientStreamingEcho(cli) bidirectionalStreamingEcho(cli) } ","date":"2021-12-03","objectID":"/grpc1/:5:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"GPRC 进阶 grpc 除了提供四种请求类型之外，还支持很多高级功能：keepalive、请求重试、负载均衡、用户验证等。接下来一一介绍。 GRPC 进阶功能 每个grpc请求都是 stream。 ","date":"2021-12-03","objectID":"/grpc2/:0:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"Keepalive Keepalive 能够让 grpc 的每个 stream 保持长连接状态，适合一些执行时间长的请求。Keepalive 支持在服务端和客户端配置，且只有服务端配置后，客户端的配置才会真正有效。先给出实例的代码在来说明 grpc keepalive 的使用情况：server 实现： // ... var kaep = keepalive.EnforcementPolicy{ MinTime: 5 * time.Second, // If a client pings more than once every 5 seconds, terminate the connection PermitWithoutStream: true, // Allow pings even when there are no active streams } var kasp = keepalive.ServerParameters{ MaxConnectionIdle: 15 * time.Second, // If a client is idle for 15 seconds, send a GOAWAY MaxConnectionAge: 30 * time.Second, // If any connection is alive for more than 30 seconds, send a GOAWAY MaxConnectionAgeGrace: 5 * time.Second, // Allow 5 seconds for pending RPCs to complete before forcibly closing connections Time: 5 * time.Second, // Ping the client if it is idle for 5 seconds to ensure the connection is still active Timeout: 1 * time.Second, // Wait 1 second for the ping ack before assuming the connection is dead } // server implements EchoServer. type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { address := \"50001\" lis, err := net.Listen(\"tcp\", address) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // 创建 grpc server 时配置服务端的 keepalive s := grpc.NewServer(grpc.KeepaliveEnforcementPolicy(kaep), grpc.KeepaliveParams(kasp)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } client 端实现： // ... var kacp = keepalive.ClientParameters{ Time: 10 * time.Second, // send pings every 10 seconds if there is no activity Timeout: time.Second, // wait 1 second for ping ack before considering the connection dead PermitWithoutStream: true, // send pings even without active streams } func main() { conn, err := grpc.Dial(\"50001\", grpc.WithInsecure(), grpc.WithKeepaliveParams(kacp)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute) defer cancel() fmt.Println(\"Performing unary request\") res, err := c.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: \"keepalive demo\"}) if err != nil { log.Fatalf(\"unexpected error from UnaryEcho: %v\", err) } fmt.Println(\"RPC response:\", res) } keepalive 的实现核心在于 keepalive.EnforcementPolicy 和 keepalive.ServerParameters。首先是 keepalive.ServerParameters。它包含几个属性： MaxConnectionIdle : 最大空闲连接时间，默认为无限制。这段时间为客户端 stream 请求为0 或者建立连接。超出这段时间后，serve 会发送一个 GoWay，强制 client stream 断开。 MaxConnectionAge：最大连接时间，默认为无限制。stream 连接超出这个值是发送一个 GoWay。 MaxConnectionAgeGrace ：超出MaxConnectionAge之后的宽限时长，默认无限制，最小为 1s。 Time ：如果一段时间客户端存活但没有 pings 请求，服务端发送一次 ping 请求，默认是 2hour。 Timeout：服务端发送 ping 请求超时的时间，默认20s。 keepalive.EnforcementPolicy在服务端强制执行策略，如果客户端违反改策略则断开连接。它有两个属性： MinTime : 如果在指定时间内收到 pings 请求大于一次，强制断开连接，默认 5min。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 keepalive.ClientParameters是在客户端这侧使用的 keepalive 配置： Time ：pings 请求间隔时间，默认无限制，最小为 10s。 Timeout ：pings 超时时间，默认是 20s。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 ","date":"2021-12-03","objectID":"/grpc2/:1:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"请求重试 grpc 支持请求重试，在客户端配置好规则之后，客户端会在请求失败之后尝试重新发起请求。 var ( retryPolicy = `{ \"methodConfig\": [{ \"name\": [{\"service\": \"mysite.pb.Echo\"}], \"waitForReady\": true, \"retryPolicy\": { \"MaxAttempts\": 3, \"InitialBackoff\": \".01s\", \"MaxBackoff\": \"1s\", \"BackoffMultiplier\": 2.0, \"RetryableStatusCodes\": [ \"UNAVAILABLE\" ] } }]}` ) // use grpc.WithDefaultServiceConfig() to set service config func retryDial() (*grpc.ClientConn, error) { return grpc.Dial(*addr, grpc.WithInsecure(), grpc.WithDefaultServiceConfig(retryPolicy)) } // ... retry 配置只需要在客户端设置即可生效。主要是配置ServerConfig，格式为该链接 MaxAttempts ：重试的最大次数，最大值是5。 InitialBackoff : 初始化重试间隔时间，第一次重试去 Randon(0,initialBackoff)。 MaxBackoff : 最大重试间隔时间，多次重试是，间隔时间取 random(0,min(initial_backoff*backoff_multiplier**(n-1), max_backoff))。 RetryableStatusCodes : 设置需要重试的状态码。 ","date":"2021-12-03","objectID":"/grpc2/:2:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"负载均衡 grpc 支持客户端负载均衡策略，负载均衡在 grpc name_resolver 的基础上实现： const ( exampleScheme = \"example\" exampleServiceName = \"lb.example.grpc.io\" ) // ... func main() { // ... // round_robin 指定负载均衡策略为轮询策略 roundrobinConn, err := grpc.Dial( fmt.Sprintf(\"%s:///%s\", exampleScheme, exampleServiceName), grpc.WithBalancerName(\"round_robin\"), // This sets the initial balancing policy. grpc.WithInsecure(), grpc.WithBlock(), ) // ... } // 配置 name resolver type exampleResolverBuilder struct{} func (*exampleResolverBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { r := \u0026exampleResolver{ target: target, cc: cc, addrsStore: map[string][]string{ exampleServiceName: addrs, }, } r.start() return r, nil } func (*exampleResolverBuilder) Scheme() string { return exampleScheme } type exampleResolver struct { target resolver.Target cc resolver.ClientConn addrsStore map[string][]string } func (r *exampleResolver) start() { addrStrs := r.addrsStore[r.target.Endpoint] addrs := make([]resolver.Address, len(addrStrs)) for i, s := range addrStrs { addrs[i] = resolver.Address{Addr: s} } r.cc.UpdateState(resolver.State{Addresses: addrs}) } func (*exampleResolver) ResolveNow(o resolver.ResolveNowOptions) {} func (*exampleResolver) Close() {} func init() { resolver.Register(\u0026exampleResolverBuilder{}) } 主要是要实现 resolver.Builder接口 // Builder creates a resolver that will be used to watch name resolution updates. type Builder interface { // Build creates a new resolver for the given target. // // gRPC dial calls Build synchronously, and fails if the returned error is // not nil. Build(target Target, cc ClientConn, opts BuildOptions) (Resolver, error) // Scheme returns the scheme supported by this resolver. // Scheme is defined at \u003chttps://github.com/grpc/grpc/blob/master/doc/naming.md\u003e. Scheme() string } 上面的实现方式不支持动态增减服务端地址，可以使用 etcd 实现负载均衡： type etcdBuilder struct { prefix string endpoints []string } func ETCDBuilder(prefix string, endpoints []string) resolver.Builder { return \u0026etcdBuilder{prefix, endpoints} } func (b *etcdBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { cli, err := clientv3.New(clientv3.Config{ Endpoints: b.endpoints, DialTimeout: 3 * time.Second, }) if err != nil { return nil, fmt.Errorf(\"connect to etcd endpoints error\") } ctx, cancel := context.WithCancel(context.Background()) rlv := \u0026etcdResolver{ cc: cc, cli: cli, ctx: ctx, cancel: cancel, watchKeyPrefix: b.prefix, freq: 5 * time.Second, t: time.NewTimer(0), rn: make(chan struct{}, 1), im: make(chan []resolver.Address), wg: sync.WaitGroup{}, } rlv.wg.Add(2) go rlv.watcher() go rlv.FetchBackendsWithWatch() return rlv, nil } func (b *etcdBuilder) Scheme() string { return \"etcd\" } type etcdResolver struct { retry int freq time.Duration ctx context.Context cancel context.CancelFunc cc resolver.ClientConn cli *clientv3.Client t *time.Timer watchKeyPrefix string rn chan struct{} im chan []resolver.Address wg sync.WaitGroup } func (r *etcdResolver) ResolveNow(opt resolver.ResolveNowOptions) { select { case r.rn \u003c- struct{}{}: default: } } func (r *etcdResolver) Close() { r.cancel() r.wg.Wait() r.t.Stop() } func (r *etcdResolver) watcher() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case addrs := \u003c-r.im: if len(addrs) \u003e 0 { r.retry = 0 r.t.Reset(r.freq) r.cc.UpdateState(resolver.State{Addresses: addrs}) continue } case \u003c-r.t.C: case \u003c-r.rn: } result := r.FetchBackends() if len(result) == 0 { r.retry++ r.t.Reset(r.freq) } else { r.retry = 0 r.t.Reset(r.freq) } r.cc.UpdateState(resolver.State{Addresses: result}) } } func (r *etcdResolver) FetchBackendsWithWatch() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case _ = \u003c-r.cli.Watch(r.ctx, r.watchKeyPrefix, clientv3.WithPrefix()): result := r.FetchBackends() r.im \u003c- result } } } func (r *etcdResolver) FetchBackends() []resolver.Address { ctx, cancel := context.WithTimeout(context.Background()","date":"2021-12-03","objectID":"/grpc2/:3:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 加密传输 以上的请求中，grpc 都是通过明文传输数据。但这种方式是很容易泄露数据内容的，grpc 支持 TLS 格式的加密通讯，来保存数据传输的安全性。 ","date":"2021-12-03","objectID":"/grpc2/:4:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"TLS 证书 我们首先来生成 TLS 证书 openssl ecparam -genkey -name secp384r1 -out server.key openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 这里需要填写相关信息 Country Name (2 letter code) []: State or Province Name (full name) []: Locality Name (eg, city) []: Organization Name (eg, company) []: Organizational Unit Name (eg, section) []: Common Name (eg, fully qualified host name) []: mysite Email Address []: 填写完成后就生成对应的证书： ssl ├── server.key └── server.pem 服务端实现 // ... const PORT = \"50001\" func main() { // 通过 credentials 加载服务端的TLS证书 c, err := credentials.NewServerTLSFromFile(\"../ssl/server.pem\", \"../ssl/server.key\") if err != nil { log.Fatalf(\"credentials.NewServerTLSFromFile err: %v\", err) } // 添加 credentials 配置 server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, \u0026SearchService{}) lis, err := net.Listen(\"tcp\", \":\"+PORT) if err != nil { log.Fatalf(\"net.Listen err: %v\", err) } server.Serve(lis) } 客户端实现 const PORT = \"9001\" func main() { // 添加 credentials 配置 c, err := credentials.NewClientTLSFromFile(\"../ssl/server.pem\", \"mysite\") if err != nil { log.Fatalf(\"credentials.NewClientTLSFromFile err: %v\", err) } // 客户端开启证书验证 conn, err := grpc.Dial(\":\"+PORT, grpc.WithTransportCredentials(c)) if err != nil { log.Fatalf(\"grpc.Dial err: %v\", err) } defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), \u0026pb.SearchRequest{ Request: \"gRPC\", }) if err != nil { log.Fatalf(\"client.Search err: %v\", err) } log.Printf(\"resp: %s\", resp.GetResponse()) } ","date":"2021-12-03","objectID":"/grpc2/:4:1","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"CA TLS 证书 TLS 证书的安全性还不够高，特别在证书生成之后，server.key文件的传输就成为一个问题。所以 CA 来签发 TLS 证书来解决这个问题。使用开源工具 cfssl 生成对应的证书：1.ca 配置 cat \u003c\u003c EOF | tee ca-config.json { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"mysite\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } }} EOF 配置 mysite 机构证书可以进行服务端和客户端双向验证。2.ca 证书 cat \u003c\u003c EOF | tee ca-csr.json { \"CN\": \"mysite CA\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 3.服务端证书 cat \u003c\u003c EOF | tee server-csr.json { \"CN\": \"mysite\", \"hosts\": [ \"127.0.0.1\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 生成 mysite ca 证书和私钥，初始化 ca cfssl gencert -initca ca-csr.json | cfssljson -bare ca 生成server证书 cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=mysite -hostname=mysite server-csr.json | cfssljson -bare server 最后的结果为: ../ssl ├── ca-config.json ├── ca-csr.json ├── ca-key.pem ├── ca.csr ├── ca.pem ├── server-csr.json ├── server-key.pem ├── server.csr └── server.pem 接下来是代码实现，先是服务端： // ... type ecServer struct { pb.UnimplementedEchoServer } func (s *ecServer) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:50001\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, }) s := grpc.NewServer(grpc.Creds(creds)) // Register EchoServer on the server. pb.RegisterEchoServer(s, \u0026ecServer{}) log.Println(\"server start\") if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } 然后是客户端： // ... func callUnaryEcho(client pb.EchoClient, message string) { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() resp, err := client.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: message}) if err != nil { log.Fatalf(\"client.UnaryEcho(_) = _, %v: \", err) } fmt.Println(\"UnaryEcho: \", resp.Message) } func main() { // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ServerName: \"mysite\", RootCAs: certPool, }) // Set up a connection to the server. conn, err := grpc.Dial(\"127.0.0.1:50001\", grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() // Make a echo client and send an RPC. rgc := pb.NewEchoClient(conn) callUnaryEcho(rgc, \"hello world\") } ","date":"2021-12-03","objectID":"/grpc2/:4:2","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"拦截器 grpc 支持服务端和客户端的拦截器，可以在请求发起或返回前进行处理，而不用修改原来的代码。接下来来看服务端和客户端各自怎么使用拦截器： // unary 请求拦截器 func UnaryInterceptor(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler, ) (resp interface{}, err error) { var ip string p, ok := peer.FromContext(ctx) if ok { ip = p.Addr.String() } md, _ := metadata.FromIncomingContext(ctx) start := time.Now() resp, err = handler(ctx, req) end := time.Now() log.Printf(\"%10s | %14s | %10v | md=%v | reply = %v\", ip, info.FullMethod, end.Sub(start), md, resp) return } // stream 请求拦截器 func StreamInterceptor(srv interface{}, ss grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler, ) (err error) { var ip string p, ok := peer.FromContext(ss.Context()) if ok { ip = p.Addr.String() } err = handler(srv, ss) log.Printf(\"stream %v | %v | %s\\\\n\", srv, ip, info.FullMethod) return } type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"network at %v: %v\\\\n\", addr, err) } s := grpc.NewServer(grpc.ChainUnaryInterceptor(UnaryInterceptor), grpc.ChainStreamInterceptor(StreamInterceptor)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"start server at %v: %v\\\\n\", addr, err) } } grpc 中的拦截器分两种，一元请求的拦截器和流式请求的拦截器。其中流式请求的连接器同时作用于服务端流式、客户端流式和双向流式三种请求模式。 接下来是客户端： func clientUnaryInterceptor( ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption, ) (err error) { ctx = metadata.AppendToOutgoingContext(ctx, \"username\", \"OOB\") err = invoker(ctx, method, req, reply, cc, opts...) return } func clientStreamInterceptor(ctx context.Context, desc *grpc.StreamDesc, cc *grpc.ClientConn, method string, streamer grpc.Streamer, opts ...grpc.CallOption, ) (stream grpc.ClientStream, err error) { // before stream stream, err = streamer(ctx, desc, cc, method, opts...) // after stream return } func callUnaryEcho(cc pb.EchoClient, msg string) { reply, err := cc.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err == nil { log.Printf(\"reply =\u003e %v\\\\n\", reply) } } func callBidirectionalEcho(cc pb.EchoClient, msg string) { stream, err := cc.BidirectionalStreamingEcho(context.TODO()) if err != nil { log.Fatalf(\"call BidirectionalEcho: %v\\\\n\", err) } _ = stream.Send(\u0026pb.EchoRequest{Message: msg}) _ = stream.CloseSend() ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } reply, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Fatalf(\"stream recv: %v\\\\n\", err) } log.Printf(\"stream reply =\u003e %v\\\\n\", reply.Message) } } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext( ctx, addr, grpc.WithInsecure(), grpc.WithChainUnaryInterceptor(clientUnaryInterceptor), grpc.WithChainStreamInterceptor(clientStreamInterceptor)) if err != nil { log.Fatalf(\"connect %v: %v\\\\n\", addr, err) } cc := pb.NewEchoClient(conn) callUnaryEcho(cc, \"unary\") callBidirectionalEcho(cc, \"start\") } grpc 的拦截器同时支持单个拦截器和链式拦截器。 ","date":"2021-12-03","objectID":"/grpc2/:5:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 添加 pprof 接口 grpc 本身是使用 http2 作为底层协议，所以它也能和 golang 的 pprof 结合提供 pprof 接口。下面给出代码： type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" // 这里可以添加服务段启动配置和各种拦截器 s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) mux := http.NewServeMux() mux.HandleFunc(\"/debug/pprof/\", pprof.Index) mux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline) mux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile) mux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol) mux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace) // 启动 http2 服务，golang http 启动时添加证书会自动转化为 http2 服务。 // 将 Content-Type 为 application/grpc 请求转交给 grpc 即可。 err := http.ListenAndServeTLS( addr, \"ssl/server.pem\", \"ssl/server-key.pem\", http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) { if r.ProtoMajor == 2 \u0026\u0026 strings.Contains(r.Header.Get(\"Content-Type\"), \"application/grpc\") { log.Println(\"call grpc service\") s.ServeHTTP(rw, r) } else { mux.ServeHTTP(rw, r) } })) if err != nil { log.Fatalf(\"start server at %v: %v\", addr, err) } } ","date":"2021-12-03","objectID":"/grpc2/:6:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 请求断开处理 grpc 的请求没有自己设置请求的超时时间，而是将这部分的处理交给 golang 的 context 包。通过 context 的功能实现客户端的登录超时，请求超时。服务端代码： type server struct { pb.UnimplementedEchoServer } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 该函数内是 stream 的整个生命周期，该函数退出后，stream 的上下文结束 // 每个stream函数相互独立 // 服务端的 stream 不能直接发起请求终止，但可以通过提前结束该函数，停止该 stream for { in, err := stream.Recv() if err != nil { fmt.Printf(\"server: error receiving from stream: %v\\n\", err) if err == io.EOF { return nil } return err } fmt.Printf(\"echoing message %q\\n\", in.Message) stream.Send(\u0026pb.EchoResponse{Message: in.Message}) } } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:10050\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } fmt.Printf(\"server listening at port %v\\n\", lis.Addr()) s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) s.Serve(lis) } 客户端: func sendMessage(stream pb.Echo_BidirectionalStreamingEchoClient, msg string) error { fmt.Printf(\"sending message %q\\n\", msg) return stream.Send(\u0026pb.EchoRequest{Message: msg}) } func recvMessage(stream pb.Echo_BidirectionalStreamingEchoClient, wantErrCode codes.Code) { res, err := stream.Recv() if status.Code(err) != wantErrCode { log.Fatalf(\"stream.Recv() = %v, %v; want _, status.Code(err)=%v\", res, err, wantErrCode) } if err != nil { fmt.Printf(\"stream.Recv() returned expected error %v\\n\", err) return } fmt.Printf(\"received message %q\\n\", res.Message) } func main() { addr := \"127.0.0.1:10050\" // 建立连接 // 建立连接的 ctx 和请求的 ctx 是独立的 conn, err := grpc.DialContext(context.Background(), addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) // Initiate the stream with a context that supports cancellation. ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) stream, err := c.BidirectionalStreamingEcho(ctx) if err != nil { log.Fatalf(\"error creating stream: %v\", err) } // Send some test messages. if err := sendMessage(stream, \"hello\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } if err := sendMessage(stream, \"world\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } // Ensure the RPC is working. recvMessage(stream, codes.OK) recvMessage(stream, codes.OK) fmt.Println(\"cancelling context\") cancel() // This Send may or may not return an error, depending on whether the // monitored context detects cancellation before the call is made. sendMessage(stream, \"closed\") // This Recv should never succeed. recvMessage(stream, codes.Canceled) } GRPC 性能优化 虽然 grpc 的官方自诩是高性能的框架，但是 grpc 内部使用大量的反射，使得 grpc 在性能上并不算很好，所以还是有必要优化。grpc 的优化思路比较简单，不需要直接修改源码，只需要在 protoc 命令生成 golang 代码是，将 golang/protobuf 换成第三方的 gogo/protobuf 。gogo库基于官方库开发，增加了很多的功能，包括： 快速的序列化和反序列化 更规范的Go数据结构 goprotobuf兼容 可选择的产生一些辅助方法，减少使用中的代码输入 可以选择产生测试代码和benchmark代码 其它序列化格式 比如etcd、k8s、dgraph、docker swarmkit都使用它。基于速度和定制化的考虑，gogo有三种产生代码的方式 gofast: 速度优先，不支持其它gogoprotobuf extensions。 go get github.com/gogo/protobuf/protoc-gen-gofast protoc --gofast_out=. myproto.proto gogofast类似gofast,但是会导入gogoprotobuf gogofaster类似gogofast, 不会产生XXX_unrecognized指针字段，可以减少垃圾回收时间。 gogoslick类似gogofaster,但是可以增加一些额外的方法gostring和equal等等。 go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/{binary} //protoc-gen-gogofast、protoc-gen-gogofaster 、protoc-gen-gogoslick go get github.com/gogo/protobuf/gogoproto protoc -I=. -I=$GOPATH/src -I=$GOPATH/src/github.com/gogo/protobuf/protobuf --{binary}_out=. myproto.proto protoc-gen-gogo: 最快的速度，最多的可定制化 你可以通过扩展定制序列化: 扩展. go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/jsonpb go get github.com/gogo/protobuf/protoc-gen-gogo go get github.com/gogo/protobuf/gogoproto gogo同样支持grpc: protoc --gofast_out=plugins=grpc:. my.proto。同时还有 protobuf 对应的教程 。 ","date":"2021-12-03","objectID":"/grpc2/:7:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"iscsi共享磁盘服务 iscsi简单介绍 iSCSI（Internet Small Computer System Interface，发音为/ˈаɪskʌzi/），Internet小型计算机系统接口，又称为IP-SAN，是一种基于因特网及SCSI-3协议下的存储技术，由IETF提出，并于2003年2月11日成为正式的标准。与传统的SCSI技术比较起来，iSCSI技术有以下三个革命性的变化： 把原来只用于本机的SCSI协义透过TCP/IP网络发送，使连接距离可作无限的地域延伸； 连接的服务器数量无限（原来的SCSI-3的上限是15）； 由于是服务器架构，因此也可以实现在线扩容以至动态部署。 简单的说就是tcp协议仿真scsi，将本地的磁盘通过网络共享给其他机器，提供数据的远程存储。 iscsi基本概念 iscsi中有一些常用的基本概念，了解这些能帮助我们认识iscsi服务的具体工作原理，下面就用一张图表来说明： 名词 说明 ACL 访问权限控制列表，用来验证客户端启动器的访问，通常是客户端 iSCSI 启动器的 IQN 名称 IQN 用于标识单个 iSCSI 目标和启动器的唯一名称(全部小写) WWN 用于标识单个光纤通道端口和节点的唯一编号 TARGET iSCSI 服务器上的存储资源 LUN iSCSI 服务器上的块设备 initiator(启动器) 以软件或硬件实施的 iSCSI 客户端 NODE 单个 iSCSI 启动器或者目标 TPG 启动器或者目标上的单个 IP 连接地址 Portal 网络接口及端口 iscsi 安装配置 iscsi 服务管理的软件有多个，这里就简单介绍两个，targetcli和tgt。 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:0:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"使用targetcli管理配置iscsi 1.准备阶段 有两台linux机器，分别作为服务端和客户端。实验环境最好在虚拟机上，方便修改的反复操作。同时在服务端上有一块磁盘作为iscsi共享磁盘。 [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 4G 0 part [SWAP] └─sda3 8:3 0 35.5G 0 part / sdb 8:16 0 10G 0 disk └─sdb1 8:17 0 10G 0 part sdc 8:32 0 10G 0 disk sr0 11:0 1 1024M 0 rom 这个选择/dev/sdb1,没有的同学可以使用fdisk命令自己分配一个。 2.安装targetcli yum install -y targetcli 还需要启动targetcli服务 systemctl start target 3.配置targetcli 配置targetcli有几个步骤，添加target，在target上添加lun，将target共享到指定网段。 先来创建一个块设备，使用命令为： /backstores/block create westos:storage1 /dev/sdb1 进入targetcli操作： [root@localhost ~]# targetcli Warning: Could not load preferences file /root/.targetcli/prefs.bin. targetcli shell version 2.1.fb46 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type 'help'. /\u003e /backstores/block create westos:storage1 /dev/sdb1 Created block storage object westos:storage1 using /dev/sdb1. # 注意这里就成功创建一个快设备 /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 0] o- loopback ......................................................................................................... [Targets: 0] /\u003e 接着创建一个iscsi共享的target，使用命令为： /iscsi create iqn.2018-10.com.westos:storage1 这里的target名称其实可以随意，但一般格式为iqn.year.month.com.domain.xxx, 执行的结果如下： /\u003e /iscsi create iqn.2018-10.com.westos:storage1 Created target iqn.2018-10.com.westos:storage1. Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ........................","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:1:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"使用tgt配置iscsi 再来介绍另外一种软件，就是tgt。 1.安装 yum install -y epel-release yum install -y scsi-target-utils 启动服务 systemctl start tgtd 2.配置tgt 配置tgt使用的命令是tgtadm，有以下常用选项： –lld –mode target –op new –tid –targetname # 新建target –lld –mode target –op delete [–force] –tid # 删除target –lld –mode target –op show # 查看所有的target –lld –mode target –op show –tid # 查看指定id的target –lld –mode target –op update –tid –name –value # 更新target –lld –mode target –op bind –tid –initiator-address # target共享到指定网段 –lld –mode target –op bind –tid –initiator-name # target共享到指定的客户端名称 –lld –mode target –op unbind –tid –initiator-address # 解绑 –lld –mode target –op unbind –tid –initiator-name –lld –mode logicalunit –op new –tid –lun –backing-store –bstype –bsopts –bsoflags # 创建lun –lld –mode logicalunit –op delete –tid –lun # 删除lun –lld –mode account –op new –user –password # 添加认证 –lld –mode account –op delete –user # 删除认证 –lld –mode account –op bind –tid –user [–outgoing] # 绑定认证 –lld –mode account –op unbind –tid –user [–outgoing] # 解绑认证 添加target [root@localhost ~]# tgtadm --lld iscsi --mode target --op new --tid 1 --targetname iqn-2019-11.com.iscsi.test [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: Account information: ACL information: 添加lun [root@localhost ~]# tgtadm --lld iscsi --mode logicalunit --op new --tid 1 --lun 22 -b /dev/sdb [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: LUN: 22 Type: disk SCSI ID: IET 00010016 SCSI SN: beaf122 Size: 10737 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: rdwr Backing store path: /dev/sdb Backing store flags: Account information: ACL information: 注：这里有一个小提示，每个lun中的SCSI ID项是在客户端中的唯一标识，它的值是根据target id和lun id计算得到的，即： SCSI ID = Target ID转16进制(前四位) + Lun ID转16进制(后四位) 所以lun 22的SCSI ID为00010016 共享到客户端： [root@localhost ~]# tgtadm --lld iscsi --mode target --op bind --tid 1 --initiator-address 192.168.3.131 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:2:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"客户端连接 1.安装客户端 yum install -y epel-release yum install -y iscsi-initiator-utils 客户端命令： iscsiadm -m session # 查看所有会话 iscsiadm -m discovery -t st -p 192.168.3.150 #查看共享target iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l #登陆连接 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -u #退出登陆 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -o delete #删除登陆数据 2.发现设备 [root@localhost ~]# iscsiadm -m discovery -t st -p 192.168.3.150 192.168.3.150:3260,1 iqn.2018-10.com.westos:storage1 登录 注：请关闭防火墙和selinux [root@localhost mnt]# iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l Logging in to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] (multiple) Login to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] successful. [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 8G 0 part [SWAP] └─sda3 8:3 0 31.5G 0 part / sdb 8:16 0 2G 0 disk └─sdb1 8:17 0 2G 0 part sr0 11:0 1 1024M 0 rom 同时在/dev/disk/by-id下生成块设备。 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:3:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"KVM之虚拟机管理 本篇文章介绍 KVM 虚拟机的管理，包括虚拟机的创建、修改、启动、删除等内容 安装虚拟机 ","date":"2021-12-03","objectID":"/kvm_vm/:0:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"使用 virt-install 安装 virt-install 是一个命令行工具，专门用于安装 kvm 虚拟机。执行以下命令： virt-install \\ --name centos \\ --ram 1024 \\ --disk path=/data/kvm/centos.img,size=20 \\ --vcpus 1 \\ --os-type linux --os-variant rhel7 \\ --network bridge=br0 \\ --graphics vnc,listen=0.0.0.0,port=5999 --noautoconsole \\ --console pty,target_type=serial \\ --cdrom CentOS-7-x86_64-DVD-1810.iso 进入安装流程： # virsh list --all Id 名称 状态 ---------------------------------------------------- 2 centos running 可以使用 vnc 客户端连接虚拟机。 参数说明： -–name 指定虚拟机的名字 –-ram 指定内存分配多少 –-disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –-vcpus 指定分配cpu几个 -–os-type 指定系统类型为linux –-os-variant 指定系统版本 -–network 指定网络类型 -–graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 -–console 指定控制台类型 -–location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS –extra-args 额外参数，需要和 –location 配置使用 –cdrom 指定操作系统镜像位置 ","date":"2021-12-03","objectID":"/kvm_vm/:1:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误处理 安装过程中出现三个错误: ","date":"2021-12-03","objectID":"/kvm_vm/:2:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误一 第一个错误如下: CPU mode 'custom' for x86_64 kvm domain on x86_64 host is not supported by hypervisor 解决方式是重启宿主机 ","date":"2021-12-03","objectID":"/kvm_vm/:2:1","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误二 第二个错误如下： Creating storage file centos.img | 20 GB 00:00 ERROR internal error Process exited while reading console log output: char device redirected to /dev/pts/4 2016-01-27T08:56:58.986952Z ...: Permission denied Domain installation does not appear to have been successful. If it was, you can restart your domain by running: virsh --connect qemu:///system start centos65 otherwise, please restart your installation. 解决方式修改 /etc/libvirt/qemu.conf 配置文件，添加 user 和 group 配置： # /etc/libvirt/qemu.conf # ... user = \"root\" # ... group = \"root\" 重启服务: systemctl restart libvirtd ","date":"2021-12-03","objectID":"/kvm_vm/:2:2","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误三 第三个错误是执行命令 virsh console centos 时卡住: # virsh console centos 连接到域 centos 换码符为 ^] 解决方式如下： 确认 ttyS0 存在在 /etc/securetty 文件中，没有就执行以下命令: echo \"ttyS0\" \u003e\u003e /etc/securetty 修改 /etc/default/grub 文件： # GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet” # 改成 GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet net.ifnames=0 console=ttyS0,115200\" 重新生成 grub 文件： grub2-mkconfig -o /boot/grub2/grub.cfg 启动 serial-getty 服务: systemctl start serial-getty@ttyS0.service systemctl enable serial-getty@ttyS0.service 操作虚拟机 KVM 在 Hypervisor 中被称作域(domain)。使用 virsh 命令可以很有效的管理域。 virsh 中管理域的命令: 命令 功能描述 list 获取当前节点上的所有域的列表 domstate \u003cID or Name or UUID\u003e 获取一个域的运行状态 dominfo \u003cID\u003e 获取一个域的基本信息 domid \u003cName or UUID\u003e 根据域的名称或UUID返回域的ID domname \u003cID or UUID\u003e 根据域的ID或UUID返回域的名称 dommemstat \u003cID\u003e 获取一个域的内存使用情况的统计信息 setmem \u003cID\u003e \u003cmem-size\u003e 设置一个域的内存大小(默认单位为KB) vcpupin \u003cID\u003e \u003cvCPU\u003e \u003cpCPU\u003e 将一个域的 vCPU 绑定到某个物理 CPU 上运行 setvcpus \u003cID\u003e \u003cvCPU-num\u003e 设置一个域的 vCPU 的个数 vncdisplay \u003cID\u003e 获取一个域的 VNC 连接 IP 地址的端口 create \u003cdom.xml\u003e 根据域的 XML 配置文件创建一个域(客户机) suspend \u003cID\u003e 暂停一个域 resume \u003cID\u003e 唤醒一个域 shutdown \u003cID\u003e 让一个域执行关机操作 reboot \u003cID\u003e 让一个域执行重启操作 reset \u003cID\u003e 强制重启一个域，相当于在物理机上按带电源 “reset” 按钮 (可能会破坏该域的文件系统) destroy \u003cID\u003e 立即销毁一个域，相当于直接拔掉物理机机器的电源线（可能会破坏该域的文件系统） save \u003cID\u003e \u003cfile.img\u003e 保存一个运行中的域的状态到一个文件中 restore \u003cfile.img\u003e 从一个被保存的文件中恢复一个域的运行 migrate \u003cID\u003e \u003cdest_url\u003e 将一个域迁移到另外一个目的地址 dumpxml \u003cID\u003e 以 XML 格式转存出一个域的信息到标准输出中 attach-device \u003cID\u003e \u003cdevice.xml\u003e 向一个域添加 XML 文件中的设备(热插拔) detach-device \u003cID\u003e \u003cdevice.xml\u003e 将 XML 文件中的设备从一个域中移除 console \u003cID\u003e 连接到一个域的控制台 ","date":"2021-12-03","objectID":"/kvm_vm/:2:3","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"虚拟机生命周期 # 启动虚拟机 virsh start centos # 关闭虚拟机 virsh shutdown centos # 重启虚拟机 virsh reboot centos # 销毁虚拟机 virsh destroy centos # 暂停虚拟机 virsh suspend centos # 恢复虚拟机 virsh resume centos # 删除虚拟机 virsh undefine centos rm -fr /etc/libvirt/qemu/centos.xml ","date":"2021-12-03","objectID":"/kvm_vm/:3:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"限制和修改虚拟机 cpu 先关闭虚拟机，修改虚拟机 xml 文件: # 设置 cpu 最大个数为 4 个，当前为 1 \u003cvcpu placement='static' current='1'\u003e4\u003c/vcpu\u003e 开启虚拟机后，动态设置虚拟机 cpu # 最大个数不能超过指定值 virsh setvcpus centos 2 ","date":"2021-12-03","objectID":"/kvm_vm/:4:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"限制和修改虚拟机内存 修改虚拟机内存最大值需要先关闭虚拟机 # 最大值不能超过宿主机内存最大值 virsh setmaxmem centos 4G 动态设置虚拟机内存 virsh setmem centos 2G ","date":"2021-12-03","objectID":"/kvm_vm/:5:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"在线添加和删除虚拟机硬盘 先创建硬盘: # qemu-img create -f qcow2 disk1.qcow2 2G Formatting 'disk1.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=2147483648 lazy_refcounts=off refcount_bits=16 创建 disk.xml 文件 $ vim disk.xml \u003cdisk type='file' device='disk'\u003e \u003cdriver name='qemu' type='qcow2'/\u003e \u003csource file='/data/kvm/disk1.qcow2'/\u003e \u003ctarget dev='vdb' bus='virtio'/\u003e \u003caddress type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/\u003e \u003c/disk\u003e 添加硬盘设备: virsh attach-device centos disk.xml 卸载硬盘设备 virsh dettach-device centos disk.xml ","date":"2021-12-03","objectID":"/kvm_vm/:6:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"在线添加和删除虚拟机网卡 添加 bridge 网卡 virsh attach-interface centos --type bridge --source br0 卸载网卡 virsh detach-interface centos --type bridge --mac 52:54:00:d9:90:bb ","date":"2021-12-03","objectID":"/kvm_vm/:7:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"修改虚拟机 vnc 先关闭虚拟机 virsh stop centos 修改虚拟机文件 # irsh edit centos \u003cgraphics type='vnc' port='6000' autoport='no' listen='0.0.0.0' passwd='123456'\u003e \u003clisten type='address' address='0.0.0.0'/\u003e \u003c/graphics\u003e 注: 虚拟机 vnc 的端口必须在 5900 - 65535 之间 加载配置文件 virsh define /etc/libvirt/qemu/centos.xml 最后启动虚拟机 virsh start centos ","date":"2021-12-03","objectID":"/kvm_vm/:8:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"KVM介绍 KVM 概述 KVM (Kernal-base Virtual Machine) 基于内核的虚拟机。是一种通过修改 linux 内核实现虚拟化功能的半虚拟化技术。由于是在内核基础上运行，所有具有接近物理机的高性能。 KVM 和 Qemu Qemu（quick emulator）开源的软件虚拟化实现，通过软件来模拟硬件的功能，但缺点是性能低。通过和 KVM 相结合来提高性能。现在的版本已经内置 KVM。 全虚拟化和半虚拟化 全虚拟化是指不需要修改操作系统内核实现虚拟化功能，半虚拟化则需要修改内核来实现虚拟化。 KVM 就是一种半虚拟化实现。 全虚拟化又分为软件全虚拟化 (Qemu) 和硬件全虚拟化(Xen)。 KVM 工具集合 libvirt：操作和管理KVM虚机的虚拟化 API，使用 C 语言编写，可以由 Python,Ruby, Perl, PHP, Java 等语言调用。可以操作包括 KVM，vmware，XEN，Hyper-v, LXC 等在内的多种 Hypervisor。 Virsh：基于 libvirt 的 命令行工具 （CLI） Virt-Manager：基于 libvirt 的 GUI 工具 virt-v2v：虚机格式迁移工具 virt-* 工具：包括 Virt-install （创建KVM虚机的命令行工具）， Virt-viewer （连接到虚机屏幕的工具），Virt-clone（虚机克隆工具），virt-top 等 sVirt：安全工具 KVM 文章 KVM介绍 KVM源码分析 ","date":"2021-12-03","objectID":"/kvm_detail/:0:0","tags":null,"title":"KVM介绍","uri":"/kvm_detail/"},{"categories":null,"content":"KVM镜像管理工具libguestfs 简介 libguestfs 是一套管理虚拟机镜像的工具。它提供以一系列命令和API来修改和管理虚拟机的镜像。 安装 直接使用 yum 安装 libguestfs : yum install -y libguestfs-tool libguestfs-devel 默认不支持修改 windows 镜像，可以安装 libguestfs-winsupport : yum install -y libguestfs-winsupport libguestfs 命令 libguestfs 的通用参数 -a|–add image : 指定查看的镜像文件路径 -c|–connect uri : 指定远程 libvirt 地址 -d|–domain guest : 指定 libvirt 上的 domain 名称 注: libguestfs 的命令需要调用 libvirt 所以响应的速度会比较慢。同时，如果命令会修改镜像的内容，需要先关闭域，避免造成数据不同步。 ","date":"2021-12-03","objectID":"/libguestfs/:0:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-inspector virt-inspector 命令用来查看镜像信息，输出格式为 xml $ virt-inspector -d centos \u003c?xml version=\"1.0\"?\u003e \u003coperatingsystems\u003e \u003coperatingsystem\u003e \u003croot\u003e/dev/centos/root\u003c/root\u003e \u003cname\u003elinux\u003c/name\u003e \u003carch\u003ex86_64\u003c/arch\u003e \u003cdistro\u003ecentos\u003c/distro\u003e \u003cproduct_name\u003eCentOS Linux release 7.6.1810 (Core) \u003c/product_name\u003e \u003cmajor_version\u003e7\u003c/major_version\u003e \u003cminor_version\u003e6\u003c/minor_version\u003e \u003cpackage_format\u003erpm\u003c/package_format\u003e \u003cpackage_management\u003eyum\u003c/package_management\u003e \u003chostname\u003elocalhost.localdomain\u003c/hostname\u003e \u003cosinfo\u003ecentos7.0\u003c/osinfo\u003e \u003cmountpoints\u003e \u003cmountpoint dev=\"/dev/centos/root\"\u003e/\u003c/mountpoint\u003e \u003cmountpoint dev=\"/dev/sda1\"\u003e/boot\u003c/mountpoint\u003e \u003c/mountpoints\u003e \u003cfilesystems\u003e \u003cfilesystem dev=\"/dev/centos/root\"\u003e \u003ctype\u003exfs\u003c/type\u003e \u003cuuid\u003e12e94e0d-93e6-4714-9c61-116fbe994936\u003c/uuid\u003e \u003c/filesystem\u003e ... ... \u003cxml\u003e ","date":"2021-12-03","objectID":"/libguestfs/:1:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-watch virt-watch 查看本机虚拟化环境 $ virt-what vmware ","date":"2021-12-03","objectID":"/libguestfs/:2:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-host-validator virt-host-validator 检查本地环境是否符合虚拟化 $ virt-host-validate QEMU: 正在检查 for hardware virtualization : PASS QEMU: 正在检查 if device /dev/kvm exists : PASS QEMU: 正在检查 if device /dev/kvm is accessible : PASS QEMU: 正在检查 if device /dev/vhost-net exists : PASS ... ... ","date":"2021-12-03","objectID":"/libguestfs/:3:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-get-kernel virt-get-kernel 获取镜像的内核文件 $ virt-get-kernel -d centos download: /boot/vmlinuz-3.10.0-957.el7.x86_64 -\u003e ./vmlinuz-3.10.0-957.el7.x86_64 download: /boot/initramfs-3.10.0-957.el7.x86_64.img -\u003e ./initramfs-3.10.0-957.el7.x86_64.img ","date":"2021-12-03","objectID":"/libguestfs/:4:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-filesystems virt-filesystems 查看镜像的文件系统 $ virt-filesystems -d centos /dev/sda1 /dev/centos/root ","date":"2021-12-03","objectID":"/libguestfs/:5:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-df virt-df 用来查看镜像的文件系统容量，同 df 命令 $ virt-df -d centos -h 文件系统 大小 已用空间 可用空间 使用百分比% centos:/dev/sda1 1014M 100M 914M 10% centos:/dev/centos/root 17G 974M 16G 6% ","date":"2021-12-03","objectID":"/libguestfs/:6:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-ls virt-ls 查看镜像的文件信息，同 ls 命令 $ virt-ls -d centos /root/ -l total 28 dr-xr-x---. 2 root root 135 Jan 26 15:07 . dr-xr-xr-x. 17 root root 224 Jan 16 09:56 .. -rw-------. 1 root root 45 Jan 26 15:07 .bash_history -rw-r--r--. 1 root root 18 Dec 29 2013 .bash_logout -rw-r--r--. 1 root root 176 Dec 29 2013 .bash_profile -rw-r--r--. 1 root root 176 Dec 29 2013 .bashrc -rw-r--r--. 1 root root 100 Dec 29 2013 .cshrc -rw-r--r--. 1 root root 129 Dec 29 2013 .tcshrc -rw-------. 1 root root 1259 Jan 16 09:57 anaconda-ks.cfg ","date":"2021-12-03","objectID":"/libguestfs/:7:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-cat virt-cat 查看镜像内的文件内容，同 cat 命令 $ virt-cat -d centos /etc/passwd root:xx:0:0:root:/root:/bin/bash ... ... ","date":"2021-12-03","objectID":"/libguestfs/:8:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-log virt-log 查看镜像的日志信息 $ virt-log -d centos Jan 30 20:13:01 localhost rsyslogd: [origin software=\"rsyslogd\" swVersion=\"8.24.0-34.el7\" x-pid=\"3123\" x-info=\"http://www.rsyslog.com\"] rsyslogd was HUPed Jan 30 20:33:37 localhost qemu-ga: info: guest-shutdown called, mode: powerdown Jan 30 20:33:37 localhost systemd: Started Delayed Shutdown Service. ","date":"2021-12-03","objectID":"/libguestfs/:9:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tail virt-tail 监听文件内容，同 tail 命令 $ virt-tail -d centos /var/log/messages --- /var/log/messages --- ... ","date":"2021-12-03","objectID":"/libguestfs/:10:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-alignment-scan virt-alignment-scan 查看镜像分区是否对齐 $ virt-alignment-scan -a centos.qcow2 /dev/sda1 1048576 1024K ok /dev/sda2 1074790400 1024K ok ","date":"2021-12-03","objectID":"/libguestfs/:11:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-diff virt-diff 比较镜像间的不同 $ # virt-diff -a centos.qcow2 -A centos.img - d 0550 150 /root + d 0550 135 /root # changed: st_size - - 0644 4 /root/kvm.txt - d 1777 187 /tmp + d 1777 172 /tmp # changed: st_size - - 0644 4 /tmp/kvm.txt ","date":"2021-12-03","objectID":"/libguestfs/:12:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-sparisify virt-sparisify 用来消除镜像内的空洞文件，减少镜像大小 $ virt-sparsify centos.qcow2 -f qcow2 centos2.qcow2 [ 0.0] Create overlay file in /tmp to protect source disk [ 0.0] Examine source disk [ 3.4] Fill free space in /dev/centos/root with zero 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 33.5] Clearing Linux swap on /dev/centos/swap 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ --:-- [ 36.2] Fill free space in /dev/sda1 with zero [ 38.5] Copy to destination and make sparse [ 51.4] Sparsify operation completed with no errors. virt-sparsify: Before deleting the old disk, carefully check that the target disk boots and works correctly. 执行完成后生成 centos2.qcow2 文件: $ ll -h 总用量 4.0G -rw-r--r-- 1 root root 1.1G 1月 30 23:39 centos2.qcow2 -rw-r--r-- 1 root root 1.5G 1月 30 20:33 centos.img -rw-r--r-- 1 root root 1.5G 1月 30 20:43 centos.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:13:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-copy-in virt-copy-in 将本地文件复制到镜像中 $ virt-copy-in -a centos.qcow2 kvm.txt /tmp/ $ virt-ls -a centos.qcow2 /tmp/ kvm.txt ","date":"2021-12-03","objectID":"/libguestfs/:14:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-copy-out virt-copy-out 将镜像中的文件复制到本地 $ virt-copy-out -a centos.qcow2 /tmp/kvm.txt . ","date":"2021-12-03","objectID":"/libguestfs/:15:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-edit virt-edit 编译镜像内的文件，默认会打开本地的 Vim 进行编辑 $ virt-edit -a centos.qcow2 /tmp/kvm.txt $ virt-cat -a centos.qcow2 /tmp/kvm.txt kvm kvm11 ","date":"2021-12-03","objectID":"/libguestfs/:16:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-make-fs virt-make-fs 根据本地的目录创建一个镜像 $ mkdir /input $ echo \"input\" \u003e /input/1.txt $ virt-make-fs --partition=gpt --type=ntfs --size=1G --format=qcow2 /input sdb.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:17:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tar-in virt-tar-in tar 压缩文件拷贝进虚拟机并解压 $ virt-tar-in -a centos.qcow2 kvm.tar /root/ ","date":"2021-12-03","objectID":"/libguestfs/:18:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tar-out virt-tar-out 镜像内指定目录文件拷贝并压缩 $ virt-tar-out -a centos.qcow2 /root root.tar ","date":"2021-12-03","objectID":"/libguestfs/:19:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"guestmount guestmount 将镜像中的文件系统分区挂载到本地目录 $ guestmount -a centos.qcow2 -m /dev/sda1 /mnt ","date":"2021-12-03","objectID":"/libguestfs/:20:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"guestumount guestumount 卸载 guestmount 挂载的目录 $ guestumount /mnt ","date":"2021-12-03","objectID":"/libguestfs/:21:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-rescue virt-rescue 进入救援模式，修复镜像 $ virt-rescue -a centos.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:22:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-resize virt-resize 镜像分区缩容和扩容 给其中某个分区扩容 5G $ virt-filesystems --long -h --all -a olddisk $ truncate -r olddisk newdisk $ truncate -s +5G newdisk $ virt-resize --expand /dev/sda2 olddisk newdisk /boot 分区扩容 200MB bigger, 剩下的分配给 /dev/sda2: $ virt-resize --resize /dev/sda1=+200M --expand /dev/sda2 olddisk newdisk lvm 分区扩容 $ virt-resize --expand /dev/sda2 --LV-expand /dev/vg_guest/lv_root olddisk newdisk ","date":"2021-12-03","objectID":"/libguestfs/:23:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"linux上使用udev创建裸设备 需求和分析 在一次项目中需要将进行oracle数据库的备份，要求在oracle机器总是能认到备份的块设备的路径以保证备份和恢复的正常。同时还需要对磁盘进行修改，转化中asm格式的。 基于这种情况下，在linux中将磁盘转化成对应的裸设备是一种合适的方法。 简单的操作就是将配置写入/etc/udev/rule.d/1401-oracle-asmdevice.rules文件中，让udev管理。 udev 规则的匹配键 ACTION： 事件 (uevent) 的行为，例如：add( 添加设备 )、remove( 删除设备 )。 KERNEL： 内核设备名称，例如：sda, cdrom。 DEVPATH：设备的 devpath 路径。 SUBSYSTEM： 设备的子系统名称，例如：sda 的子系统为 block。 BUS： 设备在 devpath 里的总线名称，例如：usb。 DRIVER： 设备在 devpath 里的设备驱动名称，例如：ide-cdrom。 ID： 设备在 devpath 里的识别号。 SYSFS{filename}： 设备的 devpath 路径下，设备的属性文件“filename”里的内容。 例如：SYSFS{model}==“ST936701SS”表示：如果设备的型号为 ST936701SS，则该设备匹配该 匹配键。 在一条规则中，可以设定最多五条 SYSFS 的 匹配键。 ENV{key}： 环境变量。在一条规则中，可以设定最多五条环境变量的 匹配键。 PROGRAM：调用外部命令。 RESULT： 外部命令 PROGRAM 的返回结果。 配置文件 这里是CentOS 6的版本 [root@rac1 ~]# cat /etc/udev/rules.d/99-oracle-asmdevice.rules KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000020fa8\",NAME+=\"oracleasm/disks/HL_360000000000000000e00000000020fa8\",OWNER=\"grid\",GROUP=\"asmadmin\",MODE=\"0660\" 然后加载配置文件 [root@rac1 ~]# start_udev 正在启动 udev： [确定] [root@rac1 ~]# ll /dev/oracleasm/disks 总用量 0 brw-rw---- 1 grid asmadmin 8, 16 1月 23 14:30 HL_360000000000000000e00000000020fa8 注意 在CentOS6和CentOS7的配置有所不同。 一个是scsi_id命令，还有是udev规则变化。 KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000160fa8\",RUN+=\"/bin/sh -c 'mkdir -pv /dev/oracleasm/disks;mknod /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8 b 1 3; chown grid:oinstall /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8; chmod 0660 /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8'\" scsi_id命令需要安装systemd包，如果知道命令对应的软件包名称，可以使用yum命令查看 yum provides \"/*/scsi_id\" udev需要使用RUN来代替NAME，在RUN中能使用linux的命令，使用；分隔多个命令。 mknod是CentOS7中转化设备的新命令，格式为： mknod /dev/sdb \u003cDEVICE_TYPE\u003e \u003c主设备号\u003e \u003c次设备号\u003e 同时修改udev的命令也发生了变化。 [root@localhost ~]# /usr/sbin/udevadm trigger --type=devices --action=change 在同时添加多个设备时，后添加的设备同步较慢。比较好的方法是先全部添加到.rules文件中，最后再执行udevadm trigger加载。 ","date":"2021-12-03","objectID":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/:0:0","tags":null,"title":"linux上使用udev创建裸设备","uri":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/"},{"categories":null,"content":"Linux中断和异常 中断(interrupt)通常被定义为一个事件，该事件改变处理器执行的指令顺序。这样的事件与CPU芯片内外部硬件电路产生的点信号相对应。 中断通常分为同步 (synchronous) 中断和异步 (asynchornous) 中断: 同步中断是当指令执行时由 CPU 控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后 CPU 才会发出中断。 异步中断是由其他硬件设备依照 CPU 时钟信号随机产生的。 在 Intel 微处理器中，把同步和异步中断分别称为异常 (exception) 和中断 (interrupt)。 中断是由间隔定时器和I/O设备产生的，异常是由程序的错误产生的，或者是由内核必须处理的异常条件产生的。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:0:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"中断信号的作用 中断信号提供了一种特殊的方式，使处理器转而去运行正常控制流之外的代码。当一个中断信号达到是，CPU 必须停止它当前正在做的事情，并且切换到一个新的活动。所以要在内核态堆栈保存程序计数器的当前值(即eip和cs寄存器的内容)，并把与中断类型相关的一个地址放进程序计数器。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:1:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"中断和异常 中断: 可屏蔽中断 (maskable interrupt) : I/O 设备发出的所有中断请求(IRQ)都产生可屏蔽中断。可屏蔽中断可以处于两种状态: 屏蔽的 (masked) 或非屏蔽的 (unmasked)；一个屏蔽的中断只要还是屏蔽的，控制单元就忽略它。 非屏蔽中断 (nonmaskable interrupt) : 只有几个危急事件(如硬件故障)才引起非屏蔽中断。非屏蔽中断总是由CPU辨认。 异常: 处理器探测异常(processor-detected exception) : 当 CPU 执行指令时探测到一个反常条件所产生的异常。可以进一步分为三组，这取决于CPU控制单元产生异常是保存在内核态堆栈eip寄存器中的值。它们分别是故障(fault)、陷阱(trap) 和异常中止(abort)。 编程异常(programmed exception) : 在编程者发出请求时发生。是由 int 或 int3 指令触发的。当 into(检查溢出)和 bound(检查地址出界)指令查询的条件不为真时，也引起编程异常。控制单元把编程异常作为陷阱来处理。编程异常通常也叫做软中断(software interrupt)。这样的异常有两种常用的用途: 执行系统调用和给调试程序通报一个特定的事件。 处理器探测的异常: 故障: 通常可以纠正。一旦纠正，程序就可以在不失连贯性的情况下重新开始。保存在 eip 中的值是引起故障的指令地址。因此，当异常处理程序终止时，那条指令会被重新执行。 陷阱: 在陷阱指令执行后立即报告。内核把控制权返回给程度后就可以继续它的执行而不失连贯性。保存在 eip 中的值是一个随后要执行的指令地址。只有当没有必须要重新执行以终止的指令时，才触发陷阱。陷阱的主要用途是为了调试程序。 异常中止: 发送一个严重的错误，控制单元出了问题，不能在 eip 寄存器中保存引起异常的指令所在的确切位置。异常中止用于报告严重的错误，如硬件故障或系统表中无效的值或不一致的值。由控制单元发送的这个中断信号时紧急信号，用来把控制权切换到相应的异常中止处理程序，这个异常中止处理程序除了强制受影响的进程中止外，没有别的选择。 每个中断和异常是由0~255之间的一个数来标识。Intel 把这个8位的无符号整数叫做一个向量(vector)。非屏蔽中断的向量和异常的向量是固定的，而可屏蔽中断的向量可以通过对中断控制器的编程来改变。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:2:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"Linux内存 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:0:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内存概论 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"虚拟内存 虚拟内存(virtual memory)是 Unix 系统中一种对内存的抽象。虚拟内存作为一种逻辑层，处于应用程序的内存请求与硬件内存管理单元(Memory Management Unit, MMU)之间。虚拟内存有很多用途和优点: 若干个进程可能并发地执行。 应用程序所需内存大于可用物理内存时也可以运行。 程序只有部分代码装入内存时进程可以执行它。 允许每个进程访问可用物理内存的子集。 进程可以共享库函数或程序的一个单独内存映象。 程序时可重定位的，也就是说，可以把程序放在物理内存的任何地方。 程序员可以编写与机器无关的代码，因为他们不必关心有关物理内存的组织结构。 虚拟内存子系统的主要成分是虚拟地址空间(virtual address space)的概念。进程所用的一组内存地址不同于物理内存地址。当进程使用一个虚拟地址时，内核和MMU协同定位其在内存中的实际物理地址位置。 现在的 CPU 包含了能自动把虚拟地址转换成物理地址的硬件电路。为了达到这个目标，把可用 RAM 划分成长度为 4KB 或 8KB 的页框(page frame)，并引入一组页表来指定虚拟地址与物理地址之间的对应关系。 一块连续的虚拟地址请求可以通过分配一组非连续的物理地址页框而得到满足。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"随机访问存储器(RAM)的使用 Unix 操作系统将 RAM 划分成两部分。其中若干兆字节专门用于存放内核映象(也就是内核代码和内核静态数据结构)。RAM的其余部分通常由虚拟内存系统来处理，并且用在以下三种可能的方面: 满足内核对缓冲区，描述符及其他动态内存数据结构的请求。 满足进程对一般内存区的请求及对文件内存映射的请求。 借助与高速缓存从磁盘及其他缓冲设备获得较好的性能。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内核内存分配器 内核内存分配器(Kernel Memory Allocator, KMA)是一个子系统，它试图满足系统中部分对内存的请求。其中一些请求来自内核其他子系统，它们需要一些内核使用的内存，还有一些请求来自于用户程序的系统调用，用来增加用户进程中地址空间。一个好的 KMA 应该具有下列特点: 必须快。因为它由所有的内核子系统(包括中断处理程序)调用。 必须把内存的浪费减到最少。 必须努力减轻内存的碎片(fragmentation)问题。 必须能与其他内存管理子系统合作，以便借用和释放页框。 基于不同的算法技术实现的KMA: 资源图分配算法(allocator) 2的幂次方空闲链表 McKusick-Karels 分配算法 伙伴 (Buddy) 系统 Mach 的区域 (Zone) 分配算法 Dynix 分配算法 Solaris 的 Slab 分配算法 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"进程虚拟地址空间处理 进程的虚拟地址空间包括了进程可以引用的所有虚拟内存地址。内核通常用一组内存区描述符描述进程虚拟地址空间。例如，当进程通过 exec() 类系统调用开始某个程序执行时，内核分配给进程的虚拟地址空间有以下内存区组成。 程序的可执行代码。 程序的初始化数据。 程序的未初始化数据。 初始程序栈(即用户态栈)。 所需共享库的可执行代码和数据。 堆(由程序董太太请求的内存)。 现代 Unix 操作系统采用了请求调页(demand paging)的内存分配策略。有了请求调页，进程可以在它的页还没有在内存时就开始执行。当进程访问一个不存在的页时，MMU产生一个异常，异常处理程序找到受影响的内存区，分配一个空闲的页，并用适当的数据把啊初始化。同理，当进程通过调用 malloc() 或 brk()(由malloc()在内部调用)系统调用动态地请求内存是，内核仅仅修改进程的堆内存区的大小。只有试图引进进程的虚拟内存而产生异常时，才给进程分配页框。 虚拟地址空间也采用其他更有效的策略，如写时复制策略。例如，当一个新进程被创建时，内核仅仅把父进程的页框赋给子进程的地址空间，但是把这些页框标记为只读。一旦父或子进程修改页中的内容时，一个异常就会产生。异常处理程序把新页框赋给受影响的进程，并用原来也中的内容初始化新页框。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:4","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"高速缓存 物理内存的一大优势就是用作磁盘和其他块设备的高速缓存。通常，在最早的 Unix 系统中就已经实现的一个策略是: 尽可能地推迟写磁盘的时间，因此，从磁盘读入内存的数据即使任何进程都不再使用它们，它们也继续留在 RAM 中。 新进程请求从磁盘读或写的数据，就是被撤销进程曾拥有的数据。当一个进程请求访问磁盘时，内核首先检查进程请求的数据是否在缓存中，如果在(把这种请求叫做缓存命中)，内核就可以为进程请求提供服务而不用访问磁盘。 sync() 系统调用把所有\"脏\"的缓冲区写入磁盘来强制磁盘同步。为了避免数据丢失，所有的操作系统都会注意周期性地把脏缓存区写回磁盘。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:5","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内存地址 x86微处理器的三种不同地址: 逻辑地址(logical address): 每一个逻辑地址都由一个段(segment)和偏移量(offset或displacement)组成，偏移量指明了从段开始的地方到实际地址之间的距离。 线性地址(linear address)(也称虚拟地址 virtual address): 线性地址通常用十六进制数字表示，值得范围从 0x00000000 到 0xffffffff。可以表示高达 4GB 的地址。 物理地址(physical address): 用于芯片级内存单元寻址。他们从微处理器的地址引脚发送到内存总线上的电信号相对应。 内存控制单元(MMU)通过分段单元(segmentation unit)的硬件电路把一个逻辑地址转换成线性地址。通过分页单元(paging unit)的硬件电路把线性地址转化成物理地址。 在多处理器系统中，所有 CPU 都共享同一内存。RAM芯片上的读和写操作必须串行执行，因此内存仲裁器(memory arbiter)的硬件电路插在总线和每个 RAM 芯片之间。其作用就是如果某个 RAM 芯片空闲，就准予一个 CPU 访问，如果该芯片忙于为另一个处理器提出的请求服务，就延迟这个 CPU 的访问。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:2:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件中的分段 80206 开始，Intel 微处理器具有两种方式执行地址转换： 实模式(real mode)。 保护模式(protected mode)。 实模式存在是处于兼容性考虑，主要还是保护模式。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"段选择符和段寄存器 一个逻辑地址由两部分组成：一个段标识符和一个指定段内相对地址的偏移量。段标识符是一个 16 位长的字段，称为段选择符(Segment Selector)。偏移量是一个 32 位长的字段。 专门存放段选择符的寄存器: cs, ss, ds, es, fs 和 gs。其中3个有专门的用途: cs 代码段寄存器，指向包含程序指令的段。 ss 栈段寄存器，指向包含当前程序栈的段。 ds 数据段寄存器，指向包含静态数据或者全局数据段。 其他3个段寄存器作一般用途，可以指向任意的数据段。 cs 寄存器还有一个很重要的功能: 它含有一个两位的字段，用以指明 CPU 的当前特权级 (Current Privilege Level, CPL)。值为0代表最高优先级，为值为3代表最低优先级。Linux 只用0级和3级，分别称之为内核态和用户态。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"段描述符 每个段由一个8字节的段描述符(Segment Descriptor)表示，它描述了段的特征。段描述符放在全局描述符表(Global Descriptor Table, GDT)或局部描述符表(Local Descriptor Table, LDT)中。 GDT 通常只有一个，在主存中的地址和大小存放在 gdtr 控制寄存器中，当前正被使用的 LDT 地址和大小放在 ldtr 控制寄存器中。 段描述符字段 字段 含义 Base 包含段的首字节的线性地址 G 粒度标志：如果改位清0，则大小以字节为单位，否则以4096字节的倍数计。 Limit 存放段中最后一个内存单元的偏移量，从而决定段的长度。如果 G 被置为0，则一个段的大小在1个字节到1MB之间变化；否则，将在 4KB 到 4GB 之间变化。 S 系统标志：如果它被清0，则这是一个系统段，存储诸如 LDT 这种关键的数据结构，否则它是一个普通的代码段或数据段。 Type 描述了段的类型特征和它的存取权限。 DPL 描述符特权级(Descriptor Privilege Level)字段：用于限制对这个段的存取。它表示为访问这个段而要求的CPU最小的优先级。因此，DPL设为0的段只能当 CPL 为0时(即在内核态)才是可访问的，而DPL设为3的段对任何CPL值都是可访问的 P Segment-Present标志：等于0表示段当前不在主存中。Linux总是把这个表示(第47位)设为1，因为它从来不把整个daunt交换到磁盘上去。 D 或 B 称为D或B的标志，取决于代码段还是数据段。D或B的含义在两种情况中有所区别，但是如果段偏移量的地址是32位长，就基本上把它置为1，如果这个偏移量是16位长，它被清0。 AVL 标志 可以由操作系统使用，但是被 Linux 忽略。 Linux 中被广泛采用的类型: 代码段描述符 数据段描述符 任务状态段描述符 段选择符字段: 字段 含义 index 指定了放在 GDT 或 LDT 中的相应段描述符的入口。 TI TI ((Table Indicator)标志：指明段描述符是在 GDT 中 (TI=0) 或在 LDT 中(TI=1))。 RPL 请求者特权级：当相应的段选择符装入到 cs 寄存器中时，指示出 CPU 当前的特权级；它还可以用于在访问数据段时有选择地削弱处理器的特权级。 为了加速逻辑地址到线性地址的转换，80x86处理器提供一种附加的非编程的寄存器，供6个可编程的段寄存器使用。现在，针对那个段的逻辑地址转化就可以不访问主存中的 GDT 或 LDT，处理器只需直接引用存放段描述符的CPU寄存器即可。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"分段单元 分段单元(segmentation unit)执行以下操作，将一个逻辑地址转换成相应的线性地址。 先检查段选择符的TI字段，以决定段描述符保存在哪一个描述表中。TI字段指明描述符是在GDT中(在这种情况下，分段单元从gdtr寄存器中得到GDT的线性基地址)还是在激活的LDT中(在这种情况下，分段单元从ldtr寄存器中得到LDT的线性基地址)。 从段选择符的 index 字段计算段描述符的地址，index字段的值乘以8(一个段描述符的大小)，这个结果与gdtr或ldtr寄存器中的内存相加。 把逻辑地址的偏移量与段描述符 Base 字段的值相加就得到了线性地址。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux 中的分段。 Linux 中使用分段的方式十分有限。分段可以给每个进程分配不同的线性地址空间，而分页可以把同一线性地址空间映射到不同的物理空间。与分段相比，Linux 中倾向采用分页方式，因为: 当所有的进程使用相同的段寄存器值时，内存管理变得更简单，也就是说它们能共享同样的一组线性地址。 Linux 设计目标之一是可以把它移植到绝大多数流行的处理器平台上。然而，RISC体系结构对分段的支持很有限。 2.6 版的 Linux 只有在 80x86 结构下才需要使用分段。 相应的段选择符由宏 __USER_CS, __USER_DS, __KERNEL_CS 和 __KERNEL_DS 分别定义。例如，为了对内存代码段寻址，内核只需要把 __KERNEL_CS 宏产生的值装进 cs 段寄存器即可。 所有段都从 0x00000000 开始，这可以得出另一个重要的结论，就是在 Linux 下逻辑地址与线性地址是一致的，机逻辑地址的偏移量字段的值与相应的线性地址的值总是一致的。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux GDT 在单处理器系统中只有一个 GDT，而在多处理器系统中每个 CPU 对应一个 GDT。所有的 GDT 都存放在 cpu_gdt_table 数组中。以下是 GDT 的布局示意图。每个 GDT 包含 18 个段描述符合 14 个空的，未使用的，或保留的项。 每一个 GDT 中包含 18 个段描述符指向下列的段: 用户态和内核态下的代码段和数据段共 4 个。 任务状态段 (TSS)，每个处理器有 1 个。 1 个包括缺省局部描述符表的段。 3 个局部线程存储。 与高级电源管理 (AMP) 相关的 3 个段。 与支持即插即用 (PnP) 功能的 BIOS 服务程序相关的 5 个段。 被内核用来处理“双重错误”(处理一个异常是可能引发另一个异常，在这个情况下产生的双重错误)异常的特殊 TSS 段。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux LDT 大多数用户态下的 Linux 程序不使用局部描述符表，这样内核就定义了一个缺省的 LDT 供大多数进程共享。缺省的局部描述符表存放在 default_ldt 数组中。 在某些情况下，进程仍然需要创建自己的局部描述符表，这对有些应用程序很有用，如 Wine 程序。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件中的分页 分页单元(paging unit)把线性地址转换成物理地址。线性地址被分成以固定长度为单位的组，称为页(page)。页内部连续的线性地址被映射到连续的物理地址中。 分页单元把所有的 RAM 分成固定长度的页框 (page frame) (有时叫做物理页)。每一个页框包含一个页 (page)，页就是说一个页框的长度与一个页的长度一致。 把线性地址映射到物理地址的数据结构称为页表 (page table)。页表放在主存中，并在启用分页单元之前必须由内核对页表进行适当的初始化。 从 80386 开始，所有的 80x86 处理器都支持分页，它通过设置 cr0 寄存器的 PG 标志启用。 当 PG=0 时，线性地址就被解释成物理地址。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"常规分页 从 80386 起，Intel 处理器的分页单元处理 4K 的页。 32 位的线性地址被分成 3 个域: Directory (目录) 最高 10 位。 Table (页表) 中间 10 位。 Offset (偏移量) 最低 12 位。 线性地址的转换分两步完成，每一步都基于一种转化表，第一种转换表称为页目录表 (page directory)，第二种转换表称为页表 (page table)。 正在使用的页目录的物理地址存放在控制寄存器 cr0 中。线性地址内的 Directory 字段决定目录中的目录项，而目录项指向适当的页表。地址的 Table 字段依次又决定页表中的表项，而表项含有页所在页框的物理地址。Offset 字段决定页框也的相对位置。由于它是 12 长，故每一页含有 4096 字节的数据。 假设进程需要读线性地址 0x20021406 中的字节。这个地址由分页单元按下面的方法处理: Directory 字段的 0x80 用于选择页目录的第 0x80 目录项，此目录项指向和该进程的页相关的页表。 Table 字段 0x21 用于选择页表的第 0x21 表项，此表项指向包含所需页的页框。 最后，Offset 字段 0x406 用于在目标页框中读偏移量为 0x406 中的字节。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件高速缓存 当今的微处理器时钟频率接近几个 GHz，而动态 RAM 芯片的存取时间是时钟周期的数百倍。这意味着，当从 RAM 中取操作数或向 RAM 中存放结果这样的指令执行时，CPU 可能登台很长时间。 为了缩小 CPU 和 RAM 之间的速度不匹配，引入了硬件高速缓存内存(hardware cache memory)。硬件高速缓存基于著名的局部性原理(locality principle)，该原理既适用程序结构也适用数据结构。 80x86 体系结构中引入了一个叫行 (line) 的新单位。行由几十个连续的字节组成，它们以脉冲突发模式 (burst mode) 在慢速 DRAM 和快速的用来实现高速缓存的片上静态 RAM (SRAM) 之间传送，用来实现高速缓存。 如图，高速缓存单元插在分页单元和主内存之间。它包含一个硬件高速缓存内存 (hardware cache memory) 和一个高速缓存控制器 (cache controller)。高速缓存内存存放内存中真正的行。高速缓存控制器存放一个表项数组，每个表项对应高速缓存内存中的一个行。每个表项有一个标签(tag)和描述高速缓存行状态的几个标志(flag)。这种内存物理地址通常分为3组：最高几位对应标签，中间几位对应高速缓存控制器的子集索引，最低几位对应行内的偏移量。 当访问一个 RAM 存储单元时，CPU 从物理地址中提取出子集的索引号并把子集中所有行的标签与物理地址的高几位相比较。如果发现某一个行的标签与这个物理地址的高位相同，则 CPU 命中一个高速缓存 (cache hit)；否则，高速缓存没有命中 (cache miss)。 对于读操作，控制器从高速缓存行中选择数据并送到 CPU 寄存器。对于写操作，控制器可能采用以下两个基本策略之一: 通写(write-through): 控制器总是既写 RAM 也写高速缓存行，为了提高写操作的效率关闭高速缓存。 回写(write-back): 只更新高速缓存行，不改变 RAM 的内存，提供了更快的效率。 处理器的 cr0 寄存器的 CD 标志位用来启用或禁用高速缓存电路。这个寄存器中的 NW 标志指明高速缓存是使用通写还是回写策略。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux 中的分页 Linux 采用了一种同时适用于32位和64位的普通分页模型。在 2.6.10 版本之前，Linux 采用三级分页的模型。从 2.6.11 版本开始，采用了四级分页模型: 页全局目录 (Page Global Directory) 页上级目录 (Page Upper Directory) 页中间目录 (Page Middle Directory) 页表 (Page Table) 页全局目录包含若干页上级目录的地址，页上级目录有一次包含若干页中间目录的地址，而页中间目录又包含若干页表的地址。每一个页表项指向一个页框。线性地址因此被分成五个部分。 Linux 的进程处理很大程度上依赖于分页。事实上，线性地址到物理地址的自动转换使下面的设计目标变得可行: 给每一个进程分配一块不同的物理地址空间，这确保了可以有效地防止寻址错误。 区别页(即一组数据)和页框(即主存中的物理地址)的不同。这就允许存放在某个页框中的一个页，然后保存到磁盘上，以后重新装入这同一页是又可以被装载不同的页框中。这就是虚拟内存机制的基本要素。 每一个进程有它自己的页全局目录和自己的页表集。当发生进程切换时，Linux 把 cr3 控制寄存器的内存保存在前一个执行进程的描述符中，然后把下一个要执行进程的描述符的值装入 cr3 寄存器中。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"线性地址字段 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"页表处理 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"物理内存布局 在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用。 内核将下列页框记为保留: 在不可用的物理地址范围内的页框。 含有内核代码和已初始化的数据结构的页框。 从 0x07ff0000 到 0x07ff2fff 的物理地址范围中存有加电自检(POST)阶段由BIOS写入的系统硬件设备信息。在初始化阶段，内核把这些信息拷贝到一个合适的内核数据结构中，然后认为这些页框是可用的。相反，从 0x07ff3000 到 0x07ffffff 的物理地址范围被映射到硬件设备的 ROM 芯片。从 0xffff0000 开始的物理地址范围标记为保留，因为它由硬件地址映射到 BIOS 的 ROM 芯片。 Linux 用 PC 体系结构未保留的页框来动态存放所分配的页。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"进程页表 进程的线性地址空间分成两部分: 从 0x00000000 到 0xbfffffff 的线性地址，无论进程运行在用户态还是内核态都可以寻址。 从 0xc0000000 到 0xffffffff 的线性地址，只有内核态的进程才能寻址。 当进程运行在用户态时，它产生的线性地址小于 0xc0000000；当进程运行在内核态时，它执行内核代码，所产生的地址大于等于 0xc0000000。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:4","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内核页表 内核维持着一组自己使用的页表，驻留在主内核页全局目录(master kernel Page Global Directory)中。 内核如何初始化自己的页表: 内核创建一个有限的地址空间，包括内核的代码段和数据段、初始页表和用于存放动态数据结构的128KB大小的空间。这个最小限度的地址空间仅够将内核装入RAM和对其初始化的数据结构。 内核充分利用剩余的RAM并适当地建立分页表。 建立分页表的详细步骤: 临时页全局目录放在 swapper_pg_dir 变量中，临时页表在 pg0 变量出开始存放，紧接在内核未初始化的数据段后面。内核在初始化的第一阶段，可以通过与物理地址相同的线性地址或者通过从 0xc0000000 开始的 8MB 线性地址对 RAM 的前 8MB 进行寻址。 内核通过把 swapper_pg_dir 所有项都填充为0来创建期望的映射，0、1、0x300(768)和0x301(769)除外，它们的初始化如下： 0 项和 0x300 项的地址字段置为 pg0 的物理地址，而 1 项和 0x301 项的地址字段置为紧随 pg0 后的页框的物理地址。 把这四个项中的 Present、Read/Write 和 User/Supervisor 标志置零。 把这四个项中的 Accessed、Dirty、PCD、PWD 和 Page Size 标志请0。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:5","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"固定映射的线性地址 我们看到内核线性地址第四个GB的初始化部分映射系统的物理内存。但是，至少128MB的线性地址总是留作它用，因为内核使用这些线性地址实现非连续内存分配和固定映射的线性地址。 固定映射的线性地址(fix-mapped linear address)基本上是一种类似于 0xffffc000 这样的常量线性地址，其对应的物理地址不必等于线性地址减去 0xc000000。内核使用固定映射的线性地址来代替指针变量，因为这些指针变量的值从不改变。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:6","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux内核同步 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:0:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"内核抢占 抢占内核的主要特点是: 一个在内核态运行的进程，可能在执行内核函数期间被另外一个进程取代。 用实例来说明抢占内核和非抢占内核的区别: 在进程A执行异常处理程序时，一个具有较高优先级的进程B变为可执行状态。这种情况是有可能出现的，例如，发生了中断请求而且相应的处理程序唤醒了进程B。如果内核是抢占的，就会发生强制性进程切换，让进程B取代进程A。异常处理程序的执行被暂停，直到调度程序再次选择进程A时才恢复它的执行。相反，如果内核是非抢占的，在进程A完成异常处理程序的执行之前，是不会发生进程切换的，除非进程A自动放弃CPU。 一个执行异常处理程序的进程已经用完了它的时间配额，如果内核是抢占的，进程可能会立即被取代，但如果内核是非抢占的，进程继续运行直到它执行完异常处理程序或自动放弃CPU。 使内核可抢占的目的是减少用户态进程的分派延迟(dispatch letency)，即从进程变为可执行状态到它实际开始运行之间的时间间隔。 只有当内核正在执行异常处理程序(尤其是系统调用)，而且内核抢占没有显式地禁用时，才可能抢占内核。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:1:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"同步原语 技术 说明 适用范围 每CPU变量 在CPU之间复制数据结构 所有CPU 原子操作 对一个计数器原子地\"读-修改-写\"的指令 所有CPU 内存屏障 避免指令重新排序 本地CPU或所有CPU 自旋锁 加锁时忙等 所有CPU 信号量 加锁时阻塞等待(睡眠) 所有CPU 顺序锁 基于访问计数器的锁 所有CPU 本地中断的禁止 禁止单个CPU上的中断处理 本地CPU 本地软中断的禁止 禁止单个CPU上的可延迟函数处理 本地CPU 读-拷贝-更新(RCU) 通过指正而不是锁来访问共享数据结构 所有CPU ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"每CPU变量 最简单也是最重要的同步技术包括把内核变量声明为每CPU变量(per-cpu variable)。每CPU变量主要是数据结构的数组变量主要是技术结构的数组，系统的每个CPU对应数组的一个元素。 虽然每CPU变量为来自不同CPU的并发访问提供保护，但对来自异步函数(中断处理程序和可延迟函数)的访问不提供保护，在这种情况下需要另外的同步原语。 此外，在单处理器和多处理器系统中，内核抢占都可能是每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:1","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"原子操作 通过原子操作指令完成。 80x86 指令: 进行零次或一次对齐内存访问的汇编指令是原子的。 如果在读操作之后，写操作之前没有其他处理器占用内存总线，那么从内存中读取数据，更新数组并把更新后数组写回内存中的这些\"读-修改-写\"汇编语言指令(例如inc或dec)是原子的。当然，在单处理器系统中，永远都不会发生内存总线窃用的情况。 操作吗前缀是 lock 字节(0xf0)的\"读-修改-写\"汇编语言指令即使在多处理器系统中也是原子的。当控制单元检测到这个前缀时，就\"锁定\"内存总线，知道这条指令执行完成为止。因此，当加锁的指令执行时，其他处理器不能访问这个内存单元。 操作码前缀是一个rep字节(0xf2,0xf3)的汇编语言执行不是原子的，这条指令强行让控制单元多次重复执行相同的指令。控制单元在执行新的循环之前要检查挂起的中断。 Linux 内核提供了一个专门的 atomic_t 类型(一个原子访问计数器)和一些专门的函数和宏，这些函数和宏作用于 atomic_t 类型的变量，并当作单独的、原子的汇编语言指令来使用。在多处理器系统中，每条这样的指令都有一个 lock 字节的前缀。 另一类原子函数操作作用于位掩码 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:2","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"优化和内存屏障 当使用优化的编译器时，编译器可能重新安排汇编语言指令已使寄存器以最优的方式使用。此外，现代CPU通常并行地执行若干条指令，且可能重新安排内存访问。然而，当处理同步时，必须避免指令重新排序。 优化屏障(optimization barrier) 原语保证编译程序不会混淆放在原语操作之前的汇编语言指令和放在原语操作之后的汇编语言指令，这些汇编语言指令在C中都有对应的语句。在Linux中，优化屏障就是 barrier() 宏，它展开 asm volatile(\"\":::\"memory\") 。指令 asm 告诉编译程序要插入汇编语言片段(这种情况下为空)。volatile 关键字禁止编译器把asm指令与程序中的其他指令重新组合。memory 关键字强制编译器假定RAM中的所有内存单元已经被汇编语言指令修改。 内存屏障(memory barrier)原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，内存屏障类似于防火墙，让任何汇编语言指令都不能通过。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:3","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"自旋锁 自旋锁(spin lock)是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁\"开着\"，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径\"锁着\"，就在周围\"旋转\"，反复执行一条紧凑的循环指令，直到锁被释放。 自旋锁的循环指令表示\"忙等\"。即使等待的内核控制路径无事可做，它也在CPU上保持运行。不过，自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时间片段；所以说，释放CPU和随后有获得CPU都不会消耗多少时间。 一般来说，由自旋锁保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这中锁本身并不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。需要注意的是，自旋转忙等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进程替代。 读/写自旋锁 读/写自旋锁的引入是为了增加是内核的并发能力。只要没有内核控制路径对数据结构进行修改，读/写自旋锁就允许多个内核控制路径同时读同一数据结构。如果一个内核控制路径想对这个结构进行写操作，那么它必须首先获取读/写锁的写锁，写锁授权独占访问这个资源。当然，允许对数据结构并发读可以提高系统性能。 顺序锁 Linux 2.6 中引入顺序锁(seqlock)，它与读/写自旋锁非常相似，只是它为写者赋予了较高的优先级；事实上，即使在读者正在读的时候，也允许写者继续运行。这种策略的好处是写者永远不会等待(除非另外一个写者正在写)，缺点是有些时候读者不得不反复多次读相同的数据直到它获得有效的副本。 每个读者都必须在读数据前后两次读顺序计数器，并检查零次读到的值是否相同，如果不相同，说明新的写者已经开始写并增加了顺序计数器，因此暗示读者刚读到的数据是无效的。 一般来说，必须在满足下述条件是才能使用顺序锁: 被保护的数据结构不包括被写者修改和被读者间接引用的指针。 读者的临界代码没有副作用。 读-拷贝-更新(RCU) 读-拷贝-更新(RCU)是为了保护在多数情况下被多个CPU读的数据结构而设计的零一种同步技术。RCU允许多个读者和写者并发执行(相对于只允许一个写者执行的顺序锁有了改进)。而且，RCU是不使用锁的，就是说，它不使用被所有CPU共享的锁或计数器，在这一点上与读/写自旋锁和顺序锁(由于高速缓存行窃用和失效有很高的开销)相比，RCU 具有更大的优势。 RCU 是如何不是用共享数据结构而令人惊讶地实现多个CPU同步呢？其关键的思想包括限制RCU的范围，如下所述: RCU 只保护被动态分配并通过指针引用的数据结构。 在被 RCU 保护的临界区中，任何内核控制路径都不能睡眠。 当内核控制路径要读取 RCU 保护的数据结构时，执行 rcu_read_lock()，它等同于 preempt_disable()。接下来，读者间接引用该数据结构指针所对应的内存单元并开始读这个数据结构。正如在前面所强调的，读者在完成对数据结构的读操作之前，是不能睡眠的。用等同于 preempt_enable() 的宏 rcu_read_unlock() 标记临界区的结束。 由于读者几乎不做任何事情来防止竞争条件的出现，所以写者不得不做得更多一些。事实上，当写者要更新数据结构是，它间接引用指针并生成整个数据结构的副本。接下来，写者修改这个副本。一旦修改完毕，写者改变指向数据结构的指针，以使它指向被修改后的副本。由于修改指针值的操作是一个原子操作，所以旧副本和新副本对每个读者或写者都是可见的，在数据结构中不会出现数据崩溃。尽管如此，还需要内存屏障来保证: 只有在数据结构被修改之后，已更新的指针对其他CPU才是可见的，如果把自旋锁与RCU结合起来以禁止写者的并发执行，就隐含地引入了这样的内存屏障。 然而，使用 RCU 技术的真正困难在于: 写者修改指针时不能立即释放数据结构的就副本。实际上，写者开始修改时，正在访问数据结构的读者可能还在读副本。只有在CPU上所有(潜在的)读者都执行完宏 rcu_read_unlock() 之后，才可以释放就副本。内核要求每个潜在的读者在下面的操作之前执行 rcu_read_unlock() 宏: CPU 执行进程切换 CPU 开始在用户态执行 CPU 执行空循环 对上述每种情况，我们说CPU已经过了静止状态(quiescent state)。 写者调用函数 call_rcu() 来释放数据结构的就副本。当所有的 CPU 都通过静止状态之后，call_rcu() 接受 rcu_head 描述符的地址和将要调用的回调函数的地址作为参数。一旦回调函数被执行，它通常释放数据结构的就副本。 函数 call_rcu() 把回调函数和其参数的地址存放在 rcu_head 描述符中，然后把描述符插入回调函数的每个 CPU (per-CPU) 链表中。内核每经过一个时钟滴答就周期性地检查本地CPU是否进过了一个静止状态。如果所有CPU都经过了静止状态，本地 tasklet (它的描述符存放在每CPU变量 rcu_tasklet 中)就执行链表中的所有回调函数。 RCU 是 Linux 2.6 中新加的功能，用在网络层和虚拟文件系统中。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:4","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"信号量 Linux 提供两种信号量 : 内核信号量，由内核控制路径使用。 System V IPC 信号量，由用户态进程使用。 内核信号量类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。然而，当内核控制路径试图获取内核信号量所保护的忙资源时，相应的进程被挂起。只有在资源被释放时，进程才再次变为可运行的。因此，只有可以睡眠的函数才能获取内核信号量；中断处理程序和可延迟函数都不能使用内核信号量。 内核信号量是 struct semaphore 类型的对象，包含下面这些字段: count: 存放 atomic_t 类型的一个值。如果该值大于 0，那么资源就是空闲的，也就是说，该资源现在可以使用。相反，如果 count 等于0。那么信号量是忙的，但没有进程等待这个被保护的资源。最后，如果 count 为负数，则资源时不可用的，并至少有一个进程等待资源。 wait: 存放等待队列链表的地址，当前等待资源的所有睡眠进程都放在这个链表中。当然，如果 count 大于或等于 0，等待队列就为空。 sleepers: 存放一个标志，表示是否有一些进程在信号量上睡眠。 可以用 init_MUTEX() 和 init_MUTEX_LOCKED() 函数来初始化互斥访问所需的信号量。 当进程希望释放内核信号量锁时，就调用 up() 函数。相反，当进程希望获取内核信号获取内核信号量锁时，就调用 down() 函数。 读/写信号量类似于\"读/写自旋锁\"，不同的是：在信号量再次变为打开之前，等待进程挂起而不是自旋。 很多内核控制路径为读可以并发地获取读/写信号量。但是，任何写者内核控制路径必须有被保护资源的互斥访问。因此，只有在没有内核控制路径为读访问或写访问持有信号量时，才可以为写获取信号量。读/写信号量可以提供内核中的并发度，并改善了这个系统的性能。 内核以严格的FIFO顺序处理等待读/写信号量的所有进程。如果读者或写者进程发现信号量关闭，这些进程就被插入到信号量等待队列链表的末尾。当信号量被释放时，就检查处于等待队列链表第一个位置的进程。第一个进程常被唤醒。如果是一个写者进程，等待队列上其他的进程就继续睡眠。如果是一个读者进程，那么紧跟第一个进程的其他所有读者进程也被唤醒并获得锁。不过，在写者进程之后排队的读者进程继续睡眠。 每个读/写信号量都是由 rw_semaphore 结构描述的，它包含下列字段: count: 存放两个16位计数器。其中最高16位计数器以二进制补码形式存放非等待写者进程的总数(0或1)和等待的写内核控制路径数。最低16位计数器存放非等待的读者和写者的总数。 wait_list: 指向等待进程的链表。链表中的每个元素多是一个 rwsem_waiter 结构，该结构包含一个指针和一个标志，指针指向睡眠进程的描述符，标志表示进程是为读需要信号量还是为需要信号量。 wait_lock: 一个自旋锁，用户保护等待队列链表和 rw_semphore 结构本身。 down_read() 和 down_write() 函数分别为读或写获取读/写信号量。同样，up_read() 和 up_write() 函数为读或写释放以前获取的读/写信号量。 down_read_trylock() 和 down_write_trylock() 函数分别类似于 down_read() 和 down_write() 函数，但是，在信号量忙的情况下，它们不阻塞进程。最后，函数 downgrade_write() 自动把写锁转换成读锁。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:5","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"Linux进程 进程时程序执行的一个实例，可以把它看作充分描述程序已经执行到何种程度的数据结构的汇集。在 Linux 源代码中，常把进程称为任务(task)或线程(thread)。 Linux 使用轻量级进程(lightweight process)对多线程应用提供更好的支持。两个轻量级进程基本上可以共享一些资源，诸如地址空间、打开的文件等等。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:0:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程描述符 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程状态 进程状态符中的 state 字段描述了进程所处的状态: 可运行状态 (TASK_RUNNING) : 进程要么在 CPU 上执行，要么准备执行。 可中断的等待状态 (TASK_INTERRUPTIBLE) : 进程被挂起 (睡眠)，直到某个条件表为真。产生一个硬件中断，释放进程正等待的系统资源，或传递一个信号都是可以唤醒进程的条件(把进程的状态放回到 TASK_RUNNING)。 不可中断的等待状态 (TASK_UNINTERRUPTIBLE) : 与可中断的等待状态类似，但有一个例外，把信号传递到睡眠不能改变它的状态。这种状态很少用到，但在一些特定的情况下(进程必须等待，直到一个不能被中断的事件发生)，这种状态是很有用的。例如，当进程打开一个设备文件，其相应的设备驱动程序开始探测相应的硬件设备时会用到这种状态。探测完成以前，设备驱动程序不能被中断，否则，硬件设备会处于不可预知的状态。 暂定状态 (TASK_STOPPED) : 进程的执行被暂停。当进程接收到 SIGSTOP、SIGTSTP、SIGTTIN 或 STGTTOU 信号，进程暂停状态。 跟踪状态 (TASK_TRACED) : 进程的执行已由 debugger 程序暂停。当一个进程被另一个进程监控时(例如 debugger 执行 ptrace() 系统调用监控一个测试程序)，任何信号都可以把这个进程置于 TASK_TRACED 状态。 还有两个进程状态是既可以存放在进程描述符的 state 字段中，也可以存放在 exit_state 字段中。从这两个字段的名称可以看出，只有当进程的执行被终止时，进程的状态才会变为这两种状态中的一种: 僵死状态 (EXIT_ZOMBIE) : 进程的执行被终止，但是，父进程还没有发布 wait4() 或 waitpid() 系统调用来返回有关死亡进程的信息。发布 wait() 类系统调用前，内核不能丢弃包含在死进程描述符中的数据，因为父进程可能还需要它。 僵死撤销状态 (EXIT_DEAD) : 最终状态：由于父进程刚发出 wait4() 或 waitpid() 系统调用，因而进程由系统删除。为了防止其他执行线程在同一个进程上也执行 wait() 类系统调用，而把进程的状态由 (EXIT_ZOMBIE) 状态改为僵死撤销状态 (EXIT_DEAD)。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"标识一个进程 标识一个进程有两种方式: 进程描述符指针: 进程和进程描述符之间有非常严格的一一对应关系，这使得用32位进程描述符地址标识进程成为一种方便的方式。 PID: PID 存放在进程描述符的 pid 字段中。 PID 被顺序编号，新创建进程的 PID 通常是前一个进程的 PID 加1。PID 存在上限，当内核使用的 PID 达到这个上限值的时候就必须开始循环使用已闲置的 PID 号。 PID 的默认最大值是32767(PID_MAX_DEFAULT-1)。可以通过修改 /proc/sys/kernel/pid_max 文件改变 PID 上限值。 内核通过管理一个 pidmap-array 位图来表示当前已分配的 PID 号和闲置的 PID 号。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程的切换 为了控制进程的执行，内核必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。这个中行为被称为进程切换 (process switch)、任务切换 (task switch) 或上下文切换 (context switch)。 所有进程共享 CPU 寄存器，所以在恢复一个进程的执行之前，必须确保每个寄存器装入了挂起进程时的值。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"硬件上下文 进程恢复执行前必须装入寄存器的一组数据称为硬件上下文 (hardware context)。在 Linux 中，进程硬件上下文的一部分存放在 TSS 段，而剩余部分存放在内核态堆栈中。 进程切换只发生在内核态，在执行进程切换之前，用户态进程使用的所有寄存器内容都已保存在内核态堆栈上，这也包括 ss 和 esp 这对寄存器的内容 (存储用户态堆栈指针的地址)。 Linux 使用软件切换上下文 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"任务状态段 80x86 体系结构包括了一个特殊的但类型，叫任务状态段 (Task State Segment, TSS) 来存放硬件上下文。Linux 不使用硬件上下文切换，但是强制为每个不同CPU创建一个TSS。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"执行进程切换 进程切换的核心点在于 scheduler() 函数。 从本质上说，每个进程切换由两步组成: 切换页全局目录以安装一个新的地址空间。 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包含 CPU 寄存器 (重点在 switch_to() 函数)。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:3","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"创建进程 Linux 中创建一个进程的方式: fork() -\u003e sys_fork() -\u003e do_fork() -\u003e copy_process() ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"内核进程 传统的 Unix 系统把一些重要的任务委托给周期性执行的进程，这些进程只运行在内核态，称作内核线程(kernel thread)，内核线程不受不必要的用户态上下文的拖累。内核线程和普通进程的区别: 内核线程只运行在内核态，而普通进程既可以运行在内核态，也可以运行在用户态。 因为内核线程只运行在内核态，它们只使用大于 PAGE_OFFSET 的线性地址空间。另一方面，不管在用户态还是在内核态，普通进程可以用 4GB 的线程地址空间。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程 0 所有进程的祖先叫做进程0，idle 进程或 swapper 进程，它是在 Linux 的初始化阶段从无到有创建的一个内核线程。start_kernel() 函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程(init进程)。 新创建的内核线程的 PID 为1，并与进程0共享每进程所有的内核数据结构。此外，当调度程序选择到它时，init 进程开始执行 init() 函数。 创建init进程后，进程0执行 cpu_idle() 函数，该函数本质上是在开中断的情况下重复执行 hlt 汇编语言指令。只有当没有进程处于 TASK_RUNNING 状态是，调度程序才选择进程0。 在多处理器系统中，每个 CPU 都有一个进程 0。只要打开机器电源，计算机的 BIOS 就启动某一个 CPU，同时禁用其他 CPU。运行在 CPU 0 上的 swapper 进程初始化内核数据结构，然后激活其他的CPU，并通过 copy_process() 函数创建另外的 swapper 进程，把 0 传递给新创建的 swapper 进程作为它们的新 PID。此外，内核把适当的 CPU 索引赋给内核所创建的每个进程的 thread_info 描述符的 cpu 字段。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程 1 由进程0创建的内核线程执行 init() 函数，init() 依次完成内核初始化。init() 调用 execve() 系统调用装入可执行程序 init。结果，init 内核线程变为一个普通进程，且拥有自己的每进程(per-process)内核数据结构。在系统关闭之前，init 进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:3","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"其他内核线程 keventd(也被称为事件): 执行 keventd_wq 工作队列中的函数。 kapmd: 处理与高级电源管理(APM)相关的事件。 kswapd: 执行内存回收。 pdflush: 刷新 “脏” 缓冲区中的内容到磁盘回收内存。 blockd: 执行 kblockd_workqueue 工作队列中的函数。 ksoftirqd: 运行 tasklet; 系统中每个 CPU 都有这样一个内核线程。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:4","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"撤销进程 进程终止的一般方式是调用 exit() 库函数。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程终止 终止用户态应用的系统调用: exit_group() 系统调用，它终止整个线程组，即整个基于多线程的应用。do_group_exit() 是实现这个系统调用的主要内核函数。 exit() 系统调用，它终止某一个线程，而不管该线程所属线程组中的所有其他进程。do_exit() 是实现这个系统调用的主要内核函数。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程删除 进程通过调用 wait() 类函数来检查子进程是否终止，在子进程已终止，但是父进程还未接收到 wait() 类函数的通知之前，子进程处于僵死状态。这时系统资源已经释放，但还占用进程描述符。 如果父进程在接收到子进程前就终止，子进程就会被init进程接管。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"Nginx多组代理配置 一、需求 具体实现以下功能：使用 nginx 作为对外的服务机器，让客户端通过访问 nginx 所在的IP+端口的方式能访问内部多个系统，这样一来通过对单台机器作访问控制就可以保证内部系统的访问安全。实现思路如下：在对外的机器上部署 nginx 服务，通过 nginx 虚拟机功能和代理功能相结合实现多组代理。具体场景如下： 代理服务器 代理服务 nginx 192.168.10.10:8080 192.168.10.11:8080 nginx 192.168.10.10:8081 192.168.10.11:9000 二、环境 测试环境如下： 代理服务器：ip 192.168.10.10；系统 CentOS7 ;  需要代理的服务：192.168.10.11:8080 nginx ；192.168.10.11:9000 tomcat 三、配置代理 假如有两个服务需要配置代理，一个 web，一个 tomcat。web 运行在 192.168.10.11:8080 tomcat 运行在 192.168.10.11:9000 现在配置 nginx 代理。 1.安装 nginx先在代理服务器上安装 nginx，使用命令： $ yum install -y nginx 安装成功后就可以尝试启动 nginx 服务器： $ systemctl start nginx 启动服务成功后，nginx 就运行在 80 端口。 2.修改配置文件安装nginx就可以修改配置文件，配置文件的默认路径为  $ ll /etc/nginx/nginx.conf -rw-r--r-- 1 root root 1822 Nov 24 19:30 /etc/nginx/nginx.conf 修改 nginx.conf 如下 # 系统用户 user nginx; # 工作进程数，配置高的机器可以适当增加 worker_processes 4; # 错误日志 error_log /var/log/nginx/error.log; # pid 文件存放目录 pid /run/nginx.pid; events { # linux 使用 epoll 事件机制 use epoll; # 连接数 worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # 配置虚拟机，在该目录下配置多个配置文件对应多台需要代理的机器 include /etc/nginx/conf.d/*.conf; # 配置 https # Settings for a TLS enabled server. # # server { # listen 443 ssl http2 default_server; # listen [::]:443 ssl http2 default_server; # server_name _; # root /usr/share/nginx/html; # # ssl_certificate \"/etc/pki/nginx/server.crt\"; # ssl_certificate_key \"/etc/pki/nginx/private/server.key\"; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 10m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # location / { # } # # error_page 404 /404.html; # location = /40x.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } # } } 注意 23 行的配置：include /etc/nginx/conf.d/*.conf; 这个目录下就是要存放代理的配置文件。一般这个文件默认是存在的，如果目录不存在，就创建并修改权限。 $ mkdir /etc/nginx/conf.d $ chmod 755 /etc/nginx/conf.d 3.配置代理文件在这个目录下存放代理服务的文件，最好一个代理对应一个配置文件。我们之前需求上需要代理的服务是两个，直接创建两个代理文件，并修改 # /etc/nginx/conf.d/nginx.conf # 代理的节点 # upstream \u003c代理名称 唯一\u003e upstream nginx_server { # 代理的ip:port,可添加多个ip地址就行负载均衡 server 192.168.10.11:8080; } server { # 监听的地址和端口 # 对应一个代理一个端口 listen 192.168.10.10:8080; # 对外的域名 server_name aaa.test.com; location / { # 代理配置，名称和以上的代理名称对应 proxy_pass http://nginx_server; # 配置使用真实的地址访问，如果不配置此项会导致代理tomcat服务器 400 错误 proxy_set_header Host $host; } } # cat /etc/nginx/conf.d/tomcat.conf upstream tomcat_server { server 192.168.10.11:9000; } server { listen 192.168.10.10:8081; server_name bbb.test.com; location / { proxy_pass http://tomcat_server; proxy_set_header Host $host; } } 修改并保存后，使用 nginx 命令来验证文件的语法： $ # nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 之后就可以重启 nginx 服务 $ systemctl restart nginx $ netstat -tnlp | grep nginx tcp 0 0 192.168.10.10:8080 0.0.0.0:* LISTEN 11643/nginx: master tcp 0 0 192.168.10.10:8081 0.0.0.0:* LISTEN 11643/nginx: master 可以看到成功绑定两个端口，代理两个服务。通过浏览器访问8080和8081![image.png] 到这里配置就完成了。如果需要再代理，在 /etc/nginx/conf.d 目录下再添加相应的配置文件就可以。如果没有访问成功，请检查各种防火墙和安全策略。 ","date":"2021-12-03","objectID":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:0:0","tags":null,"title":"Nginx多组代理配置","uri":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"postgresql 实战一：安装和使用 安装 这里直接使用 docker 安装 postgresql-13 docker run --name postgresql13 -e POSTGRES_PASSWORD=123456 -p 54322:5432 -d postgres:13 安装成功后会绑定主机端口 54322。直接进入 postgresql13 容器，使用 pgsql。 [root@localhost ~]# docker exec -it 3e3b03e3 /bin/bash root@3e3b03e3e442:/# psql -h localhost -p 5432 -U postgres psql (13.0 (Debian 13.0-1.pgdg100+1)) Type \"help\" for help. postgres=# psql 是 pgsql 的客户端命令，使用参数如下： -h：指定 pgsql 的地址 -p：指定 pgsql 的绑定端口 -U：指定登录的用户名，默认为 postgres。后面可以紧接 “database”，直接进入指定的数据库。 数据库的操作 postgresql 支持的数据库操作有 增、删、查、改 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:0:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"创建数据库 创建数据库的命令为： create database \u003cdatabasename\u003e [encoding 'UTF-8']  postgres=#createdatabasetestencoding'UTF-8';CREATEDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:1:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查询数据库 查询数据库的命令有两种：第一种是 \\l ，只能在 psql 中使用： postgres=#\\lListofdatabasesName|Owner|Encoding|Collate|Ctype|Accessprivileges-----------+----------+----------+------------+------------+----------------------- postgres|postgres|UTF8|en_US.utf8|en_US.utf8|template0|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestemplate1|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestest|postgres|UTF8|en_US.utf8|en_US.utf8|testdb|postgres|UTF8|en_US.utf8|en_US.utf8|(5rows) 另一种命令为： select * from pg_databse  postgres=#selectdatnamefrompg_database;datname----------- postgrestemplate1template0testdbtest(5rows) ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:2:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"修改数据库 修改数据库使用关键字 alter  postgres=#alterdatabasetestxrenametotest;ALTERDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:3:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"删除数据库 postgres=#dropdatabasetest;DROPDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:4:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"选择数据库 选择数据和切换数据的命令是相同的，使用命令 \\c databasename  postgres=#\\ctest;Youarenowconnectedtodatabase\"test\"asuser\"postgres\".test=#\\cpostgres;Youarenowconnectedtodatabase\"postgres\"asuser\"postgres\". 表的操作 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:5:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"创建表 创建 postgresql 表的语法为： CREATETABLEtable_name(column1datatype,column2datatype,column3datatype,.....columnNdatatype,PRIMARYKEY(oneormorecolumns)); 创建一张名为 COMPANY 的表： testdb=#CREATETABLECOMPANY(IDINTPRIMARYKEYNOTNULL,NAMETEXTNOTNULL,AGEINTNOTNULL,ADDRESSCHAR(50),SALARYREAL);CREATETABLE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:6:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查询表 查询表使用 \\d ： testdb=#\\dListofrelationsSchema|Name|Type|Owner--------+---------+-------+---------- public|company|table|postgrespublic|person|table|postgres 但是这种方式只能在 psql 命令中中使用，还可以使用 select 命令： testdb=#select*frompg_tableswhereschemaname='public';schemaname|tablename|tableowner|tablespace|hasindexes|hasrules|hastriggers|rowsecurity------------+-----------+------------+------------+------------+----------+-------------+------------- public|person|postgres||f|f|f|fpublic|company|postgres||t|f|f|f(2rows ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:7:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查看表结构 查看表结构也是使用 \\d 命令： Table\"public.company\"Column|Type|Collation|Nullable|Default---------+---------------+-----------+----------+--------- id|integer||notnull|name|text||notnull|age|integer||notnull|address|character(50)|||salary|real|||Indexes:\"company_pkey\"PRIMARYKEY,btree(id) 也可以使用 sql 实现： testdb=#SELECTa.attnum,a.attnameASfield,t.typnameAStype,a.attlenASlength,a.atttypmodASlengthvar,a.attnotnullASnotnull,b.descriptionAScommentFROMpg_classc,pg_attributeaLEFTJOINpg_descriptionbONa.attrelid=b.objoidANDa.attnum=b.objsubid,pg_typetWHEREc.relname='company'ANDa.attnum\u003e0ANDa.attrelid=c.oidANDa.atttypid=t.oidORDERBYa.attnum;attnum|field|type|length|lengthvar|notnull|comment--------+---------+--------+--------+-----------+---------+--------- 1|id|int4|4|-1|t|2|name|text|-1|-1|t|3|age|int4|4|-1|t|4|address|bpchar|-1|54|f|5|salary|float4|4|-1|f|(5rows) ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:8:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"修改表结构 ALTER TABLE 语句用于添加、修改、删除表中的列：在现有表中添加列： ALTERTABLEtable_nameADDcolumn_namedatatype; 在现有表中删除列： ALTERTABLEtable_nameDROPCOLUMNcolume_name; 在现有表中修改字段类型： ALTERTABLEtable_nameALTERCOLUMNcolume_nameTYPEdatatype; 向表中的列添加 NOT NULL 约束： ALTERTABLEtable_nameMODIFYcolume_namedatatypeNOTNULL; 添加约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK  ALTERTABLEtable_nameADDCONSTRAINTMyUniqueConstraintUNIQUE(colume_name1,colume_name2...); 删除约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK ALTERTABLEtable_nameDROPCONSTRAINTMyUniqueConstraintUNIQUE; ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:9:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"删除表 DROP 用于删除表： testdb=#droptablecompany;DROPTABLE JSON 类型的支持 PostgreSQL 支持存储 JSON 类型的数据，提供了两种类型： json 和 jsonb 。 json数据类型存储输入文本的精准拷贝，处理函数必须在每 次执行时必须重新解析该数据。 jsonb数据被存储在一种分解好的 二进制格式中，它在输入时要稍慢一些，因为需要做附加的转换。但是 jsonb在处理时要快很多，因为不需要解析。jsonb也支持索引，jsonb不保留空格、不 保留对象键的顺序并且不保留重复的对象键。 关于 JSONB 的详细信息可以参考 JSON 类型，这里只介绍 JSONB 类型数据的使用。 创建 JSONB 类型的表 CREATETABLEposts(IDINTPRIMARYKEYNOTNULL,specJSONB); 插入数据，使用的关键字为 INSERT INTO 。 -- 插入第一条数据 insertintopostsvalues(1,'{\"name\": \"first posts\", \"content\": \"This is a simple post\", \"author\": \"a\", \"time\": \"2020/10/15\"}');-- 插入第二条数据 insertintopostsvalues(2,'{\"name\": \"jsonb\", \"content\": \"jsonb is PostgreSQL inner type\", \"author\": \"bb\", \"time\": \"2020/10/12\", \"tag\": [\"database\", \"PgSQL\"]}'); 添加 key/value 索引： -- 给所有 key/values 添加索引 CREATEINDEXidx_posts_specONpostsUSINGgin(spec);-- 给指定的 key/values 添加索引 CREATEINDEXidx_posts_spec_authorONpostsUSINGgin((spec-\u003e'author')); 数据查询 SELECT ，全表查询： testdb=#select*fromposts;id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 1|{\"name\":\"first posts\",\"time\":\"2020/10/15\",\"author\":\"a\",\"content\":\"This is a simple post\"}2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(2rows) 查询 JSONB 内的数据： -- spec-\u003e'name' 输出的数据格式为原生格式 testdb=#selectid,spec-\u003e'name'fromposts;id|?column?----+--------------- 1|\"first posts\"2|\"jsonb\"(2rows)-- spec-\u003e\u003e'name' 输出格式为 TEXT testdb=#selectid,spec-\u003e\u003e'name'fromposts;id|?column?----+------------- 1|firstposts2|jsonb(2rows)testdb=#insertintopostsvalues(3,'{\"name\": \"other\", \"content\": \"other data\", \"author\": \"bb\", \"other\": {\"name\": \"other\"}}');INSERT01-- 使用 -\u003e 操作符查询多级 json 格式的数据 testdb=#selectid,spec-\u003e'name'asspec_name,spec-\u003e'other'-\u003e'name'asspec_other_namefromposts;id|spec_name|spec_other_name----+---------------+----------------- 1|\"first posts\"|2|\"jsonb\"|3|\"other\"|\"other\"-- 使用 ? 查询 key 是否存在 testdb=#selectid,specfrompostswherespec?'tag';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(1row)-- 使用 ? 查询 values testdb=#selectid,specfrompostswherespec-\u003e'author'?'bb';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(2rows)-- 使用 @\u003e 来精确查询 testdb=#selectid,specfrompostswherespec@\u003e'{\"other\": {\"name\": \"other\"}}'::jsonb;id|spec----+---------------------------------------------------------------------------------------- 3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(1row) JSONB 支持的其他函数和操作符可以参考 这里。 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:10:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"Windows Bat总结 最近项目需要再 windows 上做开发，而且一些自动化的处理需要使用 windows 的的脚本。所以做些记录，防止遗忘。 基本的语法 首先从基础开始吧，之前都是使用 linux bash 的。可以说 windows bat 脚本和 linux bash 脚本还是有很多区别的。 ","date":"2021-12-03","objectID":"/bat/:0:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"设置变量 变量设置使用的命令为set。 set a=\"hello world\" echo %a% 从上面的脚本中可以知道，使用set来设置变量，语法为set var=\u003c值\u003e。如果要引用这个变量的话就使用%var%。 注：bat 脚本不能像 bash 中一样设置临时变量，只用将变量设置为环境变量。 set命令的功能还是比较强大的，比如获取从键盘中输入的字符： set /p a=\"Input a number:\" echo %a% 支持算术： set /a a=1+2 echo %a% set /a a-=1 echo %a% set /a a*=3 echo %a% set /a a/=3 echo %a% 这个关键在于set /a 还有字符串的修改和截取： :::::::::: 字符串的截取 :::::::::: set a=Hello Windows Bat :: 截取所有 set a=%a:~0% :: 截取指定的 set a=%a:~1,-1% set a=%a:~2,4% :::::::::: 字符串的替换 :::::::::: set a=Hello Windows :: 将Windows替换成Linux set a=%a:Windows=Linux% ","date":"2021-12-03","objectID":"/bat/:1:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"注释 bat 中能实现注释功能的有两个::和rem。 它们的不同点是：rem是一条命令，在运行的时候相当于把rem本身及其后面的内容置空。既然它是一条命令，就必须处于单独的一行或者有类似 “\u0026” 的连接符号连接。 bat 遇到以冒号 “:” 开头的行时（忽略冒号前的空格），会将其后的语句识别为“标记”而不是命令语句，因此类似 “:label” 这样的在 bat 中仅仅是一个标记。 注: 使用 bat 中的注释时需要注意一点，不要再 () 的边上使用注释。 ","date":"2021-12-03","objectID":"/bat/:2:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"条件判断 bat 中的条件判断也是使用if。 set a=1 if %a%==1 ( echo OK ) else ( echo ERROR ) 如果时判断字符串使用为空时,可以这样处理: set a=\"hello\" if (%a%)==() ( echo OK ) else ( echo ERROR ) ","date":"2021-12-03","objectID":"/bat/:3:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"循环语句 bat 中的循环有些不同。关键字也是for。还是先来看一个例子： for /f \"delims=: tokens=1,2,3\" %%i in ( \"2018:04:11\" ) do ( echo %%i echo %%j ) 这段脚本中需要注意的点是：delims=:表示使用 “:” 来分割字符串，而tokens=1,2,3则表示取出分割后的字符串的部分，从1开始。%%i是循环中的每个项。输出时%%i和%%j分别对应的就是截取的字段1和2。如果还需要输出第三个，也是使用%%k表示，依次类推。 但 bat 中的for会存在延迟赋值的情况，先来看一段脚本: for /f \"delims=: tokens=2\" %%i in ( 'ipconfig /all ^| findstr /i \"ipv4\" ' ) do ( echo %%i set a=%%i echo %a% ) 输出结果: IPv4 地址 . . . . . . . . . . . . : 192.168.168.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.157.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 %a%的值一直等于最后一项。 ","date":"2021-12-03","objectID":"/bat/:4:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"函数 bat 中函数是使用:label方式定义的，使用call来调用: call :test Hello World goto EXIT :test echo %1 %2 :EXIT 脚本中的goto用来跳转退出，而且函数要放在脚本的尾部，存在多个函数时还需要使用goto直接跳转，因为脚本是会按顺序执行下去的。 实战操作 @echo off set option=%1 set address=%2 if (%option%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if (%address%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if %option% == start ( call :start %address% ) else if %option% == stop ( call :stop %address% ) else ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) ::sc config msiscsi start=auto ::net start msiscsi goto EXIT :: 连接iscsi服务器 :start iscsicli QAddTargetPortal %1 for /f \"delims= tokens=1\" %%i in ( 'iscsicli ListTargets t ^| findstr /i \"iqn.2018-11\" ' ) do ( iscsicli qlogintarget %%i ) goto EXIT :: 断开iscsi服务器 :stop set a= for /f \"delims=: tokens=2\" %%i in ('iscsicli SessionList ^| findstr /i \"fffffa8\"') do ( set a=%%i goto return ) :return set a=%a: =0x% set a=%a:-=-0x% iscsicli LogoutTarget %a% iscsicli RemoveTargetPortal %1 3260 goto EXIT :EXIT 这个脚本是用来连接和断开iscsi服务器的。脚本有两个入参，option 和 address。连接和断开iscsi服务器。脚本的思路很简单，开始判断输入参数是否正确。然后根据 option 选择执行对应的函数。特别在:stop中，因为延时复制的关系，所以循环体中只放简单的复制，处理部分在外面进行处理。 后记 ","date":"2021-12-03","objectID":"/bat/:5:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"延时赋值问题 bat 的延时赋值有对应的解决方法： SETLOCAL ENABLEDELAYEDEXPANSION set a=hello set a=!a! set a=!a:~1! ","date":"2021-12-03","objectID":"/bat/:6:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"搭建lamp环境 lamp即 apache + mysql + php，是互联网常用架构。 要注意的是php依赖apache和mysql，所以要最后安装。系统环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2021-12-03","objectID":"/lamp/:0:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2021-12-03","objectID":"/lamp/:1:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2021-12-03","objectID":"/lamp/:2:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2021-12-03","objectID":"/lamp/:3:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2021-12-03","objectID":"/lamp/:4:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2021-12-03","objectID":"/lamp/:5:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2021-12-03","objectID":"/lamp/:6:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2021-12-03","objectID":"/lamp/:7:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2021-12-03","objectID":"/lamp/:8:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装httpd 使用apache的httpd提供网络web服务 ","date":"2021-12-03","objectID":"/lamp/:9:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载httpd wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.2.31.tar.gz ","date":"2021-12-03","objectID":"/lamp/:10:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 tar -zxvf httpd-2.2.31.tar.gz ","date":"2021-12-03","objectID":"/lamp/:11:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"编译安装 # 编译 ./configure --prefix=/usr/local/apache \\ \u003e-with-include-apr --enable-so \\ \u003e--enable-deflate=shared \\ \u003e--enable-rewrite=shared \\ \u003e--enable-expires=shared \\ \u003e-with-pcre \\ \u003e-with-mpm=prefork make # 安装 make install 编译选项记录在/usr/local/apache/build/config.nice 中 ","date":"2021-12-03","objectID":"/lamp/:12:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"启动httpd /usr/local/apache/bin/apachectl start /usr/local/apache/bin/apachectl -M ：查看各种库 静态库(编译时直接放入下列文件) /usr/local/apache/bin/httpd 动态库(用到时加载) /usr/local/apache/modules/ /usr/local/apache/bin/apachectl -l ：查看静态库以及apache工作模式 /usr/local/apache/bin/apachectl -t ：查看配置文件有无语法错误 配置文件 /usr/local/apache/conf/httpd.conf /usr/local/apache/bin/apachectl graceful 加载配置文件 启动httpd时的警告： httpd: apr_sockaddr_info_get() failed for 【linux】 httpd: Could not reliably determine the server's fully qualified domain name, using 127.0.0.1 for ServerName 解决方法(问题在于主机名不匹配) 警告1 ：在/etc/hosts中的127.0.0.1行后添加linux 警告2 ：在httpd的配置文件/usr/local/apache/conf/httpd.conf中的ServerName行中改为 ServerName linux:80 ","date":"2021-12-03","objectID":"/lamp/:13:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"开机启动 修改启动脚本 cp /usr/local/apache/bin/apachectl /etc/init.d/httpd vim /etc/init.d/httpd 在#!/bin/bash下加入 #chkconfig:345 61 61 #description:Apache httpd 设置开机启动 chkconfig --add httpd chkconfig --level 345 httpd on 安装php ","date":"2021-12-03","objectID":"/lamp/:14:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载php wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2021-12-03","objectID":"/lamp/:15:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2021-12-03","objectID":"/lamp/:16:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-apxs2=/usr/local/apache/bin/apxs --with-config-file-path=/usr/local/php/etc --with-mysql=/usr/local/mysql --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif --disable-ipv6 #出现错误： configure: error: jpeglib.h not found. # 解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. #解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2021-12-03","objectID":"/lamp/:17:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"修改配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini vim /usr/local/apache/conf/httpd.conf 在 AddType application/x-compress .Z AddType application/x-gzip .gz .tgz 两行下加入 AddType application/x-httpd-php .php 将 DirectoryIndex index.html 后添加 1.php DirectoryIndex index.html 1.php ","date":"2021-12-03","objectID":"/lamp/:18:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"测试 在Apache的安装文件中添加php文件 /usr/local/apache/htdocs/目录下创建 vim 1.php \u003c?php echo \"Welcome to 1.php\" ; ?\u003e ","date":"2021-12-03","objectID":"/lamp/:19:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"搭建lnmp环境 lnmp即：nginx + mysql + php 与lamp不同的是，lnmp的php不在只是httpd中的一个库，lnmp架构中php作为一个服务，专门解析php。 同样的php依赖mysql，所以首先安装mysql 这里环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2021-12-03","objectID":"/lnmp/:0:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2021-12-03","objectID":"/lnmp/:1:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:2:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2021-12-03","objectID":"/lnmp/:3:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2021-12-03","objectID":"/lnmp/:4:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2021-12-03","objectID":"/lnmp/:5:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2021-12-03","objectID":"/lnmp/:6:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2021-12-03","objectID":"/lnmp/:7:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2021-12-03","objectID":"/lnmp/:8:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装php ","date":"2021-12-03","objectID":"/lnmp/:9:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载 wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2021-12-03","objectID":"/lnmp/:10:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2021-12-03","objectID":"/lnmp/:11:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --enable-fpm --with-fpm-user=php-fpm --with-fpm-group=php-fpm --with-mysql=/usr/local/mysql --with-mysql-sock=/tmp/mysql.sock --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-ftp --enable-mbstring --enable-exif --enable-zend-multibyte --disable-ipv6 --with-pear --with-curl # 出现错误： configure: error: jpeglib.h not found. #解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. # 解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2021-12-03","objectID":"/lnmp/:12:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"php的配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini ","date":"2021-12-03","objectID":"/lnmp/:13:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"php开机启动 cp /usr/src/php-5.4.45/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm mv /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf #服务启动的脚本配置文件 chkconfig --add php-fpm chkconfig --level 345 php-fpm on ","date":"2021-12-03","objectID":"/lnmp/:14:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"启动php useradd -s /sbin/nologin php-fpm chmod +x /etc/init.d/php-fpm service php-fpm start 安装nginx ","date":"2021-12-03","objectID":"/lnmp/:15:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载nginx cd /usr/src wget http://nginx.org/download/nginx-1.6.2.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:16:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 tar -xvf nginx-1.6.2.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:17:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"编译安装 ./configure --prefix=/usr/local/nginx --with-pcre #出现错误： ./configure: error: the HTTP rewrite module requires the PCRE library. #解决方法： yum install -y pcre-devel make make install ","date":"2021-12-03","objectID":"/lnmp/:18:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"启动 编辑启动脚本 vim /etc/init.d/nginx #!/bin/bash # chkconfig: - 30 21 # description: http service. # Source Function Library . /etc/init.d/functions # Nginx Settings NGINX_SBIN=\"/usr/local/nginx/sbin/nginx\" NGINX_CONF=\"/usr/local/nginx/conf/nginx.conf\" NGINX_PID=\"/usr/local/nginx/logs/nginx.pid\" RETVAL=0 prog=\"Nginx\" start() { echo -n $\"Starting $prog: \" mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL } stop() { echo -n $\"Stopping $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL } reload(){ echo -n $\"Reloading $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL } restart(){ stop start } configtest(){ $NGINX_SBIN -c $NGINX_CONF -t return 0 } case \"$1\" in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $\"Usage: $0{start|stop|reload|restart|configtest}\" RETVAL=1 esac exit $RETVAL 保存后，更改权限: chmod 755 /etc/init.d/nginx chkconfig --add nginx 开机启动 chkconfig nginx on 启动服务 service nginx start ","date":"2021-12-03","objectID":"/lnmp/:19:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"测试解析php 编辑配置文件/usr/local/nginx/conf/nginx.conf 修改制定行 ...... location ~ \\.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; #路径为网站根目录 include fastcgi_params; } ...... 在/usr/local/nginx/html/下创建一个info.php文件 \u003c?php phpinfo(); ?\u003e 浏览器访问：http://127.0.0.1/info.php测试 ","date":"2021-12-03","objectID":"/lnmp/:20:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"深入理解计算机系统 ","date":"2021-12-03","objectID":"/csapp/:0:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"一、计算机系统漫游 计算机系统是由硬件和软件组成。 ","date":"2021-12-03","objectID":"/csapp/:1:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.1 信息就是位 + 上下文 系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串 bit 表示的。区分不同数据对象的唯一方法是我们读到这些数据对象是的上下文。 ","date":"2021-12-03","objectID":"/csapp/:1:1","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.2 程序被其他程序翻译成不同的格式 ","date":"2021-12-03","objectID":"/csapp/:1:2","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.3 了解编译系统如何工作是大有益处的 为什么程序员必须要知道编译系统是如何工作的? 优化程序性能。 理解链接时出现的错误。 避免安全漏洞。 ","date":"2021-12-03","objectID":"/csapp/:1:3","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.4 处理器读并解释储存在内存中指令 系统硬件组成 总线: 贯穿整个系统的一组电子管道，称作总线，他携带信息字节并负责在各个部件间传递。 I/O 设备: 系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器或者适配器与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是 I/O 设备本身或者系统的主印制电路板上的芯片组。而适配器则是一块插在主板插槽上的卡。 主存: 主存是一个临时存储设备，在处理执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存储存储器 (DRAM) 芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址(数组索引)，这些地址是从零开始的。 处理器：中央处理单元 (CPU)，简称处理器，是解释(或)执行存储在主存中指令的引擎、处理器的核心是一个大小与一个字的存储设备(或寄存器)，称为程序计数器(PC)。在任何时刻，PC 都指向主存中的某条机器语言指令。 系统执行一个 Hello World 程序时，硬件运行流程。 键盘输入命令时，shell 程序将字符逐一读入寄存器，再存放到内存中。 键入回车键后，shell 执行一系列指令来加载可执行的 hello 文件，将 hello 目标文件中的代码和数据从磁盘复制到内存。 处理器开始执行 hello 程序 main 程序中的机器语言指令。 这些指令将输出的字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。 ","date":"2021-12-03","objectID":"/csapp/:1:4","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.5 高速缓存至关重要 系统运行时会频繁的挪动信息，而不同存储设备之间的读写性能有严重偏差 (从寄存器中读取数据比从主存中读取快 100 被，从主存中读取又比磁盘中快 1000 万倍)。所以不同存储设备间需要高速缓存来提供系统运行速度。 这里的高速缓存是相对概念。 ","date":"2021-12-03","objectID":"/csapp/:1:5","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.6 存储设备形成层次结构 ","date":"2021-12-03","objectID":"/csapp/:1:6","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.7 操作系统管理硬件 我们并不直接访问硬件，而是通过操作系统。所有应用程序对硬件的操作尝试都必须通过操作系统。 操作系统有两个基本功能: 防止硬件被失控的应用程序滥用。 向应用程序提供简单一致的机制来控制复杂而又通常不大相同的低级硬件设备。 操作系统通过几个基本抽象概念来实现这两个功能。 进程: 操作系统对一个正在运行的程序的一种抽象。 上下文: 操作系统保持跟踪进程运行所需的所有状态信息，其中包含 PC 和寄存器文件的当前值，以及主存的内存。 在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换。这一过程有操作系统内核 (kernel) 管理。 线程: 现代操作系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都裕兴在进程的上下文中，并共享同样的代码和全局数据。 虚拟机内存是一个抽象概念，它为每个进程提供一个假象，即每个进程都在独占地使用主存，每个进程看到的内存都是一致的，称为虚拟地址空间。 虚拟地址空间从下至上依次为: 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。 堆。堆可以在运行时动态地扩展和收缩。 共享库。存放 C 标准库和数学库这些共享库的代码和数据。 栈。位于用户虚拟地址空间顶部，编译器用它来实现函数调用，它和堆一样在程序运行期间可以动态地扩展和收缩。每次调用一个函数时，栈就会增长，从一个函数返回时，栈就会收缩。 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，他们必须调用内核来执行这些操作。 文件就是字节序列！每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成文件。 ","date":"2021-12-03","objectID":"/csapp/:1:7","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.8 系统之间利用网络通信 硬件和软件组合成一个系统，而通过网络间不同的主机连接成一个更广大的现代系统。 ","date":"2021-12-03","objectID":"/csapp/:1:8","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.9 重要主题 并发 (concurrency): 一个同时具有多个活动的系统。 并行 (parallelism): 用并发来是一个系统运行得更快。 超线程：有时称为同时多线程 (simultaneous multi-threading)，是一项允许一个 CPU 执行多个控制流的技术。 抽象的使用是计算机科学中最为重要的概念之一。这里介绍四个抽象: 文件是对 I/O 设备的抽象。 虚拟内存是对程序存储器的抽象。 进程是对一个正在运行的程序的抽象。 虚拟机是对整个计算机的抽象。 ","date":"2021-12-03","objectID":"/csapp/:1:9","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"三、程序的机器级表示 ","date":"2021-12-03","objectID":"/csapp/:2:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.1 历史观点 Intel 处理器系列俗称 x86。 摩尔定律: 1965 年， Gordon Moore, Intel 公司的创始人根据当时的芯片技术做出推断，预测在未来 10 年，芯片上的晶体管数量每年都会翻一番。这个预测就成为摩尔定律。 ","date":"2021-12-03","objectID":"/csapp/:2:1","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.2 程序编码 机器级编程重要的两种抽象: 由指令级体系结构或指令集架构(Instruction Set Architecture, ISA) 来定义机器级程序的格式和行为，它定义了处理器状态、指令的格式，以及每条指令对状态的影响。 机器级程序使用的内存地址是虚拟地址，提供的内存模型看上去是一个非常大的字节数组。 汇编代码非常接近于机器代码，它的主要特点是它用可读性更好的文本格式表示。 程序内存包含：程序的可执行机器代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，以及用户分配的内存块。 一条机器指令只能执行一个非常基本的操作。 ","date":"2021-12-03","objectID":"/csapp/:2:2","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.3 数据格式 Intel 中数据格式： 字 word: 表示 16 位数据类型 双字 double words: 32 位数 四字 qoad words: 64 位数 C 语言数据类型在 x86-64 中的大小。在 64 为机器中，指针长 8 字节。 大多数GCC生成的汇编代码指令都有一个字符的后缀，表明操作数的大小。例如。数据传送指令有四个变种： movb: 传送字节 movw: 传送字 movl: 传送双字 movq: 传送四字 ","date":"2021-12-03","objectID":"/csapp/:2:3","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.4 访问信息 一个 x86-64 的中央处理单元 CPU 包含一组 16 个存储 64 位值的通用目的寄存器，这些寄存器用来存储整数数据和指针。 关于寄存器的说明可以参考: X86-64 寄存器和栈帧 x86_64 寄存器介绍 大多数指令有一个或多个操作数(operand)，指示出执行一个操作中要使用到的源数据值，以及放置结果的目的位置。 存放操作数的类型： 立即数(immediate)，用来表示常数值。格式是 ‘$’ 后面跟一个标准 C 表示法表示的整数。比如 $-577或$0x1F。 寄存器(register)，它表示某个寄存器的内容，用符号 $R_a$ 表示。 内存引用，它会根据计算出来的地址(通常称为有效地址)访问某个内存位置。使用 $M_b$[Addr] 表示对存储在内存中从 Addr 开始的 b 个字节值的引用。 多种不同的寻址方式，允许不同形式的内存引用。 Imm($r_b$, $r_i$, s) : 一个立即数偏移 Imm，一个基址寄存器 $r_b$，一个变址寄存器 $r_i$ 和一个比例因子 s，s 必须是 1、2、4、8。基址和变址寄存器都必须是 64 位寄存器。有效地址为 Imm+R[$r_b$]+R[$r_i$]*s。 计算题: 有以下内存地址和寄存器的值: 得出以下操作数的值: 操作数 值 注释 %rax 0x100 寄存器 0x104 0xAB 绝对地址 $0x108 0x108 立即数 (%rax) 0xFF 地址 0x100 4(%rax) 0xAB 地址 0x104 9(%rax,%rdx) 0x11 地址 0x10C 260(%rax,%rdx) 0x13 地址 0x108 OxFC(,%rcx,4) 0xFF 地址 0x100 (%rax,%rdx,4) 0x11 地址 0x10C 数据传送指令: 将数据从一个位置复制到另一个位置。 源操作数指定的值是一个立即数，存储在寄存器或者内存中。目的操作数指定一个位置，寄存器或者内存地址。 x86-64 中传送指令的两个操作数不能都指向内存位置，内存间的复制需要两条指令。 MOV 的五种可能组合: movl $0x4050, $eax ; Immediate -- Register, 4 bytes movw %bp, %sp ; Register -- Register, 2 bytes movb (%bp, %rcx), %al ; Memory -- Register, 1 bytes movb $-17, (%rsp) ; Immediate -- Memory, 1 bytes movq %rax, -12(%rbp) ; Register -- Memory, 8 bytes MOVZ 类中指令把目的中剩余的字节填充为0。 MOVS 类中的指令通过符号扩展来填充，把源操作的最高为进行复制。 下面是一个数据传送示例: long exchange(long *xp, long y) { long x = *xp; *xp = y; return x; } 执行命令 gcc -Og -S main.c 生成以下汇编内容: exchange: movq (%rdi), %rax movq %rsi, (%rdi) ret 可以看出: C 语言的 “指针” 其实就是地址。间接引用指针就是间该指针放在一个寄存器中，然后再内存引用中使用这个寄存器。 最后的两个数据传送操作: 将数据压入程序栈中，从程序栈中弹出数据。 pushq %rbp ; 栈指针减8，然后将值写到新的栈顶地址。 ; 等同于 subq $8, %rsp ; Decrement stack pointer movq %rbp, (%rsp) ; Store %rbp on stack 操作示意图: popq %rbp ; 弹出一个四字的操作包括从栈顶位置读出数据，然后减栈指针加8。 ; 等同于 movq %rsp, (%rax) ; Read %rax from stack addq $8, %rsp ; Increment stack pointer ","date":"2021-12-03","objectID":"/csapp/:2:4","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.5 算术和逻辑操作 指令类 ADD 由四条加法指令组成: addb 字节加法、addw 字加法、addl 双字加法 和 addq 四字加法。 这些操作被分成四组: 加载有效地址、一元操作、二元操作和移位。 加载有效地址(load effective address)指令 leaq 实际上是 movq 指令的变形。它的指令形式是从内存读数据到寄存器，但实际上它根本就没有引用内存。 long scale(long x, long y, long z) { long t = x + 4 * y + 12 * z; return t; } 得到汇编命令: _scale: ## @scale .cfi_startproc ## %bb.0: pushq %rbp movq %rsp, %rbp leaq (%rdi,%rsi,4), %rax leaq (%rdx,%rdx,2), %rcx leaq (%rax,%rcx,4), %rax popq %rbp retq 一元操作数只有一个操作数，既是源又是目的。如 incq (%rsp)。 二元操作数，第二个操作数既是源又是目的。如 subq %rax,%rdx。 移位操作，先给出移位量，然后第二项是要移位。可以进行算术和逻辑右移。位移量可以是一个立即数，或者放在单字节寄存器 %cl 中(移位操作指令只允许以这个特定的寄存器作为操作数)。 特殊的算术操作 以下的 C 代码: #include \u003cinttypes.h\u003e typedef unsigned __int128 uint128_t; void store_uprod(uint128_t *dest, uint64_t x, uint64_t y) { *dest = x * (uint128_t) y; } void remdiv(long x, long y, long *qp, long *rp) { long q = x / y; long r = x%y; *qp = q; *rp = r; } 生成汇编 store_uprod: movq %rsp, %rbp movq %rdx, %rax ; Copy x to multiplicand mulq %rsi ; Multiply by y movq %rdx, 8(%rdi) ; Store upper 8 bytes at dest+8 movq %rax, (%rdi) ; Store lower 8 bytes at dest retq remdiv: movq %rsp, %rbp movq %rdx, %r8 ; Copy qp movq %rdi, %rax ; Move x to lower 8 bytes of dividend cqto ; Sign-extend to upper 8 bytes of dividend idivq %rsi ; Divide by y movq %rax, (%r8) ; Store remainder at rp movq %rdx, (%rcx) ; Store quotient at qp retq ","date":"2021-12-03","objectID":"/csapp/:2:5","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.6 控制 CPU 还维护着一组单个位的条件码 (condition code) 寄存器，它们描述了最近的算术或逻辑操作的属性。可以检测这些寄存器来执行条件分支指令。最常用的条件码有: CF: 进位标志。最近的操作使最高位产生了进位。可以来检查无符号操作的溢出。 ZF: 零标志。最近的操作得出的结果为0。 SF: 符号标志。最近的操作得到的结果为负数。 OF: 溢出标志。最近的操作导致一个补码溢出 —— 正溢出或负溢出。 条件码通常不会直接读取，常用的使用方法有三种: 可以根据条件码的某种组合，将一个字节设置为 0 或者 1。 可以条件跳转到程序的某个其他部分。 可以有条件地创送数据。 SET 指令是根据条件码的某种组合，将一个字节设置为 0 或者 1的一整类指令。这些指令的后缀表示不同的条件而不是操作数的大小。如 setl 表示 “小于时设置 (set less)”。 setb 表示 “低于时设置 (set below)”。 一条 SET 指令的目的操作数是低位单字节寄存器元素之一，或者是一个字节的内存位置，指令会将这个字节设置成 0 或者 1。 跳转 (jump) 指令会导致执行切换到程序中一个全新的位置。在汇编代码中，这些跳转的目的地通常用一个标号 (label) 指明。 movq $0,%rax ; Set %rax to 0 jmp .L1 ; Goto .L1 movq (%rax), %rdx ; Null pointer dereference (skipped) .L1: popq %rdx ; Jump target 实现条件操作的传统方法是通过使用控制的条件转移。当条件满足时，程序沿着一条执行路径执行，而当条件不满足是，就走另一条路径。但这个方法在现代处理器上可能会非常低效。 另一种策略是使用数据的条件转移。这个方法计算一个条件操作的两种结果，然后再根据条件是否满足从中选取一个。 汇编中没有循环指令存在，可以用条件测试和跳转组合起来实现循环效果。 long fact_do(long n) { long result = 1; do { result *= n; n = n - 1; } while (n \u003e 1); return result; } 生成汇编代码: _fact_do: ## @fact_do pushq %rbp movq %rsp, %rbp movl $1, %eax LBB0_1: ## =\u003eThis Inner Loop Header: Depth=1 imulq %rdi, %rax decq %rdi cmpq $1, %rdi jg LBB0_1 popq %rbp retq switch 语句可以根据一个整数索引值进行多重分支 (multiway branching)。switch 会被转化成跳转表 (jump table)。跳转表示一个数组，表项 i 是一个代码段的地址，这个代码段实现当开关索引值等于 i 时程序应该采取的动作。程序代码用开关索引值来执行一个跳转表内的数组引用，确定跳转指令的目标。和使用一组很长的 if-else 语句对比，使用跳转表的优点是执行开关语句的时间与开关情况的数量无关。 C switch 代码: void switch_eg(long x, long n, long *dest) { long val = x; switch (n) { case 100: val *= 13; break; case 102: val += 10; case 103: val += 11; break; case 104: case 106: val *= val; break; default: val = 0; } *dest = val; } 生成汇编: .section __TEXT,__text,regular,pure_instructions .build_version macos, 10, 15, 4 sdk_version 10, 15, 4 .globl _switch_eg ## -- Begin function switch_eg .p2align 4, 0x90 _switch_eg: ## @switch_eg ## %bb.0: pushq %rbp movq %rsp, %rbp xorl %eax, %eax addq $-100, %rsi cmpq $6, %rsi ja LBB0_7 ## %bb.1: leaq LJTI0_0(%rip), %rcx movslq (%rcx,%rsi,4), %rsi addq %rcx, %rsi jmpq *%rsi LBB0_5: imulq %rdi, %rdi jmp LBB0_6 LBB0_2: leaq (%rdi,%rdi,2), %rax leaq (%rdi,%rax,4), %rax jmp LBB0_7 LBB0_3: addq $10, %rdi LBB0_4: addq $11, %rdi LBB0_6: movq %rdi, %rax LBB0_7: movq %rax, (%rdx) popq %rbp retq ","date":"2021-12-03","objectID":"/csapp/:2:6","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.7 过程 过程是软件中一种很重要的抽象。它提供了一种封装代码的方式，用一组指定的参数和一个可选的返回值实现了某种功能。然后，可以在程序中不同的地方调用这个函数。设计良好的如软件用过程作为抽象机制，隐藏某个行为的具体实现，同时又提供清晰简洁的接口定义，说明要计算的是哪些值，过程会对程序状态产生说明样的影响。 不同编程语言中，过程的形式: 函数 (function) 方法 (method) 子例程 (subroutine) 处理函数 (handler) 假设过程 P 调用过程 Q，Q 执行后返回 P。过程可能用到的一个或多个机制: 传递控制。在进入过程 Q 的时候，程序计数器必须被设置为 Q 的代码的起始地址，然后再返回时，要把程序计数器设置为 P 中调用 Q 后面那条指令的地址。 传递数据。P 必须能够向 Q 提供一个或多个参数，Q 必须能够向 P 返回一个值。 分配和释放内存。在开始是，Q 可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间。 3.7.1 传递控制 C 语言过程调用中使用栈数据结构提供的后进先出的内存管理原则。 程序可以用栈来管理它的过程所需要的存储空间，栈和程序寄存器存放这传递控制和数据、分配内存所需要的信息。当 P 调用 Q 时，控制和数据信息添加到栈尾。当 P 返回时，这些信息会释放掉。 当 x86-64 过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间。这个部分称为过程的栈帧(stack frame)。当前正在执行的过程的帧总是在栈顶。 3.7.2 转移控制 将控制从函数 P 转移到函数 Q 只需要简单地把程序计数器(PC)设置为 Q 的代码的起始位置。不过，当稍后从 Q 返回的时候，处理器必须记录好需要继续 P 的执行的代码位置。在 x86-64 机器中，这个信息是用指令 call Q 调用过程 Q 来记录的。该指令会把地址 A 压入栈中，并将 PC 设置为 Q 的起始地址。压入的地址 A 被称为返回地址，是紧跟在 call 指令后面的那条指令的地址。对应的指令 ret 会从栈中弹出地址 A，并把 PC 设置为 A。 call 指令有一个目标，即指明被调用过程起始的指令地址。同调整一样，调用可能是直接的，也可以是间接的。在汇编代码中，直接调用的目标是一个标号，而间接调用的目标是 * 后面跟讴歌操作数指示符。 3.7.3 数据创送 数据传送: 当调用一个过程时，除了要把控制传递给它并在过程返回时再传递回来之外，过程调用还可能包括吧数据作为参数传递，而从过程返回还有可能包括返回一个值。 x86-64中，可能通过寄存器最多传递 6 个整型(例如整数和指针)参数。寄存器的使用是由特殊顺序的，寄存器使用的名字取决于要传递的数据类型的大小。 如果一个函数有大于 6 个整型参数，超出 6 个的部分就要通过栈来传递。 void proc(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) { *a1p += a1; *a2p += a2; *a3p += a3; *a4p += a4; } 3.7.4 栈上的局部存储 需要栈上局部存储的情况: 寄存器不能足够存放素有的本地数据。 对一个局部变量使用地址运算符 ‘\u0026’, 因此必须能够为他产生一个地址。 某些局部变量是数组或结构，因此必须能够通过数据或结构引用被访问到。 long call_proc() { long x1 = 1; int x2 = 2; short x3 = 3; char x4 = 4; proc(x1, \u0026x1, x2, \u0026x2, x3, \u0026x3, x4, \u0026x4); // 创建栈帧 return (x1 + x2) * (x3 - x4); } 3.7.5 寄存器中的局部存储空间 寄存器组是唯一被所有过程共享的资源，为了防止寄存器的值在被一个过程使用时，不被其他过程调用导致值被覆盖，x86-64 采用一组统一的寄存器使用惯例: 寄存器 %rbx、%rbp 和 %r12~%r15 被划分为被调用者寄存器，Q 过程必须保证寄存器值的安全。 除了栈指针 %rsp, 都分类为调用者保存寄存器。 3.7.6 递归过程 递归调用一个函数本身与调用其他函数时一样的。栈规则提供了一种机制，每次函数调用都有它自己私有的状态信息(保存的返回位置和被调用者保存寄存器的值)存储空间。如果需要，它还可以提供局部变量的存储。栈分配和释放的规则很自然就与函数调用-返回的循序匹配。这种实现函数调用和返回的方法甚至对更复杂的情况也适用，暴扣互相递归调用。 long rfact(long n) { long result; if (n \u003c= 1) { result = 1; } else { result = n * rfact(n - 1); } return result; } 对应汇编代码: rfact: pushq %rbx movq %rdi, rbx movl $1, %eax cmpq $1, %rdi jle .L35 leaq -1(%rdi), %rdi call rfact imulq %rbx, %rax .L35: popq %rbx ret ","date":"2021-12-03","objectID":"/csapp/:2:7","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.8 数组分配和访问 C 语言的数组是一种将标量数据聚集成更大数据类型的方式。 3.8.1 基本原则 对于数据类型 T 和整型常数 N，声明如下: T A[N]; 起始位置表示为 $x_A$。这个声明有两个效果。首先，它在内存中分配一个 L·N 字节的连续区域。这里 L 是数据类型 T 的大小(单位为字节)。其次，它引入了标识符 A，可以用 A 来作为指向数组开头的指针，这个指针的值就是 $x_A$。可用用 0~N-1 的证书索引来访问该数组元素。数组元素 i 会被存放在地址为 $x_A$+L·i 的地方。 3.8.2 指针运算 C 语言允许对指针进行运算，而计算出来的值会根据该指针引用的数据类型的大小进行伸缩。也就是说，如果 p 是一个指向类型为 T 的数据的指针，p 的值为 $x_p$，那么表达式 p+i 的值为 $x_p$+L·i，这里 L 是数据类型 T 的大小。 单操作数操作符 ‘$’ 和 ‘* ’ 可以产生指针和间接引用指针。对于一个表示某个对象的表达式 Expr，\u0026Expr 是该对象的一个指针。对于一个表示地址的表达式 AExpr, *AExpr 是该地址的值。因此，表达式 Expr 与 * \u0026Expr 是等价的。可以对数组和指针应用数组下标操作。 3.8.3 嵌套数组 要访问多维数组的元素，编译器会以数组起始为基地址，偏移量为索引，产生计算期望的元素偏移量，然后使用某种 MOV 指令。 通常来说，对于一个声明如下的数组: T D[R][C] 的元素 D[i][j] 的内存地址为 $$ D[i][j] = x_D+L(C·i+j) $$ 3.8.4 定长数组 C语言编译器能够优化定长多维数组上的操作代码 ","date":"2021-12-03","objectID":"/csapp/:2:8","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.9 异质的数据结构 C 语言2提供了两种将不同类型的对象组合到一起创建数据类型的机制: 结构 (structure)，关键字 struct，将多个对象集合到一个单位中。 联合 (union)，用关键字 union 来声明，允许用几种不同的类型来引用一个对象。 3.9.1 结构 C 语言的 struct 声明创建一个数据类型，将可能不同类型的对象聚合到一个对象中。用名字来引用结构的各个组成部分。类似于数组的实现，结构的所有组成部分都存放在内存中一段连续的区域内，而指向结构的指针就是结构第一个字节的地址。 struct rect { int i; int j; int a[2]; int *p; }; 该结构在内存中的布局: 3.9.2 联合 联合提供了一种方式，能够规避 C 语言的类型系统，允许以多种类型来引用一个对象。一个联合的总的大小等于它最大字段的大小。 在一些上下文中，联合十分有用。但是，它也能引起一些讨厌的错误，因为他们绕过了 C 语言类型系统提供的安全措施。一种应用情况是，我们事先知道对一个数据结构中的两个不同字段的使用是互斥的，那么将这两个字段声明为联合的一部分，而不是结构的一部分，会减小分配空间的总量。 3.9.3 数据对齐 许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值 K (通常是2、4或8)的倍数。这种对齐限制简化了形成处理器和内存系统之间接口的硬件设计。 无论数据是否对齐，x86-64 硬件都能正确工作。不过，Intel 还是建议要对齐数据以提高内存系统的性能。对齐原则是任何 K 字节的基本对象的地址必须是 K 的倍数。 确保每种数据类型都是按照指定方式来组织和分配，即每种类型的对象都满足它的对齐限制，就可保证实施对齐。编译器在汇编代码中放入命令，指明全局数据所需的对齐。 .align 8 这命令就保证了它后面的数据的开始地址是 8 的倍数。因为每个表项长 8 个字节，后面的元素都会遵守 8 字节对齐的限制。 对于包含结构的代码，编译器可能需要在字段的分配中插入间隙，以保证每个结构元素都满足它的对齐要求。而结构本身对它的起始地址也有一些对齐要求。 假设如下的结构声明: struct S1 { int i; char c; int j; } 如果编译器用最小的9字节分配，内存布局会是这样: 但是它不满足字段 i 和 j 的4字节对齐要求，所以编译器在字段 c 和 j 之间插入一个 3 字节的间隙: ","date":"2021-12-03","objectID":"/csapp/:2:9","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.10 在机器级程序中将控制与数据结合起来 3.10.1 理解指针 一些指针和它们映射到机器代码的关键原则: 每个指针都对应一个类型。这个类型表明该指针指向的是哪一类对象。 每个指针都有一个值。这个值是某个指定类型的对象的地址。特殊的 NULL(0) 值表示该指针没有指向任何地方。 指针用 ‘\u0026’ 运算符创建。 *操作符用于间接引用指针。其结果是一个值，它的类型与该指针的类型一致。间接引用是用内存来实现的，要么是存储到一个指定的地址，要么是从指定的地址读取。 数组与指针紧密联系。一个数组的名字可以像一个指针变量一样引用(但是不能修改)。 将指针从一种类型强制转化成另一个类型，只改变它的类型，而不改变它的值。强制类型转换的一个效果是改变指针运算的伸缩。 指针也可以指向函数。这提供了一个很强大的存储和向代码传递引用的功能，这个引用可以被程序的某个其他部分调用。 函数指针: #include \u003cstdio.h\u003e int fun(int x, int *p); int (*fp)(int, int *); int main() { fp = fun; int y = 1; int result = fp(3, \u0026y); printf(\"%d\\n\", result); } int fun(int x, int *p) { *p += x; return *p; } ","date":"2021-12-03","objectID":"/csapp/:2:10","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.11 浮点代码 处理器的浮点系统结构包括多个方面，会影响对浮点数据操作的程序如何被映射到机器上，包括: 如何存储和访问浮点数据。通常是通过某种寄存器方式来完成。 对浮点数据操作的指令。 向函数传递浮点数参数和从函数返回浮点数结构的规则。 函数调用过程中保存寄存器的规则。 x86-64 浮点体系结构的历史: 如图所示，AVX 浮点体系结构允许数据存储在 16 个 YMM 寄存器中，名字是 %ymm0~%ymm15。每个 YMM 寄存器都是 256(32 字节)。当对标量数据操作时，这些寄存器值保存浮点数，而且只使用低 32 位(对于 float) 或 64 位(对于 double)。汇编代码用寄存器的 SSE XMM 寄存器名字 %xmm0~%xmm15 来引用它们，每个 XMM 寄存器都是对应的 YMM 寄存器的低 128 位(16字节)。 3.11.1 浮点传送和转化操作 GCC 只用标量传送操作从内存传送数据到 XMM 寄存器或从 XMM 寄存器传送数据到内存。对于在两个 XMM 寄存器之间传送数据，GCC 会使用两种指令之一，即用 vmpovaps 传送单精度数，用 vmovapd 传送双精度数。对于这些情况，程序复制整个寄存器还是只复制低位值。既不会影响程序功能，也不会影响执行速度，所以使用这些指令还是针对标量数据的人指令没有实质上的差别。指令名字中的字母 ‘a’ 表示 “aligned(对齐的)\"。当用于读写内存是，如果地址不满足16字节对齐，它们会导致异常。在两个寄存器之间传送数据，绝不会出现错误对齐的状况。 浮点数和整数数据类型之间以及不同浮点格式之间进行转换的指令集合。 把一个从 XMM 寄存器或内存中读出的浮点值进行转换，并将结果写入一个通用寄存器。把浮点值转换成整数时，指令会执行截断(truncation)，把值向 0 进行舍入。 3.11.2 过程中的浮点代码 在 x86-64 中，XMM 寄存器用来向函数传递浮点参数，以及从函数返回浮点值。具有以下规则: XMM 寄存器 %xmm0~%xmm7 最多可以传递 8 个浮点参数。按照参数列出的顺序使用这些寄存器。可以通过栈传递额外的浮点参数。 函数使用寄存器 %xmm0 来返回浮点值。 所有的 XMM 寄存器都是调用者保存的。被调用者可以不同保存就覆盖这些寄存器中任意一个。 当函数包含指针、整数和浮点数混合的参数时，指针和整数通过通用寄存器传递，而浮点值通过 XMM 寄存器传递。也就是说，参数到寄存器的映射取决于它们的类型和排列的顺序。例如: // 这个函数会把 x 存放在 %edi 中，y 放在 %xmm0 中，z 放在 %rsi 中。 double f1(int x, double y, long z); // 这个函数的寄存器分配与函数 f1 相同。 double f2(double y, int x, long z); // 这个函数会将 x 放在 %xmm0 中，y 放在 %rdi 中，z 放在 %rsi 中。 double f1(float x, double *y, long *z); 3.11.3 浮点运算操作 下图描述了一组执行算术运算的标量 AVX2 浮点指令。每条指令有一个($S_1$)或两个($S_1, S_2$)，和一个目的操作数 D。第一个源操作数 $S_1$ 可以是一个 XMM 寄存器或一个内存位置。第二个源操作数和目的操作数都必须是 XMM 寄存器。每个操作多有一条针对当精度的指令和一条针对双精度的指令。结果存放在目的寄存器中。 3.11.4 定义和使用浮点常数 和整数运算操作不同，AVX 浮点操作不能以立即数值作为操作数。相反，编译器必须为所有的常量值分配和初始化存储空间。然后代码再把这些值从内存读入。 3.11.5 在浮点代码中使用位级操作 3.11.6 浮点比较操作 浮点比较指令会设置三个条件码: 零标志位 ZF, 进位标志位 CF 和奇偶标志位 PF。 ","date":"2021-12-03","objectID":"/csapp/:2:11","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"}]