[{"categories":null,"content":"Aix添加和删除Iscsi存储卷 Aix为6.1版本 使用iscsi存储 首先需要创建一个iscsi target，并共享到IBM Aix上。 ","date":"2021-12-03","objectID":"/aix1/:0:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"检查iscsi是否被安装 $ lslpp -L | grep -i iscsi devices.common.IBM.iscsi.rte 6.1.5.0 C F Common iSCSI Files devices.iscsi.disk.rte 6.1.5.0 C F iSCSI Disk Software ... ","date":"2021-12-03","objectID":"/aix1/:1:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"配置iscsi $ vi /etc/iscsi/targets ... # 添加target 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup ","date":"2021-12-03","objectID":"/aix1/:2:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"重新扫盘 $ cfgmgr -l iscsi0 cfgmgr: 0514-621 WARNING: The following device packages are required for device support but are not currently installed. devices.iscsi.array ","date":"2021-12-03","objectID":"/aix1/:3:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"查看iscsi盘 $ lsdev -Cc disk | grep iSCSI hdisk18 Available Other iSCSI Disk Drive ","date":"2021-12-03","objectID":"/aix1/:4:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建物理卷 $ chdev -l hdisk18 -a pv=yes ","date":"2021-12-03","objectID":"/aix1/:5:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建vg $ mkvg -y wbrt_portal_bg hdisk18 ","date":"2021-12-03","objectID":"/aix1/:6:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建lv $ mklv -t jfs2 -y wbrt_portal_bl wbrt_portal_bg 700 注:lv的大小可以使用命令 $ lsvg wbrt_portal_bg | grep \"TOTAL PPs\" | awk -F' ' '{ print $6}' 703 但不要全部使用，需要一些剩余空间。 ","date":"2021-12-03","objectID":"/aix1/:7:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"创建挂载目录 $ mkdir /mnt/iscsi ","date":"2021-12-03","objectID":"/aix1/:8:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"格式化并挂载 $ crfs -v jfs2 -m /mnt/iscsi -d wbrt_portal_bl $ mount /mnt/iscsi 删除存储盘 ","date":"2021-12-03","objectID":"/aix1/:9:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"卸载磁盘 $ umount /mnt/iscsi ","date":"2021-12-03","objectID":"/aix1/:10:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"lv $ rmlv wbrt_portal_bl ","date":"2021-12-03","objectID":"/aix1/:11:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除文件系统 $ rmfs -r /dev/wbrt_portal_bl ","date":"2021-12-03","objectID":"/aix1/:12:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除vg $ reducevg -d wbrt_portal_bg hdisk18 ","date":"2021-12-03","objectID":"/aix1/:13:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除物理盘 $ rmdev -dl hdisk18 -R ","date":"2021-12-03","objectID":"/aix1/:14:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"删除iscsi target $ vi /etc/iscsi/targets ... # 添加target # 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup 重读磁盘 $ cfgmgr -l iscsi0 ","date":"2021-12-03","objectID":"/aix1/:15:0","tags":null,"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":null,"content":"C++友元 友元说明 相对于其他的编程语言，“友元”是C++中特别的一种语法。那它有什么作用呢？ 其实“友元”就是提供一种访问类私有部分的的方法。如果没有“友元”，我们只能通过类本身提供的公有方法来访问，但相对地，这样限制太高了，所以“友元”就是一种的在类的封装性和实用性中很好的“折中”方式。 C++中的友元有三种： 友元函数 友元类 友元成员函数 C++中使用关键字friend来定义。 友元函数 这里直接用代码来说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p(\"xingyys\", \"123456\"); getPerson(p); return 0; } 这个例子还是比较简单的，只要在指定的方法中添加关键字就可以实现了。 友元类 在来一个例子说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Tv { private: int state; int volume; int maxchannel; int channel; int mode; int input; public: // 在这里指定谁是他的友元 friend class Remote; enum { Off, On }; enum { MinVal, MaxVal = 20 }; enum { Antenna, Cable }; enum { TV, DVD }; Tv(int s = Off, int mc = 125) : state(s), volume(5), maxchannel(mc), channel(2), mode(Cable), input(TV) {} void onoff() { state = (state == On) ? Off : On; } bool ison() const { return state == On; } bool volup(); bool voldown(); void chanup(); void chandown(); void set_mode() { mode = (mode == Antenna) ? Cable : Antenna; } void set_input() { input = (input == TV) ? DVD : TV; } void settings() const; }; class Remote { private: int mode; public: Remote(int m = Tv::TV) : mode(m) {} bool volup(Tv \u0026t) { return t.volup(); } bool voldown(Tv \u0026t) { return t.voldown(); } void onoff(Tv \u0026t) { t.onoff(); } void chanup(Tv \u0026t) { t.chanup(); } void chandown(Tv \u0026t) { t.chandown(); } void set_chan(Tv \u0026t, int c) { t.channel = c; } void set_mode(Tv \u0026t) { t.set_mode(); } void set_input(Tv \u0026t) { t.set_input(); } }; bool Tv::volup() { if (volume \u003c MaxVal) { volume++; return true; } else { return false; } } bool Tv::voldown() { if (volume \u003e MinVal) { volume--; return true; } else { return false; } } void Tv::chanup() { if (channel \u003c maxchannel) channel++; else channel = 1; } void Tv::chandown() { if (channel \u003e 1) channel--; else channel = maxchannel; } void Tv::settings() const { using std::cout; using std::endl; cout \u003c\u003c \"TV is \" \u003c\u003c (state == Off ? \"Off\" : \"On\") \u003c\u003c endl; if (state == On) { cout \u003c\u003c \"Volume setting = \" \u003c\u003c volume \u003c\u003c endl; cout \u003c\u003c \"Channel setting = \" \u003c\u003c channel \u003c\u003c endl; cout \u003c\u003c \"Mode = \" \u003c\u003c (mode == Antenna ? \"antenna\" : \"cable\") \u003c\u003c endl; cout \u003c\u003c \"Input = \" \u003c\u003c (input == TV ? \"TV\" : \"DVD\") \u003c\u003c endl; } } int main() { using std::cout; Tv s42; cout \u003c\u003c \"Initial setting for 42\\\"TV:\\n\"; s42.settings(); s42.onoff(); s42.chanup(); cout \u003c\u003c \"\\nAdjusted setting for 42\\\"TV:\\n\"; s42.chanup(); cout \u003c\u003c \"\\nAdjusted settings for 42\\\"TV:\\n\"; s42.settings(); Remote grey; grey.set_chan(s42, 10); grey.volup(s42); grey.volup(s42); cout \u003c\u003c \"\\n42\\\"setting after using remote:\\n\"; s42.settings(); Tv s58(Tv::On); s58.set_mode(); grey.set_chan(s58, 28); cout \u003c\u003c \"\\n58\\\"settings:\\n\"; s58.settings(); return 0; } 友元成员函数 #include \u003ciostream\u003e#include \u003cstring\u003e class Person; class Point { public: void getPerson(Person \u0026p); }; class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void Point::getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void Point::getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p (\"xingyys\", \"123456\"); Point pt; pt.getPerson(p); return 0; } 补充 不能定义类的对象。 可以用于定义指向这个类型的指针或引用。 用于声明(不是定义)，使用该类型作为形参类型或者函数的返回值类型。 友元关系不能被继承。 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明 ","date":"2021-12-03","objectID":"/c-%E5%8F%8B%E5%85%83/:0:0","tags":null,"title":"C++友元","uri":"/c-%E5%8F%8B%E5%85%83/"},{"categories":null,"content":"CentOS7 安装 qemu-5.2.0 本文介绍在 CentOS7.9 上编译安装 qemu-5.2.0 安装 Python3 编译安装 qemu-5.2.0 依赖 Python3.6 及以上的版本。所以首先安装 Python3.6。这里选择编译安装。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:0:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"下载 Python3.6.12 从 Python 官网下载 Python3.6.12 源码包： wget https://www.python.org/ftp/python/3.6.12/Python-3.6.12.tar.xz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:1:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"解压 tar -xvf Python-3.6.12.tar.gz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:2:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"安装 openssl pip 下载是需要 ssl 支持，所以下载 openssl yum install -y openssl openssl-devel zlib-devel bzip2-devel bzip2 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:3:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"编译安装 cd Python-3.6.12 ./configure --prefix=/usr/local/python3 --enable-optimizations make -j8 build_all \u0026\u0026 make -j8 install ","date":"2021-12-03","objectID":"/centos7_install_qemu/:4:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"设置软链接 ln -s /usr/local/python3/bin/python3 /usr/bin/python3 ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:5:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"验证 # python3 Python 3.6.12 (default, Dec 27 2020, 07:52:33) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e 安装 ninja qemu-5.2.0 编译时使用构建工具 ninja 下载 ninja git clone git://github.com/ninja-build/ninja.git \u0026\u0026 cd ninja ./configure.py --bootstrap cp ninja /usr/bin/ 使用 ninja --version, 验证 ninja 版本: # ninja --version 1.10.2.git 编译安装 qemu-5.2.0 完成以上步骤之后就可以开始安装qemu了。其实可以通过 yum 安装，但是会缺少一些二进制文件。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:6:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"安装依赖 首先安装 qemu-5.2.0 所需的依赖，这里追加一个小提示： CentOS7 编译安装软件时经常需要安装对应的依赖。编译过程中如果发现缺少依赖，则编译后报错并退出，这时候就需要安装依赖包。以qemu-5.2.0安装为例，编译时提示缺少 glib2 包。这时候不是下载 glib2，而是下载对应的开发包，CentOS里是 glib2-devel，Ubuntu 下则是 glib2-dev。 yum install -y pkgconfig-devel glib2-devel pixman-devel 这里提供的依赖可能补全，编译过程中如果提示缺少依赖，请根据以上给出的提示安装对应依赖。 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:7:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"下载 qemu-5.2.0 在 qemu 官网下载源码包 wget https://download.qemu.org/qemu-5.2.0.tar.xz ","date":"2021-12-03","objectID":"/centos7_install_qemu/:8:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"编译安装 tar xvJf qemu-5.2.0.tar.xz cd qemu-5.2.0 ./configure --enable-debug --target-list=x86_64-softmmu --enable-kvm make \u0026\u0026 make install ","date":"2021-12-03","objectID":"/centos7_install_qemu/:9:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"验证 # qemu- qemu-edid qemu-img qemu-nbd qemu-storage-daemon qemu-ga qemu-io qemu-pr-helper qemu-system-x86_64 ","date":"2021-12-03","objectID":"/centos7_install_qemu/:10:0","tags":null,"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":null,"content":"CentOS下kvm安装 注：运行kvm保证机器支持虚拟化且在bios中开启。 准备工作 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:0:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"清除iptables规则 # CentOS6 service iptables stop; service iptables save # CentOS7 systemctl stop firewalld ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:1:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"关闭selinux sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config setenforce 0 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:2:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"检测系统是否支持虚拟化 grep -Ei 'vmx|svm' /proc/cpuinfo 如果有输出内容，则支持，其中intel cpu支持会有vmx，amd cpu支持会有svm 安装 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:3:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"执行安装命令 yum install -y kvm virt-* libvirt bridge-utils qemu-img 说明： kvm:软件包中含有KVM内核模块，它在默认linux内核中提供kvm管理程序 libvirt:安装虚拟机管理工具，使用virsh等命令来管理和控制虚拟机。 bridge-utils:设置网络网卡桥接。 virt-*:创建、克隆虚拟机命令，以及图形化管理工具virt-manager qemu-img:安装qemu组件，使用qemu命令来创建磁盘等。 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:4:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"检查kvm模块是否加载 lsmod |grep kvm 结果输出： kvm_intel 55496 3 kvm 337772 1 kvm_intel 如果没有，需要执行，还没有就重启一下试试 modprobe kvm-intel ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:5:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"配置网卡 cd /etc/sysconfig/network-scripts/ cp ifcfg-eth0 ifcfg-br0 编辑eth0 DEVICE=eth0 HWADDR=00:0C:29:55:A7:0A TYPE=Ethernet UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none BRIDGE=br0 编辑br0 DEVICE=br0 #HWADDR=00:0C:29:55:A7:0A TYPE=Bridge #UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=192.168.11.17 NETMASK=255.255.255.0 GATEWAY=192.168.11.1 DNS1=202.106.0.20 记得重启网卡：/etc/init.d/network restart br0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet addr:192.168.11.17 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:141326 errors:0 dropped:0 overruns:0 frame:0 TX packets:90931 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:456024940 (434.8 MiB) TX bytes:10933593 (10.4 MiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:341978 errors:0 dropped:0 overruns:0 frame:0 TX packets:90946 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:468848861 (447.1 MiB) TX bytes:10934699 (10.4 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) virbr0 Link encap:Ethernet HWaddr 52:54:00:14:EF:D5 inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:6:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"启动服务 /etc/init.d/libvirtd start /etc/init.d/messagebus restart 此时可以查看网络接口列表 $ brctl show bridge name bridge id STP enabled interfaces br0 8000.000c2955a70a no eth0 virbr0 8000.52540014efd5 yes virbr0-nic 创建虚拟机 创建一个存储虚拟机虚拟磁盘的目录，该目录所在分区必须足够大 mkdir /data/ 执行命令： virt-install \\ --name ping \\ --ram 512 \\ --disk path=/data/ping.img,size=20 \\ --vcpus 1 \\ --os-type linux \\ --os-variant rhel6 \\ --network bridge=br0 \\ --graphics none \\ --console pty,target_type=serial \\ --location 'http://mirrors.163.com/centos/6.8/os/x86_64/' \\ --extra-args 'console=ttyS0,115200n8 serial' 说明： –name 指定虚拟机的名字 –ram 指定内存分配多少 –disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –vcpus 指定分配cpu几个 –os-type 指定系统类型为linux –os-variant 指定系统版本 –network 指定网络类型 –graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 –console 指定控制台类型 –location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS 之后就出现： 开始安装...... 搜索文件 .treeinfo...... | 720 B 00:00 ... 搜索文件 vmlinuz...... | 7.7 MB 00:02 ... 搜索文件 initrd.img...... | 63 MB 00:23 ... 创建存储文件 ping.img | 30 GB 00:00 创建域...... | 0 B 00:00 连接到域 ping Escape character is ^] 然后就是我们非常熟悉的OK or Next 了 ，只不过这个过程是文本模式，如果想使用图形，只能开启vnc啦 最后安装完，reboot就进入刚刚创建的虚拟机了。要想退回到宿主机，ctrl + ] 即可。 virsh list 可以列出当前的子机列表。 virsh start ping 开启子机 virsh console ping 可以进入指定的子机 使用python管理API ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:7:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装相关包 yum install libvirt-devel ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:8:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装python的libvirt库 pip install libvirt-python libvirt ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:9:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"测试 import libvirt conn = libvirt.open(\"qemu:///system\") ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:10:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"远程管理 直接上述安装还只能在本地使用python管理。如果还需要远程管理的话还要额外的配置。 修该配置文件/etc/libvirt/libvirtd.conf ###/etc/libvirt/libvirtd.conf listen_tls = 0　#禁用tls登录 listen_tcp = 1　#启用tcp方式登录 tcp_port = \"16509\"　#tcp端口16509 listen_addr = \"0.0.0.0\" unix_sock_group = \"libvirtd\" unix_sock_rw_perms = \"0770\" auth_unix_ro = \"none\" auth_unix_rw = \"none\" auth_tcp = \"none\"　#TCP不使用认证 max_clients = 1024　#最大总的连接客户数1024 min_workers = 50　#libvirtd启动时，初始的工作线程数目 max_workers = 200　#同上，最大数目 max_requests = 1000　#最大同时支持的RPC调用，必须大于等于max_workers max_client_requests = 200　#每个客户端支持的最大连接数 修改配置文件/etc/sysconfig/libvirtd： LIBVIRTD_ARGS=\"--listen\" 重启服务后libvirtd会绑定在16509端口 在远程的机器上安装python库 yum install libvirt-devel python-devel # 要先安装libvirt-devel包，因为libvirt-python依赖于libvirt-devel pip install libvirt libvirt-python 测试代码： import libvirt conn = libvirt.open(\"qemu+tcp://192.168.11.17/system\") 没有报错，安装完毕。 ","date":"2021-12-03","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:11:0","tags":null,"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"Containerd源码分析 从 Kubernetes 1.22 开始，k8s 的容器运行是默认替换成 containerd。有必要深入了解 containerd 的内部实现原理。本篇通过分析 containerd 的代码深入理解其内部原理。 使用的版本为 containerd 1.5。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"配置环境 下载 containerd 源码: git clone github.com/containerd/containerd 启动 goland 的远程调试功能 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:1:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"入口 先来从 main 函数来看启动流程。从以下目录结构中可以看出来，containerd 项目目录中包含一个守护进程和对应的执行工具。 cmd ├── containerd // containerd CRI 实现，对外提供容器服务，对内和 containerd-shim-runc 通讯 ├── containerd-shim ├── containerd-shim-runc-v1 // 负责和 runc 通信，管理容器实例 ├── containerd-shim-runc-v2 // v2 版本 ├── containerd-stress ├── ctr // containerd 客户端命令行工具 ├── gen-manpages └── protoc-gen-gogoctrd 以下是它们之间的调用流程图: ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:2:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"containerd containerd 本身是一个命令行工具实现，入口文件为 cmd/containerd/main.go func main() { app := command.App() if err := app.Run(os.Args); err != nil { fmt.Fprintf(os.Stderr, \"containerd: %s\\n\", err) os.Exit(1) } } ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"command app containerd 包含三个子命令: configCommand: 输出 containerd 默认配置文件 publishCommand: 向 containerd 服务发布一个事件 ociHook: 启动一个 oci 钩子 app.Action 中定义了 containerd 的启动流程： ... app.Action = func(context *cli.Context) error { ... // 加载配置文件 configPath := context.GlobalString(\"config\") ... // 通过配置文件创建 server，server 中包含 ttrpc、grpc、tcp、metrics server, err := server.New(ctx, config) ... ... // 启动 ttrpc 服务 serve(ctx, tl, server.ServeTTRPC) ... if config.GRPC.TCPAddress != \"\" { l, err := net.Listen(\"tcp\", config.GRPC.TCPAddress) if err != nil { return errors.Wrapf(err, \"failed to get listener for TCP grpc endpoint\") } // 启动 tcp 服务 serve(ctx, l, server.ServeTCP) } ... // 启动 grpc 服务 serve(ctx, l, server.ServeGRPC) ... return nil } ... 再来看 server.New，它创建 containerd 服务: func New(ctx context.Context, config *srvconfig.Config) (*Server, error) { ... // 从配置文件中加载插件 plugins, err := LoadPlugins(ctx, config) if err != nil { return nil, err } ... // 循环确认插件类型，并解析。 for _, p := range plugins { id := p.URI() reqID := id if config.GetVersion() == 1 { reqID = p.ID } log.G(ctx).WithField(\"type\", p.Type).Infof(\"loading plugin %q...\", id) initContext := plugin.NewContext( ctx, p, initialized, config.Root, config.State, ) initContext.Events = s.events initContext.Address = config.GRPC.Address initContext.TTRPCAddress = config.TTRPC.Address // load the plugin specific configuration if it is provided if p.Config != nil { pc, err := config.Decode(p) if err != nil { return nil, err } initContext.Config = pc } result := p.Init(initContext) if err := initialized.Add(result); err != nil { return nil, errors.Wrapf(err, \"could not add plugin result to plugin set\") } instance, err := result.Instance() if err != nil { if plugin.IsSkipPlugin(err) { log.G(ctx).WithError(err).WithField(\"type\", p.Type).Infof(\"skip loading plugin %q...\", id) } else { log.G(ctx).WithError(err).Warnf(\"failed to load plugin %s\", id) } if _, ok := required[reqID]; ok { return nil, errors.Wrapf(err, \"load required plugin %s\", id) } continue } delete(required, reqID) // check for grpc services that should be registered with the server if src, ok := instance.(plugin.Service); ok { grpcServices = append(grpcServices, src) } if src, ok := instance.(plugin.TTRPCService); ok { ttrpcServices = append(ttrpcServices, src) } if service, ok := instance.(plugin.TCPService); ok { tcpServices = append(tcpServices, service) } s.plugins = append(s.plugins, result) } // 注册服务 // register services after all plugins have been initialized for _, service := range grpcServices { if err := service.Register(grpcServer); err != nil { return nil, err } } for _, service := range ttrpcServices { if err := service.RegisterTTRPC(ttrpcServer); err != nil { return nil, err } } for _, service := range tcpServices { if err := service.RegisterTCP(tcpServer); err != nil { return nil, err } } return s, nil } 由此可知，containerd 中的服务都是通过插件加载的，插件的加载代码统一存放在 cmd/containerd/containerd 目录下的 builtins*.go 文件中。 其中包含以下几种服务: container content diff images events introspection leases namespaces snapshots tasks ttrpc version 具体的代码存放在 services 目录下，接下来我们来看 images 和 container 这两个最重要的服务。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:1","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"镜像操作 containerd 作为 docker 的替代者，理所当然的需要实现 docker 的核心功能 OCI。images 服务包含: Get : 通过名称获取单个镜像 List : 获取镜像列表 Create : 创建一个镜像 Update : 更新镜像 Delete : 通过名称删除镜像 具体代码请看 services/images/local.go: // 初始化，注册成插件 func init() { plugin.Register(\u0026plugin.Registration{ Type: plugin.ServicePlugin, // 插件类型 ID: services.ImagesService, // 插件名称 Requires: []plugin.Type{ plugin.MetadataPlugin, // 依赖的插件 plugin.GCPlugin, }, InitFn: func(ic *plugin.InitContext) (interface{}, error) { // 初始化方法 m, err := ic.Get(plugin.MetadataPlugin) // 获取 plugin.MetadataPlugin 插件，作为存储，内部使用 bblot 实现 if err != nil { return nil, err } g, err := ic.Get(plugin.GCPlugin) // GC 插件，用于资源回收 if err != nil { return nil, err } return \u0026local{ store: metadata.NewImageStore(m.(*metadata.DB)), publisher: ic.Events, // 内部的订阅发布模型 gc: g.(gcScheduler), // gc 调度器 }, nil }, }) } // images 服务的具体实现 type local struct { store images.Store // 内部存储器 gc gcScheduler // gc 调度器 publisher events.Publisher // 内部的订阅发布模型 } var _ imagesapi.ImagesClient = \u0026local{} ... 这里我们可以把 images 的操作分为读取和修改两组。Get 和 List 为读取操作，就是从数据库中读取相关记录。 ... func (l *local) Get(ctx context.Context, req *imagesapi.GetImageRequest, _ ...grpc.CallOption) (*imagesapi.GetImageResponse, error) { image, err := l.store.Get(ctx, req.Name) if err != nil { return nil, errdefs.ToGRPC(err) } imagepb := imageToProto(\u0026image) return \u0026imagesapi.GetImageResponse{ Image: \u0026imagepb, }, nil } func (l *local) List(ctx context.Context, req *imagesapi.ListImagesRequest, _ ...grpc.CallOption) (*imagesapi.ListImagesResponse, error) { images, err := l.store.List(ctx, req.Filters...) if err != nil { return nil, errdefs.ToGRPC(err) } return \u0026imagesapi.ListImagesResponse{ Images: imagesToProto(images), }, nil } ... Create、Update 和 Delete 是修改操作，核心是通过 events.Publisher 发布事件对应的事件 // services/images/local.go func (l *local) Create(ctx context.Context, req *imagesapi.CreateImageRequest, _ ...grpc.CallOption) (*imagesapi.CreateImageResponse, error) { ... if err := l.publisher.Publish(ctx, \"/images/create\", \u0026eventstypes.ImageCreate{ Name: resp.Image.Name, Labels: resp.Image.Labels, }); err != nil { return nil, err } ... return \u0026resp, nil } 而真正处理该事件的订阅者则是 containerd 实现的 CRI 接口服务 。 // pkg/cri/server/service.go ... // criService implements CRIService. type criService struct { ... } ... cri 启动时，订阅 containerd 事件，并启动事件处理协程: // pkg/cri/server/service.go // Run starts the CRI service. func (c *criService) Run() error { logrus.Info(\"Start subscribing containerd event\") c.eventMonitor.subscribe(c.client) ... // Start event handler. logrus.Info(\"Start event monitor\") eventMonitorErrCh := c.eventMonitor.start() ... } eventMonitor.start() 内部处理逻辑如下: func (em *eventMonitor) start() \u003c-chan error { ... go func() { defer close(errCh) for { select { case e := \u003c-em.ch: logrus.Debugf(\"Received containerd event timestamp - %v, namespace - %q, topic - %q\", e.Timestamp, e.Namespace, e.Topic) if e.Namespace != constants.K8sContainerdNamespace { logrus.Debugf(\"Ignoring events in namespace - %q\", e.Namespace) break } id, evt, err := convertEvent(e.Event) if err != nil { logrus.WithError(err).Errorf(\"Failed to convert event %+v\", e) break } if em.backOff.isInBackOff(id) { logrus.Infof(\"Events for %q is in backoff, enqueue event %+v\", id, evt) em.backOff.enBackOff(id, evt) break } if err := em.handleEvent(evt); err != nil { logrus.WithError(err).Errorf(\"Failed to handle event %+v for %s\", evt, id) em.backOff.enBackOff(id, evt) } case err := \u003c-em.errCh: ... case \u003c-backOffCheckCh: ... } } }() return errCh } namespace 不为 k8s.io 时事件都会被忽略。 criService 一共处理五类事件: TaskExit TaskOOM ImageCreate ImageUpdate ImageDelete // pkg/cri/server/event.go // handleEvent handles a containerd event. func (em *eventMonitor) handleEvent(any interface{}) error { ... switch e := any.(type) { case *eventtypes.TaskExit: ... case *eventtypes.TaskOOM: ... case *eventtypes.ImageCreate: logrus.Infof(\"ImageCreate event %+v\", e) return em.c.updateImage(ctx, e.Name) case *eventtypes.ImageUpdate: logrus.Infof(\"ImageUpdate event %+v\", e) return e","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"容器操作 介绍完镜像操作后，接下来就是关于容器部分的操作。以下我们通过一段代码来探究 containerd 内部的容器管理方式: package main import ( \"context\" \"log\" \"syscall\" \"github.com/containerd/containerd\" \"github.com/containerd/containerd/cio\" \"github.com/containerd/containerd/namespaces\" \"github.com/containerd/containerd/oci\" ) func main() { client, err := containerd.New(\"/run/containerd/containerd.sock\", containerd.WithDefaultNamespace(\"default\")) if err != nil { log.Fatal(err) } defer client.Close() ctx := context.Background() log.Println(\"get image\") img, err := client.GetImage(ctx, \"docker.io/library/redis:alpine3.14\") if err != nil { log.Fatal(err) } log.Println(\"new container\") ctx = namespaces.WithNamespace(ctx, \"default\") c, err := client.NewContainer(ctx, \"redis\", containerd.WithNewSnapshot(\"redis-rootfs\", img), containerd.WithNewSpec(oci.WithImageConfig(img)), ) if err != nil { log.Fatalf(\"new container: %v\", err) } defer c.Delete(ctx) log.Println(\"new task\") task, err := c.NewTask(ctx, cio.NewCreator(cio.WithStdio)) if err != nil { log.Fatal(err) } pid := task.Pid() log.Printf(\"redis running in pid=%d\\n\", pid) err = task.Start(ctx) if err != nil { log.Fatalf(\"start task: %v\", err) } err = task.Kill(ctx, syscall.SIGINT) if err != nil { log.Fatalf(\"kill task: %v\", err) } for { status, _ := task.Status(ctx) if status.Status == containerd.Stopped { break } } _, err = task.Delete(ctx) if err != nil { log.Fatalf(\"delete task: %v\", err) } } containerd 中创建一个容器之后，如果要运行这个容器，就需要创建一个 task 用来管理容器的生命周期。可以理解为 task 就是 containerd 的运行时。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"创建 创建容器如下: // services/containers/local.go func (l *local) Create(ctx context.Context, req *api.CreateContainerRequest, _ ...grpc.CallOption) (*api.CreateContainerResponse, error) { var resp api.CreateContainerResponse if err := l.withStoreUpdate(ctx, func(ctx context.Context) error { container := containerFromProto(\u0026req.Container) created, err := l.Store.Create(ctx, container) if err != nil { return err } resp.Container = containerToProto(\u0026created) return nil }); err != nil { return \u0026resp, errdefs.ToGRPC(err) } if err := l.publisher.Publish(ctx, \"/containers/create\", \u0026eventstypes.ContainerCreate{ ID: resp.Container.ID, Image: resp.Container.Image, Runtime: \u0026eventstypes.ContainerCreate_Runtime{ Name: resp.Container.Runtime.Name, Options: resp.Container.Runtime.Options, }, }); err != nil { return \u0026resp, err } return \u0026resp, nil } 逻辑很简单，就是保存数据到内部存储中，再发布创建容器的事件。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:1","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"启动 启动容器需要先创建一个 task，使用 task 来管理容器 // services/tasks/local.go ... func (l *local) Create(ctx context.Context, r *api.CreateTaskRequest, _ ...grpc.CallOption) (*api.CreateTaskResponse, error) { ... // 创建容器运行时 c, err := rtime.Create(ctx, r.ContainerID, opts) if err != nil { return nil, errdefs.ToGRPC(err) } if err := l.monitor.Monitor(c); err != nil { return nil, errors.Wrap(err, \"monitor task\") } return \u0026api.CreateTaskResponse{ ContainerID: r.ContainerID, Pid: c.PID(), }, nil } // runtime/v2/manager.go // Create a new task func (m *TaskManager) Create(ctx context.Context, id string, opts runtime.CreateOpts) (_ runtime.Task, retErr error) { // 在磁盘上新建一个约束目录 bundle, err := NewBundle(ctx, m.root, m.state, id, opts.Spec.Value) ... // 创建启动一个 containerd-shim-runc-v2 管理容器运行时 shim, err := m.startShim(ctx, bundle, id, opts) ... // 创建一个 task t, err := shim.Create(ctx, opts) ... // 添加 task if err := m.tasks.Add(ctx, t); err != nil { return nil, errors.Wrap(err, \"failed to add task\") } return t, nil } 内部维护一个 TaskManager 来管理 tasks // runtime/v2/manager.go // TaskManager manages v2 shim's and their tasks type TaskManager struct { root string state string containerdAddress string containerdTTRPCAddress string tasks *runtime.TaskList events *exchange.Exchange containers containers.Store } containerd 服务和 containerd-shim-runc-v2 使用 ttrpc 通讯。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:2","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"停止 如何停止一个容器呢? // services/tasks/local.go func (l *local) Kill(ctx context.Context, r *api.KillRequest, _ ...grpc.CallOption) (*ptypes.Empty, error) { t, err := l.getTask(ctx, r.ContainerID) if err != nil { return nil, err } p := runtime.Process(t) if r.ExecID != \"\" { if p, err = t.Process(ctx, r.ExecID); err != nil { return nil, errdefs.ToGRPC(err) } } if err := p.Kill(ctx, r.Signal, r.All); err != nil { return nil, errdefs.ToGRPC(err) } return empty, nil } // runtime/v2/shim.go func (s *shim) Kill(ctx context.Context, signal uint32, all bool) error { if _, err := s.task.Kill(ctx, \u0026task.KillRequest{ ID: s.ID(), Signal: signal, All: all, }); err != nil { return errdefs.FromGRPC(err) } return nil } 从 containerd tasks 服务中获取 tasks 信息，然后通过 ttrpc 连接 containerd-shim-runc-v2 并杀死进程。 containerd-shim-runc-v2 支持以下接口 Create Delete Exec State Pause Resume Kill Pids CloseIO CheckPoint Update ResizePty ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:3","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"插件机制 containerd 内部服务都是通过插件方式注册。注册插件代码如下: // services/server/tasks/local.go func init() { plugin.Register(\u0026plugin.Registration{ Type: plugin.ServicePlugin, ID: services.TasksService, Requires: tasksServiceRequires, InitFn: initFunc, }) timeout.Set(stateTimeout, 2*time.Second) } containerd 内部维护一个全局插件列表: // plugin/plugin.go var register = struct { sync.RWMutex r []*Registration }{} 对外提供三种方法: Load : 通过路径加载插件 Register : 注册插件 Graph : 遍历插件列表 注册的插件在 containerd 服务启动时初始化: // services/server/server.go // New creates and initializes a new containerd server func New(ctx context.Context, config *srvconfig.Config) (*Server, error) { ... for _, p := range plugins { id := p.URI() reqID := id if config.GetVersion() == 1 { reqID = p.ID } log.G(ctx).WithField(\"type\", p.Type).Infof(\"loading plugin %q...\", id) // 新建插件上下文结构体 initContext := plugin.NewContext( ctx, p, initialized, config.Root, config.State, ) initContext.Events = s.events initContext.Address = config.GRPC.Address initContext.TTRPCAddress = config.TTRPC.Address // 加载配置参数 if p.Config != nil { pc, err := config.Decode(p) if err != nil { return nil, err } initContext.Config = pc } // 插件初始化 result := p.Init(initContext) if err := initialized.Add(result); err != nil { return nil, errors.Wrapf(err, \"could not add plugin result to plugin set\") } // 获取插件实例 instance, err := result.Instance() if err != nil { if plugin.IsSkipPlugin(err) { log.G(ctx).WithError(err).WithField(\"type\", p.Type).Infof(\"skip loading plugin %q...\", id) } else { log.G(ctx).WithError(err).Warnf(\"failed to load plugin %s\", id) } if _, ok := required[reqID]; ok { return nil, errors.Wrapf(err, \"load required plugin %s\", id) } continue } delete(required, reqID) // 根据插件类型，加载成不同的服务 if src, ok := instance.(plugin.Service); ok { grpcServices = append(grpcServices, src) } if src, ok := instance.(plugin.TTRPCService); ok { ttrpcServices = append(ttrpcServices, src) } if service, ok := instance.(plugin.TCPService); ok { tcpServices = append(tcpServices, service) } s.plugins = append(s.plugins, result) } ... return s, nil } 插件初始化函数需要 InitContext。 // InitContext is used for plugin inititalization type InitContext struct { Context context.Context Root string State string Config interface{} Address string TTRPCAddress string Events *exchange.Exchange Meta *Meta // plugins can fill in metadata at init. plugins *Set } InitContext 中携带的 plugins 变量指向全局插件集合。结构体中保存插件初始化所需的参数，包括 Root : containerd 项目的根目录，从配置文件中获取。（默认为 /var/lib/containerd） State : containerd 运行过程中数据的存放目录，从配置文件中获取，(默认为 /run/containerd) Config : 配置文件 Address : gRPC 地址 TTRPCAddress: ttrpc 地址 Events: 全局的订阅发布模型 // plugin/context.go // Plugin represents an initialized plugin, used with an init context. type Plugin struct { Registration *Registration // registration, as initialized Config interface{} // config, as initialized Meta *Meta instance interface{} err error // will be set if there was an error initializing the plugin } 每个服务使用 Plugin 封装，插件的信息保存到 Registration 中: // plugin/plugin.go // Registration contains information for registering a plugin type Registration struct { // Type of the plugin Type Type // ID of the plugin ID string // Config specific to the plugin Config interface{} // Requires is a list of plugins that the registered plugin requires to be available Requires []Type // InitFn is called when initializing a plugin. The registration and // context are passed in. The init function may modify the registration to // add exports, capabilities and platform support declarations. InitFn func(*InitContext) (interface{}, error) // Disable the plugin from loading Disable bool } Registration 包含插件类型，插件ID，配置参数，依赖的其他插件类型，初始化函数。 ","date":"2021-12-03","objectID":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:6:0","tags":null,"title":"Containerd源码分析","uri":"/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":null,"content":"Dblink 查询所有触发器 select*fromuser_triggers; 根据名称禁用触发器 altertriggerLOGMNRGGC_TRIGGERdisable; 查询所有 job select*fromuser_jobs; 根据 id 禁用 job BEGINdbms_job.broken(4001,true);END; 禁用 oracle dblink altersystemsetopen_links=0sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=0sid='$sid'scope=spfile; 启用 oracle dblink altersystemsetopen_links=4sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=4sid='$sid'scope=spfile; ","date":"2021-12-03","objectID":"/dblink/:0:0","tags":null,"title":"Dblink","uri":"/dblink/"},{"categories":null,"content":"Docker容器和网络架构设计 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:0:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"常用的容器化技术 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Chroot 特点: 改变正在运行的进程和它的子进程根目录。 经chroot设置根目录的程序，不能够对这个指定根目录之外的文件进行访问和读取，也不能写操作。 原理: 修改PCB实现限制功能 (PCB: process control block) 缺点: 隔离文件系统 但是无法限制 CPU, 内存, 网络端口号的命名空间 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:1","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Jails 特点： 基于Chroot的操作系统层虚拟化技术。 只能访问某个部分的文件系统，但是FreeBSD jail机制限制了在软件监狱中运作的行程，不能够影响操作系统的其他部分 场景： 虚拟化 安全性 易维护 缺点: 使用复杂 隔离级别较弱 出现沙盒概念 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:2","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Linux vserver / openVZ 特点: 类似Jails机制，可以对计算机系统上的资源（文件系统、网络地址、内存）进行分区 Linux操作系统级虚拟化技术，它通过Linux内核补丁形式进行虚拟化、隔离、资源管理和状态检查 优点: 资源隔离性(CPU超卖，内存共享) 缺点: 隔离级别较弱 进一步强化沙盒概念。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:3","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"LXC 特点: linux 自带功能，几乎没有额外的性能损耗。 轻量级的 “虚拟化 “方法，同时运行多个虚拟单元。 容器是用内核控制组（cgroups）和内核命名空间来隔离的。 优势 通过容器隔离应用程序和操作系统 通过LXC实时管理资源的分配，提供近乎原生的性能。 通过cgroups控制网络接口和应用容器内的资源。 缺陷 所有LXC容器都使用相同的内核。 只能在Linux操作系统运行。 LXC 并不安全，安全性取决于主机系统。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:4","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"cgroup 和 namespace Cgroups: 用于限制和隔离一组进程对系统资源的使用 对不同资源的具体管理是由各个子系统分工完成的 Namespace: 内核全局资源的封装 每个namespace是一份独立的资源 不同进程在各自namespace中对同一种资源的使用互不干扰 常用的namespace有IPC、Network、Mount、PID、User和UTC  ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:1:5","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"docker 的架构和原理 容器技术的目标 提高系统资源利用率 提高进程运行稳定性 docker 之前的解决方案: 虚拟化解决方案 软件虚拟化 硬件虚拟化 虚拟化方案提高了进程稳定性，一定程度提高了资源利用率。但仍然有很大程度的资源浪费(虚拟化成本) 容器化解决方案:在操作系统层面实现资源隔离 OpenVZ LXC Process Container(cgroups) 均衡了资源利用率和稳定性。 稳定性比虚拟化差，但资源利用率比虚拟化高，适合分布式环境。 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:2:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"Docker 网络架构和原理 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:0","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"网络基础知识 Lan/VLan/VXLan: LAN (Local Area Network)本地局域网 VLAN(Virtual Local Area Network)虚拟本地局域网 VXLAN(Virtual eXtensible Local Area Network) 在一套物理网络设备上虚拟出多个二层网络 VXLAN: VLAN ID数量限制 交换机MAC地址表限制 灵活的虚机部署和部署 复用网络链路 桥接: 从一个网卡设备发出的以太帧，原封不动地到达另外一个网卡设备。 将多个广播域组合成一个广播域，在链路层允许设备互联。 桥接与路由的区别: 分割广播域 桥接无法控制广播在不同物理接口之间的穿梭。广播嘈杂，对主机的干扰程度严重。 路由可以将某些主机放在一个广播域，将另外一些主机放在另外的广播域。 控制网络流量 不同协议类型的物理接口，只能使用路由。 二层封装方式不一样，桥接无法解析数据。路由器可以替换二层数据帧 ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:1","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"docker 跨主机互访方案 Bridge Host Overlay Flannel ","date":"2021-12-03","objectID":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/:3:2","tags":null,"title":"Docker容器和网络架构设计","uri":"/docker%E5%AE%B9%E5%99%A8%E5%92%8C%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"categories":null,"content":"etcd的使用实例 etcd 有如下的使用场景： 服务发现（Service Discovery） 消息发布与订阅 负载均衡 分布式通知与协调 分布式锁 分布式队列 集群监控于Leader竞选。 一、服务发现 etcd 的常见使用场景之一就是服务发现。实现思路如下：先准备 etcd 服务端，服务端的程序在第一次启动之后会连接到 etcd 服务器并设置一个格式为 ip:port 的键值对，并绑定一个 lease。之后的服务端内部维护一个定时器，每隔一段时间就更新服务端注册中心的 lease 的 TTL。另外一个组件就是服务发现组件，discovery 会 watch 服务端的 key。每次该 key 变化时，discovery 就可以检测到时间并做出对应的操作。代码的实现如下： // server.go package main import ( \"context\" \"crypto/md5\" \"encoding/json\" \"errors\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client stopSignal = make(chan struct{}, 1) srvKey string ) var ( serv = flag.String(\"name\", \"hello\", \"service name\") port = flag.Int(\"port\", 30000, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func Register(endpoints string, config *SvConfig, interval time.Duration, ttl int) error { // 解析服务端的值 srvValue, _ := json.Marshal(config) srvKey = fmt.Sprintf(\"%s/%x\", prefix, md5.Sum(srvValue)) var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(endpoints, \",\"), DialTimeout: time.Second * 2, }) if err != nil { return fmt.Errorf(\"register service failed: %v\", err) } go func() { timer := time.NewTicker(interval) for { resp, _ := client.Grant(context.TODO(), int64(ttl)) _, err = client.Get(context.TODO(), srvKey) if err != nil { // 捕获 key 不存在的场合 if errors.Is(err, rpctypes.ErrKeyNotFound) { _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) if err != nil { log.Printf(\"register service %s at %s:%d\\n\", config.Name, config.Host, config.Port) } } } else { // 如果key存在就更新ttl _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) } select { case \u003c-stopSignal: return case \u003c-timer.C: } } }() return err } func Unregister() error { stopSignal \u003c- struct{}{} stopSignal = make(chan struct{}, 1) _, err := client.Delete(context.TODO(), srvKey) return err } func main() { flag.Parse() // 绑定服务地址和端口 lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", *port)) if err != nil { panic(err) } config := \u0026SvConfig{ Name: *serv, Host: \"127.0.0.1\", Port: *port, } Register(*endpoint, config, time.Second*10, 15) ch := make(chan os.Signal, 1) signal.Notify(ch, syscall.SIGTERM, syscall.SIGINT, syscall.SIGKILL, syscall.SIGHUP, syscall.SIGQUIT) go func() { \u003c-ch Unregister() os.Exit(1) }() log.Printf(\"service %s start at %d\", *serv, *port) // server todo for { lis.Accept() } } // discovery.go package main import ( \"context\" \"encoding/json\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client ) var ( port = flag.Int(\"port\", 30001, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func watcher() error { var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(*endpoint, \",\"), DialTimeout: time.Second * 3, }) if err != nil { return fmt.Errorf(\"connect etcd cluster failed: %v\", err.Error()) } go func() { resp := client.Watch(context.TODO(), prefix, clientv3.WithPrefix()) for ch := range resp { for _, event := range ch.Events { switch event.Type { case clientv3.EventTypePut: if event.IsCreate() { srv := parseSrv(event.Kv.Value) log.Printf(\"discovery service %s at %s:%d\", srv.Name, srv.Host, srv.Port) } case clientv3.EventTypeDelete: log.Printf(\"delete service %s\", event.Kv.Key) } } } }() return err } func parseSrv(text []byte) *SvConfig { svc := \u0026SvConfig{} json.Unmarshal(text, \u0026svc) return svc } func main() { flag.Parse() // 绑定服务地址和端口 lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", *port)) if err != nil { panic(err) } ch := ma","date":"2021-12-03","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:0:0","tags":null,"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":null,"content":"Flask与Vue的token认证 后端使用flask设计基于token认证方式的restful接口，前端使用vue.js全家桶，利用axios通讯。 感谢两篇文章的作者： http://www.cnblogs.com/vovlie/p/4182814.html https://segmentfault.com/a/1190000008383094?_ea=1639495 源码链接：https://github.com/xingyys/flaskvue 后端Flask Flask采用token认证方式，主要思路是通过/api/login登录获取token，然后使用token调用各个接口。 所用到框架的库： flask flask-cors：flask跨域 flask-sqlachemy: flask数据库orm flask-httpauth：flask的auth认证 passlib: python密码解析库 itsdangerous ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:0:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"后端结构图 flask/ ├── app # 主目录 │ ├── __init__.py │ ├── __init__.pyc │ ├── models.py # 数据库 │ ├── models.pyc │ ├── views.py # 视图 │ └── views.pyc ├── config.py # 配置信息 ├── config.pyc ├── db_create.py # 创建数据库 ├── db_migrate.py # 更新数据库 ├── db_repository │ ├── __init__.py │ ├── __init__.pyc │ ├── manage.py │ ├── migrate.cfg │ ├── README │ └── versions │ ├── 008_migration.py │ ├── 008_migration.pyc │ ├── 009_migration.py │ ├── 009_migration.pyc │ ├── __init__.py │ └── __init__.pyc ├── index.html └── run.py # app的运行文件 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:1:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"具体实现 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"系统初始化app/__init__.py # -*- coding:utf-8 -*- from flask import Flask from flask_sqlalchemy import SQLAlchemy from flask_httpauth import HTTPBasicAuth from flask_cors import CORS app = Flask(__name__) # flask的跨域解决 CORS(app) app.config.from_object('config') db = SQLAlchemy(app) auth = HTTPBasicAuth() from . import models, views ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:1","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"配置文件config.py import os basedir = os.path.abspath(os.path.dirname(__file__)) SQLALCHEMY_DATABASE_URI = \"mysql://root:123456@127.0.0.1/rest\" SQLALCHEMY_MIGRATE_REPO = os.path.join(basedir, 'db_repository') SQLALCHEMY_TRACK_MODIFICATIONS = True BASEDIR = basedir # 安全配置 CSRF_ENABLED = True SECRET_KEY = 'jklklsadhfjkhwbii9/sdf\\sdf' 环境中使用mysql数据库，版本为mariadb 10.1.22。创建rest表 $ mysql -uroot -p xxxxxx $ create database rest default charset utf8; ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:2","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"创建数据库表app/models.py # -*- coding:utf-8 -*- from app import db, app from passlib.apps import custom_app_context from itsdangerous import TimedJSONWebSignatureSerializer as Serializer, SignatureExpired, BadSignature class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(32), index=True) password = db.Column(db.String(128)) # 密码加密 def hash_password(self, password): self.password = custom_app_context.encrypt(password) # 密码解析 def verify_password(self, password): return custom_app_context.verify(password, self.password) # 获取token，有效时间10min def generate_auth_token(self, expiration = 600): s = Serializer(app.config['SECRET_KEY'], expires_in = expiration) return s.dumps({ 'id': self.id }) # 解析token，确认登录的用户身份 @staticmethod def verify_auth_token(token): s = Serializer(app.config['SECRET_KEY']) try: data = s.loads(token) except SignatureExpired: return None # valid token, but expired except BadSignature: return None # invalid token user = User.query.get(data['id']) return user 创建数据库users表： $ python db_create.py $ python db_migrate.py ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:3","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"视图app/views.py from app import app, db, auth from flask import render_template, json, jsonify, request, abort, g from app.models import * @app.route(\"/\") @auth.login_required def index(): return jsonify('Hello, %s' % g.user.username) @app.route('/api/users', methods = ['POST']) def new_user(): username = request.json.get('username') password = request.json.get('password') if username is None or password is None: abort(400) # missing arguments if User.query.filter_by(username = username).first() is not None: abort(400) # existing user user = User(username = username) user.hash_password(password) db.session.add(user) db.session.commit() return jsonify({ 'username': user.username }) @auth.verify_password def verify_password(username_or_token, password): if request.path == \"/api/login\": user = User.query.filter_by(username=username_or_token).first() if not user or not user.verify_password(password): return False else: user = User.verify_auth_token(username_or_token) if not user: return False g.user = user return True @app.route('/api/login') @auth.login_required def get_auth_token(): token = g.user.generate_auth_token() return jsonify(token) 用户注册后密码加密存储，确认用户身份时密码解密。需要认证的api上添加@auth.login_required，它会在调用接口之前调用@auth.verify_password下的方法(此方法唯一)如verify_password。根据请求的路径选择不同的认证方式。 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:4","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"测试 使用curl命令测试接口 注册用户: $ curl -i -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"123456\"}' http://127.0.0.1:5000/api/register HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 26 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:33:46 GMT { \"username\": \"admin\" } 查看数据库： MariaDB [rest]\u003e select * from users\\G; *************************** 1. row *************************** id: 1 username: admin password: $6$rounds=656000$etV4F3xLL0dwflX8$mLFX9l5dumBnQFtajGmey346viGuQ4bxR7YhQdKtB/nQH9ij2e3HHMEBPj.ef/o//4o9P2Wd3Y7dxQfjwR2hY/ 1 row in set (0.00 sec) 获取token： curl -i -u admin:123456 -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/api/login HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 125 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:37:01 GMT \"eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ\" 使用token调用api： $ curl -i -u eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ:unused -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/ HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 15 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:38:22 GMT \"Hello, admin\" 基于token的Flask api成功！！！！ 前端Vue.js 前端使用vue的全家桶，axios前后端通讯，axios拦截器，localStorage保存token 所使用的框架和库： vue2.0 iview2.X axios vuex vue-router ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:5","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"具体实现 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:0","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"main.js // 初始化axios axios.defaults.baseURL = 'http://127.0.0.1:5000' axios.defaults.auth = { username: '', password: '', } // axios.interceptors.request.use((config) =\u003e { // console.log(config) // return config; // }, (error) =\u003e { // return Promise.reject(error) // }) // axios拦截器，401状态时跳转登录页并清除token axios.interceptors.response.use((response) =\u003e { return response; }, (error) =\u003e { if (error.response) { switch (error.response.status) { case 401: store.commit('del_token') router.push('/login') } } return Promise.reject(error.response.data) }) // 路由跳转 router.beforeEach((to, from, next) =\u003e { if (to.meta.required) { // 检查localStorage if (localStorage.token) { store.commit('set_token', localStorage.token) // 添加axios头部Authorized axios.defaults.auth = { username: store.state.token, password: store.state.token, } // iview的页面加载条 iView.LoadingBar.start(); next() } else { next({ path: '/login', }) } } else { iView.LoadingBar.start(); next() } }) router.afterEach((to, from, next) =\u003e { iView.LoadingBar.finish(); }) ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:1","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"路由 export default new Router({ routes: [{ path: '/', name: 'index', component: Index, meta: { required: true, } }, { path: '/login', name: 'login', component: Login, }] }) 路由添加meta字段，作为需要认证路由的标志 ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:2","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"vuex export default new Vuex.Store({ state: { token: '' }, mutations: { set_token(state, token) { state.token = token localStorage.token = token }, del_token(state) { state.token = '' localStorage.removeItem('token') } } }) vuex中保存token，同时修改删除token和localStorage.token ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:3","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"登录和登出 登录： handleSubmit(name, form) { this.$refs[name].validate((valid) =\u003e { if (valid) { // 用户名密码简单验证后添加到axios的auth中 this.$axios.defaults.auth = { username: form.username, password: form.password, } this.$axios.get('/api/login').then(response =\u003e { this.$Message.success(\"提交成功\") let data = response.data // 保存token this.$store.commit('set_token', data) this.$router.push('/') }).catch(error =\u003e { this.$Message.error(error.status) }) } else { this.$Message.error('表单验证失败!'); } }) } 登出： logout() { this.$store.commit('del_token') this.$router.push('/login') } 删除token并跳转到登录页 flask和vue的token认证就完成了！！！！ ","date":"2021-12-03","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:4","tags":null,"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":null,"content":"Go 结合 etcd 关于 etcd 的安装和介绍看 这里 。官方的实例可以看 这里 一、连接 首先是关于 golang 如何连接 etcd ，先是简单的连接。 package main import ( \"github.com/coreos/etcd/clientv3\" \"log\" \"time\" ) func connect() { cli, err := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 还有带 https 和 开启用户验证的连接 func connectTlsAuth() { tlsInfo := transport.TLSInfo{ CertFile: \"/tmp/cert.pem\", KeyFile: \"/tmp/key.pem\", TrustedCAFile: \"/tmp/ca.pem\", } tlsConfig, err := tlsInfo.ClientConfig() if err != nil { log.Fatal(\"parse tls config file: \" + err.Error()) } cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, DialTimeout: time.Second * 3, TLS: tlsConfig, Username: \"root\", Password: \"root\", }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 二、KV 操作 ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:0:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.1 简单的 curd 在连接基础上，接下来就可以对key做操作了。对key做 curd func kv() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl put foo 1 _, err := cli.Put(ctx, \"foo\", \"1\") if err != nil { log.Fatal(\"put key:\" + err.Error()) } // etcdctl get foo --prefix // 带参数的请求 resp, err := cli.Get(ctx, \"foo\", clientv3.WithPrefix()) if err != nil { log.Fatal(\"get key: \" + err.Error()) } for _, v := range resp.Kvs { log.Printf(\"get %s =\u003e %s\\n\", v.Key, string(v.Value)) } kvcli := clientv3.NewKV(cli) // etcdctl del foo _, err = kvcli.Delete(ctx, \"foo\") if err != nil { log.Fatal(\"delete key: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:1:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.2 事务 使用事务如下： func txn() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() kvc := clientv3.NewKV(cli) _, err := kvc.Put(ctx, \"foo\", \"xyz\") if err != nil { log.Fatal(\"put key: \" + err.Error()) } _, err = kvc.Txn(ctx). // txn value comparisons are lexical If(clientv3.Compare(clientv3.Value(\"foo\"), \"\u003e\", \"abc\")). // the \"Then\" runs, since \"xyz\" \u003e \"abc\" Then(clientv3.OpPut(\"foo\", \"XYZ\")). // the \"Else\" does not run Else(clientv3.OpPut(\"foo\", \"ABC\")). Commit() if err != nil { log.Fatal(\"run txn: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:2:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 批量操作 批量指定操作 func do() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() ops := []clientv3.Op{ clientv3.OpPut(\"key1\", \"123\"), clientv3.OpGet(\"key1\"), clientv3.OpPut(\"key2\", \"456\"), } for _, op := range ops { if _, err := cli.Do(ctx, op); err != nil { log.Fatal(err.Error()) } } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:3:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 watch 监视key func watch() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() go func() { timer := time.NewTicker(time.Second) for { select { case \u003c-timer.C: // change foo value every second _, _ = cli.Put(context.TODO(), \"foo\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo1\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo2\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo3\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo4\", time.Now().String()) } } }() //rch := cli.Watch(ctx, \"foo\") rch := cli.Watch(ctx, \"foo\", clientv3.WithPrefix()) //rch := cli.Watch(ctx, \"foo\", clientv3.WithRange(\"foo4\")) for wresp := range rch { for _, ev := range wresp.Events { fmt.Printf(\"%s %q: %q\\n\", ev.Type, ev.Kv.Key, ev.Kv.Value) } } } func watchWithProcessNotify() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() rch := cli.Watch(ctx, \"foo\", clientv3.WithProgressNotify()) wresp := \u003c- rch fmt.Printf(\"wresp.Header.Revision: %d\\n\", wresp.Header.Revision) fmt.Println(\"wresp.IsProgressNotify:\", wresp.IsProgressNotify()) } 三、lease ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:4:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.1 创建 lease func grant() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl lease grant 5 // grant lease 5s resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } // after 5 seconds, the key 'foo' will be removed _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(\"put key with lease: \" + err.Error()) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:5:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.2 删除 lease func revoke() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } // revoking lease expires the key attached to its lease ID _, err = cli.Revoke(ctx, resp.ID) if err != nil { log.Fatal(err) } } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:6:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.3 续租 func keepAlive() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } ch, err := cli.KeepAlive(ctx, resp.ID) if err != nil { log.Fatal(err.Error()) } ka := \u003c- ch fmt.Println(\"ttl:\", ka.TTL) // 官方提示：多数情况下使用 KeepAlive 来代替 KeepAliveOnce kaa, err := cli.KeepAliveOnce(ctx, resp.ID) if err != nil { log.Fatal(err) } fmt.Println(\"ttl:\", kaa.TTL) } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:7:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"2.4 查询 lease func leases() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() _, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 10) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 15) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } resp, err := cli.Lease.Leases(ctx) if err != nil { log.Fatal(err) } for _, lease := range resp.Leases { ttl, err := cli.Lease.TimeToLive(ctx, lease.ID, clientv3.WithAttachedKeys()) if err == nil { fmt.Printf(\"lease: %d, ttl: %d, grantedTTL: %d\\n\", ttl.ID, ttl.TTL, ttl.GrantedTTL) } } } 四、访问控制 func auth() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() auth := clientv3.NewAuth(cli) // create role if _, err := auth.RoleAdd(ctx, \"root\"); err != nil { log.Fatal(err) } // create role if _, err := auth.UserAdd(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } // grant role root to user root if _, err := auth.UserGrantRole(ctx, \"root\", \"root\"); err != nil { log.Fatal(err) } if _, err := auth.UserChangePassword(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } if _, err := auth.RoleAdd(ctx, \"guest\"); err != nil { log.Fatal(err) } if _, err := auth.UserAdd(ctx, \"xingyys\", \"\"); err != nil { log.Fatal(err) } if _, err := auth.UserGrantRole(ctx, \"xingyys\", \"guest\"); err != nil { log.Fatal(err) } // 不知道为什么，需要在grant后更新密码 // 否则密码无效 if _, err := auth.UserChangePassword(ctx, \"xingyys\", \"123\"); err != nil { log.Fatal(err) } // 添加指定key的访问权限 // read, write, readwrite if _, err := auth.RoleGrantPermission(ctx, \"guest\", \"foo\", \"zoo\", clientv3.PermissionType(clientv3.PermReadWrite)); err != nil { log.Fatal(err) } if _, err := auth.AuthEnable(ctx); err != nil { log.Fatal(err) } authCli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, Username: \"xingyys\", Password: \"123\", }) defer authCli.Close() _, _ = authCli.Put(ctx, \"foo\", \"1\") resp, _ := authCli.Get(ctx, \"foo\") for _, v := range resp.Kvs { log.Printf(\"%s =\u003e %q\\n\", v.Key, v.Value) } _, err := authCli.Txn(ctx). If(clientv3.Compare(clientv3.Value(\"zoo1\"), \"\u003e\", \"abc\")). Then(clientv3.OpPut(\"zoo1\", \"XYZ\")). Else(clientv3.OpPut(\"zoo1\", \"ABC\")). Commit() log.Println(err) } 五、集群 func member() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() cluster := clientv3.NewCluster(cli) resp, err := cluster.MemberList(ctx) if err != nil { log.Fatal(err) } for _, member := range resp.Members { fmt.Printf(\"ID: %d | Name: %s | ClientURL: %q | PeerURL: %q\\n\", member.ID, member.Name, member.ClientURLs, member.PeerURLs) } //_, _ = cluster.MemberAdd(ctx, []string{\"192.168.10.10:2370\", \"192.168.10.11:2379\"}) //_, _ = cluster.MemberRemove(ctx, // id) //_, _ = cluster.MemberUpdate(ctx, // id, // peer) } 六、并发 ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:8:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.1 锁 func lock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquired lock for s1 if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") m2Locked := make(chan struct{}) go func() { defer close(m2Locked) // wait util s1 is locks /lock if err := m2.Lock(context.TODO()); err != nil { log.Fatal(err) } }() if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"release lock for s1\") \u003c-m2Locked fmt.Println(\"acquired lock for s2\") } func tryLock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquire lock for s1 if err = m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") if err = m2.TryLock(context.TODO()); err == nil { log.Fatal(\"should not acquire lock\") } if err == concurrency.ErrLocked { fmt.Println(\"cannot acquire lock for s2, as already locked in another session\") } if err = m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"released lock for s1\") if err = m2.TryLock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s2\") } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:9:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.2 领导选举 func election() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // create two separate sessions for election competition s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() e1 := concurrency.NewElection(s1, \"/my-election/\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() e2 := concurrency.NewElection(s2, \"/my-election/\") // create competing candidates, with e1 initially losing to e2 var wg sync.WaitGroup wg.Add(2) electc := make(chan *concurrency.Election, 2) go func() { defer wg.Done() // delay candidacy so e2 wins first time.Sleep(3 * time.Second) if err := e1.Campaign(context.Background(), \"e1\"); err != nil { log.Fatal(err) } electc \u003c- e1 }() go func() { defer wg.Done() if err := e2.Campaign(context.Background(), \"e2\"); err != nil { log.Fatal(err) } electc \u003c- e2 }() cctx, cancel := context.WithCancel(context.TODO()) defer cancel() e := \u003c-electc fmt.Println(\"completed first election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) // resign so next candidate can be elected if err := e.Resign(context.TODO()); err != nil { log.Fatal(err) } e = \u003c-electc fmt.Println(\"completed second election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) wg.Wait() } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:10:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"6.3 软件事务内存 func stm() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // set up \"accounts\" totalAccounts := 5 for i := 0; i \u003c totalAccounts; i++ { k := fmt.Sprintf(\"accts/%d\", i) if _, err = cli.Put(context.TODO(), k, \"100\"); err != nil { log.Fatal(err) } } exchange := func(stm concurrency.STM) error { from, to := rand.Intn(totalAccounts), rand.Intn(totalAccounts) if from == to { // nothing to do return nil } // read values fromK, toK := fmt.Sprintf(\"accts/%d\", from), fmt.Sprintf(\"accts/%d\", to) fromV, toV := stm.Get(fromK), stm.Get(toK) fromInt, toInt := 0, 0 fmt.Sscanf(fromV, \"%d\", \u0026fromInt) fmt.Sscanf(toV, \"%d\", \u0026toInt) // transfer amount xfer := fromInt / 2 fromInt, toInt = fromInt-xfer, toInt+xfer // write back stm.Put(fromK, fmt.Sprintf(\"%d\", fromInt)) stm.Put(toK, fmt.Sprintf(\"%d\", toInt)) return nil } // concurrently exchange values between accounts var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() if _, serr := concurrency.NewSTM(cli, exchange); serr != nil { log.Fatal(serr) } }() } wg.Wait() // confirm account sum matches sum from beginning. sum := 0 accts, err := cli.Get(context.TODO(), \"accts/\", clientv3.WithPrefix()) if err != nil { log.Fatal(err) } for _, kv := range accts.Kvs { v := 0 fmt.Sscanf(string(kv.Value), \"%d\", \u0026v) sum += v } fmt.Println(\"account sum is\", sum) } ","date":"2021-12-03","objectID":"/go%E7%BB%93%E5%90%88etcd/:11:0","tags":null,"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":null,"content":"Golang使用json格式实现增删查改 需求和思路 在一般的小项目或者一个小软件,例如客户端之类的小程序中,可能会需要数据的持久化.但是使用一般的数据库(Mysql)之类的不合适.使用sqlite3这种嵌入式的是个较好的方法,但是Go语言中sqlite3的库是C语言的,Cgo不支持跨平台编译.正是由于这种需求,才想到使用json格式将数据直接保存在文件中. 具体的思路是怎么样呢? 在Go语言中如果要将数据转化成json格式的话,有两种格式 struct 和 map. 如果同时需要增删查改功能的话,将map作为中间格式是比较合适的.接下来我们就来实现它. 查询操作 这种操作的实现比较简单,直接将文件中的数据读取出来,使用json库反序列化就可以了. 代码如下 : type Product struct { Name string `json:\"name\"` Num int `json:\"num\"` } func findAll() { ps := make([]Product, 0) data, err := ioutil.ReadFile(\"./index.json\") if err != nil { log.Fatal(err) } // 这里参数要指定为变量的地址 err = json.Unmarshal(data, \u0026ps) if err != nil { log.Fatal(err) } fmt.Println(ps) } 添加操作 添加的实现实在查询的基础上的,我们需要先查询文件中的数据库,并转化为map格式,再将struct也转化为map格式(这里要使用反射),合并map,json序列化,最后保存在文件中.代码如下: func create() { fields := make([]map[string]interface{}, 0) p1 := \u0026Product{ Name: \"Blog\", Num: 2, } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 data, _ := ioutil.ReadFile(\"./index.json\") err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") field[key] = field2.Interface() } // 合并map fields = append(fields, field) // 写入文件 out, _ := json.Marshal(fields) _ = ioutil.WriteFile(\"./index.json\", out, 0755) } 条件查询 思路: 将struct转化为map,根据输入的条件查询.查询的结果转化为struct.代码如下: func FindOne() { product := \u0026Product{} p1 := \u0026Product{ Name: \"John\", Num: 23, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field[key] = float64(field2.Interface().(uint)) case reflect.Uint8: field[key] = float64(field2.Interface().(uint8)) case reflect.Uint16: field[key] = float64(field2.Interface().(uint16)) case reflect.Uint32: field[key] = float64(field2.Interface().(uint32)) case reflect.Uint64: field[key] = float64(field2.Interface().(uint64)) case reflect.Float32: field[key] = float64(field2.Interface().(float32)) case reflect.Float64: field[key] = field2.Interface() default: field[key] = field2.Interface() } } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 // 数据转化为map时,数值类型的统一变成float64 data, _ := ioutil.ReadFile(\"./index.json\") fields := make([]map[string]interface{}, 0) err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 查询的条件 columns := []string{\"name\", \"num\"} length := len(columns) for _, item := range fields { for i := 0; i \u003c length; i++ { // 这里的比较需要改进 if item[columns[i]] != field[columns[i]] { break } if i == length-1 { field = item goto OVER } } } OVER: fmt.Println(field) out, _ := json.Marshal(field) _ = json.Unmarshal(out, \u0026product) fmt.Println(product) } 修改操作 修改操作在查询操作的基础上实现, 修改操作需要有一个id值,能确定元素的唯一性.代码如下: func Update() { p1 := \u0026Product{ Id: \"2bbec87025968879c3c9682abe3bf730\", Name: \"John_e\", Num: 100, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field","date":"2021-12-03","objectID":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/:0:0","tags":null,"title":"Golang使用json格式实现增删查改","uri":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/"},{"categories":null,"content":"golang打包和解包 打包 // 打包 func Compress(destPath, srcDir string) error { // 压缩文件路径 fw, err := os.Create(destPath) if err != nil { return err } defer fw.Close() // gzip writer gw := gzip.NewWriter(fw) defer gw.Close() // tar writer tw := tar.NewWriter(gw) defer tw.Close() // 读取要压缩的目录 dir, err := os.Open(srcDir) if err != nil { return err } defer dir.Close() // 读取目录内容 files, err := dir.Readdir(0) if err != nil { return err } for _, file := range files { if file.IsDir() { continue } // 路径补全 filePath := path.Join(dir.Name(), file.Name()) fread, err := os.Open(filePath) if err != nil { continue } // 获取文件头部信息 h := \u0026tar.Header{} h.Name = file.Name() h.Size = file.Size() h.Mode = int64(file.Mode()) h.ModTime = file.ModTime() err = tw.WriteHeader(h) if err == nil { // 开始压缩，这里等于忽略错误 io.Copy(tw, fread) } // 记得关闭文件 fread.Close() } return nil } 解包 // 解压 func DeCompress(srcPath, destDir string) error { // 解压包的路径 fread, err := os.Open(srcPath) if err != nil { return err } defer fread.Close() // 检测目标路径是否存在 _, err = os.Stat(destDir) if err != nil { return err } // gzip reader gr, err := gzip.NewReader(fread) if err != nil { return err } defer gr.Close() // tr reader tr := tar.NewReader(gr) for { // 获取下一个文件 h, err := tr.Next() // 读取完毕 if err == io.EOF { break } if err != nil { continue } fw, err := os.OpenFile(path.Join(destDir, h.Name), os.O_CREATE|os.O_WRONLY, 0644) if err == nil { io.Copy(fw, tr) fw.Close() } } return nil } ","date":"2021-12-03","objectID":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/:0:0","tags":null,"title":"golang打包和解包","uri":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/"},{"categories":null,"content":"Golang监控进程流量 链接 libpcap ","date":"2021-12-03","objectID":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/:0:0","tags":null,"title":"Golang监控进程流量","uri":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/"},{"categories":null,"content":"Golang跨平台编译 golang cgo 到 Windows 的交叉编译 本篇记录在 MaxOS 下 cgo 交叉编译的解决方案。因为在项目中使用 go-sqlite3 ，编译 go-sqlite3 中需要使用到 cgo。在 MacOS 下编译 Go 原生 Linux 和 Windows 的程序使用以下命令： # 交叉编译到 linux GOOS=linux GOARCH=amd64 go build main.go # 交叉编译到 windows GOOS=windows GOARCH=amd64 go build -o main.exe main.go 如果使用 cgo 的话，还需要添加 CGO_ENABLED 参数： CGO_ENABLED=1 GOOS=windows GOARCH=amd64 go build -o main.exe main.go 但是这种编译 go-sqlite3 的代码会出现以下错误： # runtime/cgo gcc_libinit_windows.c:7:10: fatal error: 'windows.h' file not found 因为 Windows 中使用 MinGW，MacOS 下如果交叉编译需要安装 C/C++ 交叉编译工具： brew install FiloSottile/musl-cross/musl-cross brew install mingw-w64 安装完工具之后就可以使用命令： CGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build -a -v -o store.exe store/sqlite.exe 注意参数： CXX=x86_64-w64-mingw32-g++ ，如果缺少这个参数时，可能会出现错误： # runtime/cgo gcc: error: unrecognized command line option ‘-mthreads’; did you mean ‘-pthread’? ","date":"2021-12-03","objectID":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/:0:0","tags":null,"title":"Golang跨平台编译","uri":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/"},{"categories":null,"content":"GPRC 实战 GRPC 简介 grpc 是由 google 开发的一款开源，高性能 rpc（远程进程调用协议）使用 Protocol Buffers 作为数据交换格式。 GRPC 安装 golang 使用 grpc 要安装 grpc-go, protoc 和 对应的插件。 ","date":"2021-12-03","objectID":"/grpc1/:0:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"安装grpc-go go get -u github.com/golang/protobuf/{proto,protoc-gen-go} go get -u google.golang.org/grpc 如果是国内用户无法连接到 google.golang.org 的话可以使用 VPN。或者直接从 github.com 直接下载源代码再编译安装 git clone https://github.com/grpc/grpc-go.git $GOPATH/src/google.golang.org/grpc go get -u google.golang.org/grpc ","date":"2021-12-03","objectID":"/grpc1/:1:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"安装 protoc golang 要使用 grpc，还需要使用 protoc 工具。因为 golang 不能直接识别 .proto 文件，需要使用 protoc 工具将 .proto 转化成 golang 代码。下面介绍几个平台下安装 protobuf 的方法。 ","date":"2021-12-03","objectID":"/grpc1/:2:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"macos macos 下安装直接使用 brew 命令即可。 brew install protobuf ","date":"2021-12-03","objectID":"/grpc1/:2:1","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"linux linux 下需要先从 github.com 下载 protobuf 源码或者二进制文件，下载地址。二进制安装的话就下载 protobuf-all-*.tar.gz 包，解压后进入生成的目录。之后执行命令： make \u0026\u0026 make install ","date":"2021-12-03","objectID":"/grpc1/:2:2","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"windows 下载 protobuf.all-*.zip 包，解压后再配置环境变量，将 protobuf\\bin 配置到 $PATH 变量中。 GRPC使用 ","date":"2021-12-03","objectID":"/grpc1/:2:3","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"新建项目 新建一个 grpc 项目，如下: ../sample └── pb └── echo.proto echo.proto 的内容为: syntax = \"proto3\"; // protobuf 语法版本，默认为 proto2 // // 这个是注释 // .proto 所在的包路径 package sample.pb;option go_package = \"pb\";// EchoRequest grpc 请求报文格式. message EchoRequest { string message = 1;}// EchoResponse grpc 响应报文格式. message EchoResponse { string message = 1;}// 定义 Echo 服务. service Echo { // UnaryEcho 一元请求. rpc UnaryEcho(EchoRequest) returns (EchoResponse) {} // ServerStreamingEcho 服务端 stream 请求. rpc ServerStreamingEcho(EchoRequest) returns (stream EchoResponse) {} // ClientStreamingEcho 客户端 stream 请求. rpc ClientStreamingEcho(stream EchoRequest) returns (EchoResponse) {} // BidirectionalStreamingEcho 双向 stream. rpc BidirectionalStreamingEcho(stream EchoRequest) returns (stream EchoResponse) {}} 执行以下命令将 .proto 转化为 golang 代码: cd sample # protoc -I\u003cimport路径\u003e \u003c...-I$PATH\u003e --go_out=plugins=grpc:\u003c输出路径\u003e *.proto protoc -I. --go_out=plugins=grpc:. pb/echo.proto 简单描述下 protoc 命令的功能。 -I : *.proto 中导入的包的路径，导入的路径为全路径格式。. 表示当前路径。 –go_out=plugins=grpc: ：指定 _.proto 输出的格式和路径，生成 _.go 文件的路径为 和 *.proto 的拼接。执行成功后成为文件 echo.pb.go 文件: ../sample └── pb ├── echo.pb.go └── echo.proto ","date":"2021-12-03","objectID":"/grpc1/:3:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"Server package main import ( \"context\" \"errors\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" \"net\" ) type server struct { pb.EchoServer } // 简单请求 func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: \"echo: \" + request.Message}, nil } // 服务端流式 func (s *server) ServerStreamingEcho(request *pb.EchoRequest, stream pb.Echo_ServerStreamingEchoServer) error { _ = stream.Send(\u0026pb.EchoResponse{Message: \"hello\"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \" \"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \"client\"}) return nil } // 客户端流式 func (s *server) ClientStreamingEcho(stream pb.Echo_ClientStreamingEchoServer) error { for { recv, err := stream.Recv() // block 直到有数据输出 if errors.Is(err, io.EOF) { // 表示消息传输完毕 break } if err != nil { log.Printf(\"recv error: %v\", err) return err } // client 断开连接 log.Printf(\"recv data: %v\", recv.Message) } // SendAndClose 只存在于客户端 stream 请求 // 发送完关闭 stream return stream.SendAndClose(\u0026pb.EchoResponse{Message: \"bye\"}) } // 双向流式 func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 如果服务端 stream 方法退出，客户端请求也直接断开 for { recv, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv error: %v\", err) return err } if recv.Message == \"bye\" { log.Printf(\"client send done!\") break } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + recv.Message}); err != nil { log.Printf(\"send message error: %v\", err) return err } } return nil } func main() { addr := \"127.0.0.1:50001\" // grpc 为 http2 请求，传输层协议为 tcp lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"binding at %v: %v\", addr, err) } gRPCServer := grpc.NewServer() pb.RegisterEchoServer(gRPCServer, \u0026server{}) if err := gRPCServer.Serve(lis); err != nil { log.Fatalf(\"start grpc: %v\", err) } } ","date":"2021-12-03","objectID":"/grpc1/:4:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"Client package main import ( \"context\" \"errors\" \"fmt\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" ) // 简单请求 func unaryEcho(cli pb.EchoClient, msg string) { recv, err := cli.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"unaryEcho %v\", err) } log.Println(\"recv data =\u003e \" + recv.Message) } // 服务端流式 func serverStreamingEcho(cli pb.EchoClient, msg string) { stream, err := cli.ServerStreamingEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"serverStreamingEcho %v\", err) } ctx := stream.Context() for { select { case \u003c-ctx.Done(): log.Println(\"serverStreamingEcho done!\") break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err == nil { log.Println(\"serverStreaming reply =\u003e \", msg.Message) } } } // 客户端流式 func clientStreamingEcho(cli pb.EchoClient) { stream, err := cli.ClientStreamingEcho(context.Background()) if err != nil { log.Printf(\"connect client Streaming: %v\\n\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"hello\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \" \"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"world\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } if recv, err := stream.CloseAndRecv(); err == nil { fmt.Printf(\"recv data: %v\\n\", recv.Message) } } // 双向流式 func bidirectionalStreamingEcho(cli pb.EchoClient) { stream, err := cli.BidirectionalStreamingEcho(context.Background()) if err != nil { log.Printf(\"bidirectionalStreamingEcho error: %v\\n\", err) return } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 1\"}) recv, err := stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 2\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 3\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"bye\"}) stream.CloseSend() } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext(ctx, addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"connect %v: %v\", addr, err) } cli := pb.NewEchoClient(conn) unaryEcho(cli, \"hello\") serverStreamingEcho(cli, \"hello\") clientStreamingEcho(cli) bidirectionalStreamingEcho(cli) } ","date":"2021-12-03","objectID":"/grpc1/:5:0","tags":null,"title":"GPRC 实战","uri":"/grpc1/"},{"categories":null,"content":"GPRC 进阶 grpc 除了提供四种请求类型之外，还支持很多高级功能：keepalive、请求重试、负载均衡、用户验证等。接下来一一介绍。 GRPC 进阶功能 每个grpc请求都是 stream。 ","date":"2021-12-03","objectID":"/grpc2/:0:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"Keepalive Keepalive 能够让 grpc 的每个 stream 保持长连接状态，适合一些执行时间长的请求。Keepalive 支持在服务端和客户端配置，且只有服务端配置后，客户端的配置才会真正有效。先给出实例的代码在来说明 grpc keepalive 的使用情况：server 实现： // ... var kaep = keepalive.EnforcementPolicy{ MinTime: 5 * time.Second, // If a client pings more than once every 5 seconds, terminate the connection PermitWithoutStream: true, // Allow pings even when there are no active streams } var kasp = keepalive.ServerParameters{ MaxConnectionIdle: 15 * time.Second, // If a client is idle for 15 seconds, send a GOAWAY MaxConnectionAge: 30 * time.Second, // If any connection is alive for more than 30 seconds, send a GOAWAY MaxConnectionAgeGrace: 5 * time.Second, // Allow 5 seconds for pending RPCs to complete before forcibly closing connections Time: 5 * time.Second, // Ping the client if it is idle for 5 seconds to ensure the connection is still active Timeout: 1 * time.Second, // Wait 1 second for the ping ack before assuming the connection is dead } // server implements EchoServer. type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { address := \"50001\" lis, err := net.Listen(\"tcp\", address) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // 创建 grpc server 时配置服务端的 keepalive s := grpc.NewServer(grpc.KeepaliveEnforcementPolicy(kaep), grpc.KeepaliveParams(kasp)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } client 端实现： // ... var kacp = keepalive.ClientParameters{ Time: 10 * time.Second, // send pings every 10 seconds if there is no activity Timeout: time.Second, // wait 1 second for ping ack before considering the connection dead PermitWithoutStream: true, // send pings even without active streams } func main() { conn, err := grpc.Dial(\"50001\", grpc.WithInsecure(), grpc.WithKeepaliveParams(kacp)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute) defer cancel() fmt.Println(\"Performing unary request\") res, err := c.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: \"keepalive demo\"}) if err != nil { log.Fatalf(\"unexpected error from UnaryEcho: %v\", err) } fmt.Println(\"RPC response:\", res) } keepalive 的实现核心在于 keepalive.EnforcementPolicy 和 keepalive.ServerParameters。首先是 keepalive.ServerParameters。它包含几个属性： MaxConnectionIdle : 最大空闲连接时间，默认为无限制。这段时间为客户端 stream 请求为0 或者建立连接。超出这段时间后，serve 会发送一个 GoWay，强制 client stream 断开。 MaxConnectionAge：最大连接时间，默认为无限制。stream 连接超出这个值是发送一个 GoWay。 MaxConnectionAgeGrace ：超出MaxConnectionAge之后的宽限时长，默认无限制，最小为 1s。 Time ：如果一段时间客户端存活但没有 pings 请求，服务端发送一次 ping 请求，默认是 2hour。 Timeout：服务端发送 ping 请求超时的时间，默认20s。 keepalive.EnforcementPolicy在服务端强制执行策略，如果客户端违反改策略则断开连接。它有两个属性： MinTime : 如果在指定时间内收到 pings 请求大于一次，强制断开连接，默认 5min。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 keepalive.ClientParameters是在客户端这侧使用的 keepalive 配置： Time ：pings 请求间隔时间，默认无限制，最小为 10s。 Timeout ：pings 超时时间，默认是 20s。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 ","date":"2021-12-03","objectID":"/grpc2/:1:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"请求重试 grpc 支持请求重试，在客户端配置好规则之后，客户端会在请求失败之后尝试重新发起请求。 var ( retryPolicy = `{ \"methodConfig\": [{ \"name\": [{\"service\": \"mysite.pb.Echo\"}], \"waitForReady\": true, \"retryPolicy\": { \"MaxAttempts\": 3, \"InitialBackoff\": \".01s\", \"MaxBackoff\": \"1s\", \"BackoffMultiplier\": 2.0, \"RetryableStatusCodes\": [ \"UNAVAILABLE\" ] } }]}` ) // use grpc.WithDefaultServiceConfig() to set service config func retryDial() (*grpc.ClientConn, error) { return grpc.Dial(*addr, grpc.WithInsecure(), grpc.WithDefaultServiceConfig(retryPolicy)) } // ... retry 配置只需要在客户端设置即可生效。主要是配置ServerConfig，格式为该链接 MaxAttempts ：重试的最大次数，最大值是5。 InitialBackoff : 初始化重试间隔时间，第一次重试去 Randon(0,initialBackoff)。 MaxBackoff : 最大重试间隔时间，多次重试是，间隔时间取 random(0,min(initial_backoff*backoff_multiplier**(n-1), max_backoff))。 RetryableStatusCodes : 设置需要重试的状态码。 ","date":"2021-12-03","objectID":"/grpc2/:2:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"负载均衡 grpc 支持客户端负载均衡策略，负载均衡在 grpc name_resolver 的基础上实现： const ( exampleScheme = \"example\" exampleServiceName = \"lb.example.grpc.io\" ) // ... func main() { // ... // round_robin 指定负载均衡策略为轮询策略 roundrobinConn, err := grpc.Dial( fmt.Sprintf(\"%s:///%s\", exampleScheme, exampleServiceName), grpc.WithBalancerName(\"round_robin\"), // This sets the initial balancing policy. grpc.WithInsecure(), grpc.WithBlock(), ) // ... } // 配置 name resolver type exampleResolverBuilder struct{} func (*exampleResolverBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { r := \u0026exampleResolver{ target: target, cc: cc, addrsStore: map[string][]string{ exampleServiceName: addrs, }, } r.start() return r, nil } func (*exampleResolverBuilder) Scheme() string { return exampleScheme } type exampleResolver struct { target resolver.Target cc resolver.ClientConn addrsStore map[string][]string } func (r *exampleResolver) start() { addrStrs := r.addrsStore[r.target.Endpoint] addrs := make([]resolver.Address, len(addrStrs)) for i, s := range addrStrs { addrs[i] = resolver.Address{Addr: s} } r.cc.UpdateState(resolver.State{Addresses: addrs}) } func (*exampleResolver) ResolveNow(o resolver.ResolveNowOptions) {} func (*exampleResolver) Close() {} func init() { resolver.Register(\u0026exampleResolverBuilder{}) } 主要是要实现 resolver.Builder接口 // Builder creates a resolver that will be used to watch name resolution updates. type Builder interface { // Build creates a new resolver for the given target. // // gRPC dial calls Build synchronously, and fails if the returned error is // not nil. Build(target Target, cc ClientConn, opts BuildOptions) (Resolver, error) // Scheme returns the scheme supported by this resolver. // Scheme is defined at \u003chttps://github.com/grpc/grpc/blob/master/doc/naming.md\u003e. Scheme() string } 上面的实现方式不支持动态增减服务端地址，可以使用 etcd 实现负载均衡： type etcdBuilder struct { prefix string endpoints []string } func ETCDBuilder(prefix string, endpoints []string) resolver.Builder { return \u0026etcdBuilder{prefix, endpoints} } func (b *etcdBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { cli, err := clientv3.New(clientv3.Config{ Endpoints: b.endpoints, DialTimeout: 3 * time.Second, }) if err != nil { return nil, fmt.Errorf(\"connect to etcd endpoints error\") } ctx, cancel := context.WithCancel(context.Background()) rlv := \u0026etcdResolver{ cc: cc, cli: cli, ctx: ctx, cancel: cancel, watchKeyPrefix: b.prefix, freq: 5 * time.Second, t: time.NewTimer(0), rn: make(chan struct{}, 1), im: make(chan []resolver.Address), wg: sync.WaitGroup{}, } rlv.wg.Add(2) go rlv.watcher() go rlv.FetchBackendsWithWatch() return rlv, nil } func (b *etcdBuilder) Scheme() string { return \"etcd\" } type etcdResolver struct { retry int freq time.Duration ctx context.Context cancel context.CancelFunc cc resolver.ClientConn cli *clientv3.Client t *time.Timer watchKeyPrefix string rn chan struct{} im chan []resolver.Address wg sync.WaitGroup } func (r *etcdResolver) ResolveNow(opt resolver.ResolveNowOptions) { select { case r.rn \u003c- struct{}{}: default: } } func (r *etcdResolver) Close() { r.cancel() r.wg.Wait() r.t.Stop() } func (r *etcdResolver) watcher() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case addrs := \u003c-r.im: if len(addrs) \u003e 0 { r.retry = 0 r.t.Reset(r.freq) r.cc.UpdateState(resolver.State{Addresses: addrs}) continue } case \u003c-r.t.C: case \u003c-r.rn: } result := r.FetchBackends() if len(result) == 0 { r.retry++ r.t.Reset(r.freq) } else { r.retry = 0 r.t.Reset(r.freq) } r.cc.UpdateState(resolver.State{Addresses: result}) } } func (r *etcdResolver) FetchBackendsWithWatch() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case _ = \u003c-r.cli.Watch(r.ctx, r.watchKeyPrefix, clientv3.WithPrefix()): result := r.FetchBackends() r.im \u003c- result } } } func (r *etcdResolver) FetchBackends() []resolver.Address { ctx, cancel := context.WithTimeout(context.Background()","date":"2021-12-03","objectID":"/grpc2/:3:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 加密传输 以上的请求中，grpc 都是通过明文传输数据。但这种方式是很容易泄露数据内容的，grpc 支持 TLS 格式的加密通讯，来保存数据传输的安全性。 ","date":"2021-12-03","objectID":"/grpc2/:4:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"TLS 证书 我们首先来生成 TLS 证书 openssl ecparam -genkey -name secp384r1 -out server.key openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 这里需要填写相关信息 Country Name (2 letter code) []: State or Province Name (full name) []: Locality Name (eg, city) []: Organization Name (eg, company) []: Organizational Unit Name (eg, section) []: Common Name (eg, fully qualified host name) []: mysite Email Address []: 填写完成后就生成对应的证书： ssl ├── server.key └── server.pem 服务端实现 // ... const PORT = \"50001\" func main() { // 通过 credentials 加载服务端的TLS证书 c, err := credentials.NewServerTLSFromFile(\"../ssl/server.pem\", \"../ssl/server.key\") if err != nil { log.Fatalf(\"credentials.NewServerTLSFromFile err: %v\", err) } // 添加 credentials 配置 server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, \u0026SearchService{}) lis, err := net.Listen(\"tcp\", \":\"+PORT) if err != nil { log.Fatalf(\"net.Listen err: %v\", err) } server.Serve(lis) } 客户端实现 const PORT = \"9001\" func main() { // 添加 credentials 配置 c, err := credentials.NewClientTLSFromFile(\"../ssl/server.pem\", \"mysite\") if err != nil { log.Fatalf(\"credentials.NewClientTLSFromFile err: %v\", err) } // 客户端开启证书验证 conn, err := grpc.Dial(\":\"+PORT, grpc.WithTransportCredentials(c)) if err != nil { log.Fatalf(\"grpc.Dial err: %v\", err) } defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), \u0026pb.SearchRequest{ Request: \"gRPC\", }) if err != nil { log.Fatalf(\"client.Search err: %v\", err) } log.Printf(\"resp: %s\", resp.GetResponse()) } ","date":"2021-12-03","objectID":"/grpc2/:4:1","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"CA TLS 证书 TLS 证书的安全性还不够高，特别在证书生成之后，server.key文件的传输就成为一个问题。所以 CA 来签发 TLS 证书来解决这个问题。使用开源工具 cfssl 生成对应的证书：1.ca 配置 cat \u003c\u003c EOF | tee ca-config.json { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"mysite\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } }} EOF 配置 mysite 机构证书可以进行服务端和客户端双向验证。2.ca 证书 cat \u003c\u003c EOF | tee ca-csr.json { \"CN\": \"mysite CA\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 3.服务端证书 cat \u003c\u003c EOF | tee server-csr.json { \"CN\": \"mysite\", \"hosts\": [ \"127.0.0.1\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 生成 mysite ca 证书和私钥，初始化 ca cfssl gencert -initca ca-csr.json | cfssljson -bare ca 生成server证书 cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=mysite -hostname=mysite server-csr.json | cfssljson -bare server 最后的结果为: ../ssl ├── ca-config.json ├── ca-csr.json ├── ca-key.pem ├── ca.csr ├── ca.pem ├── server-csr.json ├── server-key.pem ├── server.csr └── server.pem 接下来是代码实现，先是服务端： // ... type ecServer struct { pb.UnimplementedEchoServer } func (s *ecServer) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:50001\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, }) s := grpc.NewServer(grpc.Creds(creds)) // Register EchoServer on the server. pb.RegisterEchoServer(s, \u0026ecServer{}) log.Println(\"server start\") if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } 然后是客户端： // ... func callUnaryEcho(client pb.EchoClient, message string) { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() resp, err := client.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: message}) if err != nil { log.Fatalf(\"client.UnaryEcho(_) = _, %v: \", err) } fmt.Println(\"UnaryEcho: \", resp.Message) } func main() { // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ServerName: \"mysite\", RootCAs: certPool, }) // Set up a connection to the server. conn, err := grpc.Dial(\"127.0.0.1:50001\", grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() // Make a echo client and send an RPC. rgc := pb.NewEchoClient(conn) callUnaryEcho(rgc, \"hello world\") } ","date":"2021-12-03","objectID":"/grpc2/:4:2","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"拦截器 grpc 支持服务端和客户端的拦截器，可以在请求发起或返回前进行处理，而不用修改原来的代码。接下来来看服务端和客户端各自怎么使用拦截器： // unary 请求拦截器 func UnaryInterceptor(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler, ) (resp interface{}, err error) { var ip string p, ok := peer.FromContext(ctx) if ok { ip = p.Addr.String() } md, _ := metadata.FromIncomingContext(ctx) start := time.Now() resp, err = handler(ctx, req) end := time.Now() log.Printf(\"%10s | %14s | %10v | md=%v | reply = %v\", ip, info.FullMethod, end.Sub(start), md, resp) return } // stream 请求拦截器 func StreamInterceptor(srv interface{}, ss grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler, ) (err error) { var ip string p, ok := peer.FromContext(ss.Context()) if ok { ip = p.Addr.String() } err = handler(srv, ss) log.Printf(\"stream %v | %v | %s\\\\n\", srv, ip, info.FullMethod) return } type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"network at %v: %v\\\\n\", addr, err) } s := grpc.NewServer(grpc.ChainUnaryInterceptor(UnaryInterceptor), grpc.ChainStreamInterceptor(StreamInterceptor)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"start server at %v: %v\\\\n\", addr, err) } } grpc 中的拦截器分两种，一元请求的拦截器和流式请求的拦截器。其中流式请求的连接器同时作用于服务端流式、客户端流式和双向流式三种请求模式。 接下来是客户端： func clientUnaryInterceptor( ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption, ) (err error) { ctx = metadata.AppendToOutgoingContext(ctx, \"username\", \"OOB\") err = invoker(ctx, method, req, reply, cc, opts...) return } func clientStreamInterceptor(ctx context.Context, desc *grpc.StreamDesc, cc *grpc.ClientConn, method string, streamer grpc.Streamer, opts ...grpc.CallOption, ) (stream grpc.ClientStream, err error) { // before stream stream, err = streamer(ctx, desc, cc, method, opts...) // after stream return } func callUnaryEcho(cc pb.EchoClient, msg string) { reply, err := cc.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err == nil { log.Printf(\"reply =\u003e %v\\\\n\", reply) } } func callBidirectionalEcho(cc pb.EchoClient, msg string) { stream, err := cc.BidirectionalStreamingEcho(context.TODO()) if err != nil { log.Fatalf(\"call BidirectionalEcho: %v\\\\n\", err) } _ = stream.Send(\u0026pb.EchoRequest{Message: msg}) _ = stream.CloseSend() ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } reply, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Fatalf(\"stream recv: %v\\\\n\", err) } log.Printf(\"stream reply =\u003e %v\\\\n\", reply.Message) } } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext( ctx, addr, grpc.WithInsecure(), grpc.WithChainUnaryInterceptor(clientUnaryInterceptor), grpc.WithChainStreamInterceptor(clientStreamInterceptor)) if err != nil { log.Fatalf(\"connect %v: %v\\\\n\", addr, err) } cc := pb.NewEchoClient(conn) callUnaryEcho(cc, \"unary\") callBidirectionalEcho(cc, \"start\") } grpc 的拦截器同时支持单个拦截器和链式拦截器。 ","date":"2021-12-03","objectID":"/grpc2/:5:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 添加 pprof 接口 grpc 本身是使用 http2 作为底层协议，所以它也能和 golang 的 pprof 结合提供 pprof 接口。下面给出代码： type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" // 这里可以添加服务段启动配置和各种拦截器 s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) mux := http.NewServeMux() mux.HandleFunc(\"/debug/pprof/\", pprof.Index) mux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline) mux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile) mux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol) mux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace) // 启动 http2 服务，golang http 启动时添加证书会自动转化为 http2 服务。 // 将 Content-Type 为 application/grpc 请求转交给 grpc 即可。 err := http.ListenAndServeTLS( addr, \"ssl/server.pem\", \"ssl/server-key.pem\", http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) { if r.ProtoMajor == 2 \u0026\u0026 strings.Contains(r.Header.Get(\"Content-Type\"), \"application/grpc\") { log.Println(\"call grpc service\") s.ServeHTTP(rw, r) } else { mux.ServeHTTP(rw, r) } })) if err != nil { log.Fatalf(\"start server at %v: %v\", addr, err) } } ","date":"2021-12-03","objectID":"/grpc2/:6:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"grpc 请求断开处理 grpc 的请求没有自己设置请求的超时时间，而是将这部分的处理交给 golang 的 context 包。通过 context 的功能实现客户端的登录超时，请求超时。服务端代码： type server struct { pb.UnimplementedEchoServer } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 该函数内是 stream 的整个生命周期，该函数退出后，stream 的上下文结束 // 每个stream函数相互独立 // 服务端的 stream 不能直接发起请求终止，但可以通过提前结束该函数，停止该 stream for { in, err := stream.Recv() if err != nil { fmt.Printf(\"server: error receiving from stream: %v\\n\", err) if err == io.EOF { return nil } return err } fmt.Printf(\"echoing message %q\\n\", in.Message) stream.Send(\u0026pb.EchoResponse{Message: in.Message}) } } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:10050\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } fmt.Printf(\"server listening at port %v\\n\", lis.Addr()) s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) s.Serve(lis) } 客户端: func sendMessage(stream pb.Echo_BidirectionalStreamingEchoClient, msg string) error { fmt.Printf(\"sending message %q\\n\", msg) return stream.Send(\u0026pb.EchoRequest{Message: msg}) } func recvMessage(stream pb.Echo_BidirectionalStreamingEchoClient, wantErrCode codes.Code) { res, err := stream.Recv() if status.Code(err) != wantErrCode { log.Fatalf(\"stream.Recv() = %v, %v; want _, status.Code(err)=%v\", res, err, wantErrCode) } if err != nil { fmt.Printf(\"stream.Recv() returned expected error %v\\n\", err) return } fmt.Printf(\"received message %q\\n\", res.Message) } func main() { addr := \"127.0.0.1:10050\" // 建立连接 // 建立连接的 ctx 和请求的 ctx 是独立的 conn, err := grpc.DialContext(context.Background(), addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) // Initiate the stream with a context that supports cancellation. ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) stream, err := c.BidirectionalStreamingEcho(ctx) if err != nil { log.Fatalf(\"error creating stream: %v\", err) } // Send some test messages. if err := sendMessage(stream, \"hello\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } if err := sendMessage(stream, \"world\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } // Ensure the RPC is working. recvMessage(stream, codes.OK) recvMessage(stream, codes.OK) fmt.Println(\"cancelling context\") cancel() // This Send may or may not return an error, depending on whether the // monitored context detects cancellation before the call is made. sendMessage(stream, \"closed\") // This Recv should never succeed. recvMessage(stream, codes.Canceled) } GRPC 性能优化 虽然 grpc 的官方自诩是高性能的框架，但是 grpc 内部使用大量的反射，使得 grpc 在性能上并不算很好，所以还是有必要优化。grpc 的优化思路比较简单，不需要直接修改源码，只需要在 protoc 命令生成 golang 代码是，将 golang/protobuf 换成第三方的 gogo/protobuf 。gogo库基于官方库开发，增加了很多的功能，包括： 快速的序列化和反序列化 更规范的Go数据结构 goprotobuf兼容 可选择的产生一些辅助方法，减少使用中的代码输入 可以选择产生测试代码和benchmark代码 其它序列化格式 比如etcd、k8s、dgraph、docker swarmkit都使用它。基于速度和定制化的考虑，gogo有三种产生代码的方式 gofast: 速度优先，不支持其它gogoprotobuf extensions。 go get github.com/gogo/protobuf/protoc-gen-gofast protoc --gofast_out=. myproto.proto gogofast类似gofast,但是会导入gogoprotobuf gogofaster类似gogofast, 不会产生XXX_unrecognized指针字段，可以减少垃圾回收时间。 gogoslick类似gogofaster,但是可以增加一些额外的方法gostring和equal等等。 go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/{binary} //protoc-gen-gogofast、protoc-gen-gogofaster 、protoc-gen-gogoslick go get github.com/gogo/protobuf/gogoproto protoc -I=. -I=$GOPATH/src -I=$GOPATH/src/github.com/gogo/protobuf/protobuf --{binary}_out=. myproto.proto protoc-gen-gogo: 最快的速度，最多的可定制化 你可以通过扩展定制序列化: 扩展. go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/jsonpb go get github.com/gogo/protobuf/protoc-gen-gogo go get github.com/gogo/protobuf/gogoproto gogo同样支持grpc: protoc --gofast_out=plugins=grpc:. my.proto。同时还有 protobuf 对应的教程 。 ","date":"2021-12-03","objectID":"/grpc2/:7:0","tags":null,"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":null,"content":"iscsi共享磁盘服务 iscsi简单介绍 iSCSI（Internet Small Computer System Interface，发音为/ˈаɪskʌzi/），Internet小型计算机系统接口，又称为IP-SAN，是一种基于因特网及SCSI-3协议下的存储技术，由IETF提出，并于2003年2月11日成为正式的标准。与传统的SCSI技术比较起来，iSCSI技术有以下三个革命性的变化： 把原来只用于本机的SCSI协义透过TCP/IP网络发送，使连接距离可作无限的地域延伸； 连接的服务器数量无限（原来的SCSI-3的上限是15）； 由于是服务器架构，因此也可以实现在线扩容以至动态部署。 简单的说就是tcp协议仿真scsi，将本地的磁盘通过网络共享给其他机器，提供数据的远程存储。 iscsi基本概念 iscsi中有一些常用的基本概念，了解这些能帮助我们认识iscsi服务的具体工作原理，下面就用一张图表来说明： 名词 说明 ACL 访问权限控制列表，用来验证客户端启动器的访问，通常是客户端 iSCSI 启动器的 IQN 名称 IQN 用于标识单个 iSCSI 目标和启动器的唯一名称(全部小写) WWN 用于标识单个光纤通道端口和节点的唯一编号 TARGET iSCSI 服务器上的存储资源 LUN iSCSI 服务器上的块设备 initiator(启动器) 以软件或硬件实施的 iSCSI 客户端 NODE 单个 iSCSI 启动器或者目标 TPG 启动器或者目标上的单个 IP 连接地址 Portal 网络接口及端口 iscsi 安装配置 iscsi 服务管理的软件有多个，这里就简单介绍两个，targetcli和tgt。 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:0:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"使用targetcli管理配置iscsi 1.准备阶段 有两台linux机器，分别作为服务端和客户端。实验环境最好在虚拟机上，方便修改的反复操作。同时在服务端上有一块磁盘作为iscsi共享磁盘。 [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 4G 0 part [SWAP] └─sda3 8:3 0 35.5G 0 part / sdb 8:16 0 10G 0 disk └─sdb1 8:17 0 10G 0 part sdc 8:32 0 10G 0 disk sr0 11:0 1 1024M 0 rom 这个选择/dev/sdb1,没有的同学可以使用fdisk命令自己分配一个。 2.安装targetcli yum install -y targetcli 还需要启动targetcli服务 systemctl start target 3.配置targetcli 配置targetcli有几个步骤，添加target，在target上添加lun，将target共享到指定网段。 先来创建一个块设备，使用命令为： /backstores/block create westos:storage1 /dev/sdb1 进入targetcli操作： [root@localhost ~]# targetcli Warning: Could not load preferences file /root/.targetcli/prefs.bin. targetcli shell version 2.1.fb46 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type 'help'. /\u003e /backstores/block create westos:storage1 /dev/sdb1 Created block storage object westos:storage1 using /dev/sdb1. # 注意这里就成功创建一个快设备 /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 0] o- loopback ......................................................................................................... [Targets: 0] /\u003e 接着创建一个iscsi共享的target，使用命令为： /iscsi create iqn.2018-10.com.westos:storage1 这里的target名称其实可以随意，但一般格式为iqn.year.month.com.domain.xxx, 执行的结果如下： /\u003e /iscsi create iqn.2018-10.com.westos:storage1 Created target iqn.2018-10.com.westos:storage1. Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ........................","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:1:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"使用tgt配置iscsi 再来介绍另外一种软件，就是tgt。 1.安装 yum install -y epel-release yum install -y scsi-target-utils 启动服务 systemctl start tgtd 2.配置tgt 配置tgt使用的命令是tgtadm，有以下常用选项： –lld –mode target –op new –tid –targetname # 新建target –lld –mode target –op delete [–force] –tid # 删除target –lld –mode target –op show # 查看所有的target –lld –mode target –op show –tid # 查看指定id的target –lld –mode target –op update –tid –name –value # 更新target –lld –mode target –op bind –tid –initiator-address # target共享到指定网段 –lld –mode target –op bind –tid –initiator-name # target共享到指定的客户端名称 –lld –mode target –op unbind –tid –initiator-address # 解绑 –lld –mode target –op unbind –tid –initiator-name –lld –mode logicalunit –op new –tid –lun –backing-store –bstype –bsopts –bsoflags # 创建lun –lld –mode logicalunit –op delete –tid –lun # 删除lun –lld –mode account –op new –user –password # 添加认证 –lld –mode account –op delete –user # 删除认证 –lld –mode account –op bind –tid –user [–outgoing] # 绑定认证 –lld –mode account –op unbind –tid –user [–outgoing] # 解绑认证 添加target [root@localhost ~]# tgtadm --lld iscsi --mode target --op new --tid 1 --targetname iqn-2019-11.com.iscsi.test [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: Account information: ACL information: 添加lun [root@localhost ~]# tgtadm --lld iscsi --mode logicalunit --op new --tid 1 --lun 22 -b /dev/sdb [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: LUN: 22 Type: disk SCSI ID: IET 00010016 SCSI SN: beaf122 Size: 10737 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: rdwr Backing store path: /dev/sdb Backing store flags: Account information: ACL information: 注：这里有一个小提示，每个lun中的SCSI ID项是在客户端中的唯一标识，它的值是根据target id和lun id计算得到的，即： SCSI ID = Target ID转16进制(前四位) + Lun ID转16进制(后四位) 所以lun 22的SCSI ID为00010016 共享到客户端： [root@localhost ~]# tgtadm --lld iscsi --mode target --op bind --tid 1 --initiator-address 192.168.3.131 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:2:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"客户端连接 1.安装客户端 yum install -y epel-release yum install -y iscsi-initiator-utils 客户端命令： iscsiadm -m session # 查看所有会话 iscsiadm -m discovery -t st -p 192.168.3.150 #查看共享target iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l #登陆连接 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -u #退出登陆 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -o delete #删除登陆数据 2.发现设备 [root@localhost ~]# iscsiadm -m discovery -t st -p 192.168.3.150 192.168.3.150:3260,1 iqn.2018-10.com.westos:storage1 登录 注：请关闭防火墙和selinux [root@localhost mnt]# iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l Logging in to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] (multiple) Login to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] successful. [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 8G 0 part [SWAP] └─sda3 8:3 0 31.5G 0 part / sdb 8:16 0 2G 0 disk └─sdb1 8:17 0 2G 0 part sr0 11:0 1 1024M 0 rom 同时在/dev/disk/by-id下生成块设备。 ","date":"2021-12-03","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:3:0","tags":null,"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":null,"content":"KVM之虚拟机管理 本篇文章介绍 KVM 虚拟机的管理，包括虚拟机的创建、修改、启动、删除等内容 安装虚拟机 ","date":"2021-12-03","objectID":"/kvm_vm/:0:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"使用 virt-install 安装 virt-install 是一个命令行工具，专门用于安装 kvm 虚拟机。执行以下命令： virt-install \\ --name centos \\ --ram 1024 \\ --disk path=/data/kvm/centos.img,size=20 \\ --vcpus 1 \\ --os-type linux --os-variant rhel7 \\ --network bridge=br0 \\ --graphics vnc,listen=0.0.0.0,port=5999 --noautoconsole \\ --console pty,target_type=serial \\ --cdrom CentOS-7-x86_64-DVD-1810.iso 进入安装流程： # virsh list --all Id 名称 状态 ---------------------------------------------------- 2 centos running 可以使用 vnc 客户端连接虚拟机。 参数说明： -–name 指定虚拟机的名字 –-ram 指定内存分配多少 –-disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –-vcpus 指定分配cpu几个 -–os-type 指定系统类型为linux –-os-variant 指定系统版本 -–network 指定网络类型 -–graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 -–console 指定控制台类型 -–location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS –extra-args 额外参数，需要和 –location 配置使用 –cdrom 指定操作系统镜像位置 ","date":"2021-12-03","objectID":"/kvm_vm/:1:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误处理 安装过程中出现三个错误: ","date":"2021-12-03","objectID":"/kvm_vm/:2:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误一 第一个错误如下: CPU mode 'custom' for x86_64 kvm domain on x86_64 host is not supported by hypervisor 解决方式是重启宿主机 ","date":"2021-12-03","objectID":"/kvm_vm/:2:1","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误二 第二个错误如下： Creating storage file centos.img | 20 GB 00:00 ERROR internal error Process exited while reading console log output: char device redirected to /dev/pts/4 2016-01-27T08:56:58.986952Z ...: Permission denied Domain installation does not appear to have been successful. If it was, you can restart your domain by running: virsh --connect qemu:///system start centos65 otherwise, please restart your installation. 解决方式修改 /etc/libvirt/qemu.conf 配置文件，添加 user 和 group 配置： # /etc/libvirt/qemu.conf # ... user = \"root\" # ... group = \"root\" 重启服务: systemctl restart libvirtd ","date":"2021-12-03","objectID":"/kvm_vm/:2:2","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"错误三 第三个错误是执行命令 virsh console centos 时卡住: # virsh console centos 连接到域 centos 换码符为 ^] 解决方式如下： 确认 ttyS0 存在在 /etc/securetty 文件中，没有就执行以下命令: echo \"ttyS0\" \u003e\u003e /etc/securetty 修改 /etc/default/grub 文件： # GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet” # 改成 GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet net.ifnames=0 console=ttyS0,115200\" 重新生成 grub 文件： grub2-mkconfig -o /boot/grub2/grub.cfg 启动 serial-getty 服务: systemctl start serial-getty@ttyS0.service systemctl enable serial-getty@ttyS0.service 操作虚拟机 KVM 在 Hypervisor 中被称作域(domain)。使用 virsh 命令可以很有效的管理域。 virsh 中管理域的命令: 命令 功能描述 list 获取当前节点上的所有域的列表 domstate \u003cID or Name or UUID\u003e 获取一个域的运行状态 dominfo \u003cID\u003e 获取一个域的基本信息 domid \u003cName or UUID\u003e 根据域的名称或UUID返回域的ID domname \u003cID or UUID\u003e 根据域的ID或UUID返回域的名称 dommemstat \u003cID\u003e 获取一个域的内存使用情况的统计信息 setmem \u003cID\u003e \u003cmem-size\u003e 设置一个域的内存大小(默认单位为KB) vcpupin \u003cID\u003e \u003cvCPU\u003e \u003cpCPU\u003e 将一个域的 vCPU 绑定到某个物理 CPU 上运行 setvcpus \u003cID\u003e \u003cvCPU-num\u003e 设置一个域的 vCPU 的个数 vncdisplay \u003cID\u003e 获取一个域的 VNC 连接 IP 地址的端口 create \u003cdom.xml\u003e 根据域的 XML 配置文件创建一个域(客户机) suspend \u003cID\u003e 暂停一个域 resume \u003cID\u003e 唤醒一个域 shutdown \u003cID\u003e 让一个域执行关机操作 reboot \u003cID\u003e 让一个域执行重启操作 reset \u003cID\u003e 强制重启一个域，相当于在物理机上按带电源 “reset” 按钮 (可能会破坏该域的文件系统) destroy \u003cID\u003e 立即销毁一个域，相当于直接拔掉物理机机器的电源线（可能会破坏该域的文件系统） save \u003cID\u003e \u003cfile.img\u003e 保存一个运行中的域的状态到一个文件中 restore \u003cfile.img\u003e 从一个被保存的文件中恢复一个域的运行 migrate \u003cID\u003e \u003cdest_url\u003e 将一个域迁移到另外一个目的地址 dumpxml \u003cID\u003e 以 XML 格式转存出一个域的信息到标准输出中 attach-device \u003cID\u003e \u003cdevice.xml\u003e 向一个域添加 XML 文件中的设备(热插拔) detach-device \u003cID\u003e \u003cdevice.xml\u003e 将 XML 文件中的设备从一个域中移除 console \u003cID\u003e 连接到一个域的控制台 ","date":"2021-12-03","objectID":"/kvm_vm/:2:3","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"虚拟机生命周期 # 启动虚拟机 virsh start centos # 关闭虚拟机 virsh shutdown centos # 重启虚拟机 virsh reboot centos # 销毁虚拟机 virsh destroy centos # 暂停虚拟机 virsh suspend centos # 恢复虚拟机 virsh resume centos # 删除虚拟机 virsh undefine centos rm -fr /etc/libvirt/qemu/centos.xml ","date":"2021-12-03","objectID":"/kvm_vm/:3:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"限制和修改虚拟机 cpu 先关闭虚拟机，修改虚拟机 xml 文件: # 设置 cpu 最大个数为 4 个，当前为 1 \u003cvcpu placement='static' current='1'\u003e4\u003c/vcpu\u003e 开启虚拟机后，动态设置虚拟机 cpu # 最大个数不能超过指定值 virsh setvcpus centos 2 ","date":"2021-12-03","objectID":"/kvm_vm/:4:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"限制和修改虚拟机内存 修改虚拟机内存最大值需要先关闭虚拟机 # 最大值不能超过宿主机内存最大值 virsh setmaxmem centos 4G 动态设置虚拟机内存 virsh setmem centos 2G ","date":"2021-12-03","objectID":"/kvm_vm/:5:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"在线添加和删除虚拟机硬盘 先创建硬盘: # qemu-img create -f qcow2 disk1.qcow2 2G Formatting 'disk1.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=2147483648 lazy_refcounts=off refcount_bits=16 创建 disk.xml 文件 $ vim disk.xml \u003cdisk type='file' device='disk'\u003e \u003cdriver name='qemu' type='qcow2'/\u003e \u003csource file='/data/kvm/disk1.qcow2'/\u003e \u003ctarget dev='vdb' bus='virtio'/\u003e \u003caddress type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/\u003e \u003c/disk\u003e 添加硬盘设备: virsh attach-device centos disk.xml 卸载硬盘设备 virsh dettach-device centos disk.xml ","date":"2021-12-03","objectID":"/kvm_vm/:6:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"在线添加和删除虚拟机网卡 添加 bridge 网卡 virsh attach-interface centos --type bridge --source br0 卸载网卡 virsh detach-interface centos --type bridge --mac 52:54:00:d9:90:bb ","date":"2021-12-03","objectID":"/kvm_vm/:7:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"修改虚拟机 vnc 先关闭虚拟机 virsh stop centos 修改虚拟机文件 # irsh edit centos \u003cgraphics type='vnc' port='6000' autoport='no' listen='0.0.0.0' passwd='123456'\u003e \u003clisten type='address' address='0.0.0.0'/\u003e \u003c/graphics\u003e 注: 虚拟机 vnc 的端口必须在 5900 - 65535 之间 加载配置文件 virsh define /etc/libvirt/qemu/centos.xml 最后启动虚拟机 virsh start centos ","date":"2021-12-03","objectID":"/kvm_vm/:8:0","tags":null,"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":null,"content":"KVM介绍 KVM 概述 KVM (Kernal-base Virtual Machine) 基于内核的虚拟机。是一种通过修改 linux 内核实现虚拟化功能的半虚拟化技术。由于是在内核基础上运行，所有具有接近物理机的高性能。 KVM 和 Qemu Qemu（quick emulator）开源的软件虚拟化实现，通过软件来模拟硬件的功能，但缺点是性能低。通过和 KVM 相结合来提高性能。现在的版本已经内置 KVM。 全虚拟化和半虚拟化 全虚拟化是指不需要修改操作系统内核实现虚拟化功能，半虚拟化则需要修改内核来实现虚拟化。 KVM 就是一种半虚拟化实现。 全虚拟化又分为软件全虚拟化 (Qemu) 和硬件全虚拟化(Xen)。 KVM 工具集合 libvirt：操作和管理KVM虚机的虚拟化 API，使用 C 语言编写，可以由 Python,Ruby, Perl, PHP, Java 等语言调用。可以操作包括 KVM，vmware，XEN，Hyper-v, LXC 等在内的多种 Hypervisor。 Virsh：基于 libvirt 的 命令行工具 （CLI） Virt-Manager：基于 libvirt 的 GUI 工具 virt-v2v：虚机格式迁移工具 virt-* 工具：包括 Virt-install （创建KVM虚机的命令行工具）， Virt-viewer （连接到虚机屏幕的工具），Virt-clone（虚机克隆工具），virt-top 等 sVirt：安全工具 KVM 文章 KVM介绍 KVM源码分析 ","date":"2021-12-03","objectID":"/kvm_detail/:0:0","tags":null,"title":"KVM介绍","uri":"/kvm_detail/"},{"categories":null,"content":"KVM镜像管理工具libguestfs 简介 libguestfs 是一套管理虚拟机镜像的工具。它提供以一系列命令和API来修改和管理虚拟机的镜像。 安装 直接使用 yum 安装 libguestfs : yum install -y libguestfs-tool libguestfs-devel 默认不支持修改 windows 镜像，可以安装 libguestfs-winsupport : yum install -y libguestfs-winsupport libguestfs 命令 libguestfs 的通用参数 -a|–add image : 指定查看的镜像文件路径 -c|–connect uri : 指定远程 libvirt 地址 -d|–domain guest : 指定 libvirt 上的 domain 名称 注: libguestfs 的命令需要调用 libvirt 所以响应的速度会比较慢。同时，如果命令会修改镜像的内容，需要先关闭域，避免造成数据不同步。 ","date":"2021-12-03","objectID":"/libguestfs/:0:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-inspector virt-inspector 命令用来查看镜像信息，输出格式为 xml $ virt-inspector -d centos \u003c?xml version=\"1.0\"?\u003e \u003coperatingsystems\u003e \u003coperatingsystem\u003e \u003croot\u003e/dev/centos/root\u003c/root\u003e \u003cname\u003elinux\u003c/name\u003e \u003carch\u003ex86_64\u003c/arch\u003e \u003cdistro\u003ecentos\u003c/distro\u003e \u003cproduct_name\u003eCentOS Linux release 7.6.1810 (Core) \u003c/product_name\u003e \u003cmajor_version\u003e7\u003c/major_version\u003e \u003cminor_version\u003e6\u003c/minor_version\u003e \u003cpackage_format\u003erpm\u003c/package_format\u003e \u003cpackage_management\u003eyum\u003c/package_management\u003e \u003chostname\u003elocalhost.localdomain\u003c/hostname\u003e \u003cosinfo\u003ecentos7.0\u003c/osinfo\u003e \u003cmountpoints\u003e \u003cmountpoint dev=\"/dev/centos/root\"\u003e/\u003c/mountpoint\u003e \u003cmountpoint dev=\"/dev/sda1\"\u003e/boot\u003c/mountpoint\u003e \u003c/mountpoints\u003e \u003cfilesystems\u003e \u003cfilesystem dev=\"/dev/centos/root\"\u003e \u003ctype\u003exfs\u003c/type\u003e \u003cuuid\u003e12e94e0d-93e6-4714-9c61-116fbe994936\u003c/uuid\u003e \u003c/filesystem\u003e ... ... \u003cxml\u003e ","date":"2021-12-03","objectID":"/libguestfs/:1:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-watch virt-watch 查看本机虚拟化环境 $ virt-what vmware ","date":"2021-12-03","objectID":"/libguestfs/:2:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-host-validator virt-host-validator 检查本地环境是否符合虚拟化 $ virt-host-validate QEMU: 正在检查 for hardware virtualization : PASS QEMU: 正在检查 if device /dev/kvm exists : PASS QEMU: 正在检查 if device /dev/kvm is accessible : PASS QEMU: 正在检查 if device /dev/vhost-net exists : PASS ... ... ","date":"2021-12-03","objectID":"/libguestfs/:3:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-get-kernel virt-get-kernel 获取镜像的内核文件 $ virt-get-kernel -d centos download: /boot/vmlinuz-3.10.0-957.el7.x86_64 -\u003e ./vmlinuz-3.10.0-957.el7.x86_64 download: /boot/initramfs-3.10.0-957.el7.x86_64.img -\u003e ./initramfs-3.10.0-957.el7.x86_64.img ","date":"2021-12-03","objectID":"/libguestfs/:4:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-filesystems virt-filesystems 查看镜像的文件系统 $ virt-filesystems -d centos /dev/sda1 /dev/centos/root ","date":"2021-12-03","objectID":"/libguestfs/:5:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-df virt-df 用来查看镜像的文件系统容量，同 df 命令 $ virt-df -d centos -h 文件系统 大小 已用空间 可用空间 使用百分比% centos:/dev/sda1 1014M 100M 914M 10% centos:/dev/centos/root 17G 974M 16G 6% ","date":"2021-12-03","objectID":"/libguestfs/:6:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-ls virt-ls 查看镜像的文件信息，同 ls 命令 $ virt-ls -d centos /root/ -l total 28 dr-xr-x---. 2 root root 135 Jan 26 15:07 . dr-xr-xr-x. 17 root root 224 Jan 16 09:56 .. -rw-------. 1 root root 45 Jan 26 15:07 .bash_history -rw-r--r--. 1 root root 18 Dec 29 2013 .bash_logout -rw-r--r--. 1 root root 176 Dec 29 2013 .bash_profile -rw-r--r--. 1 root root 176 Dec 29 2013 .bashrc -rw-r--r--. 1 root root 100 Dec 29 2013 .cshrc -rw-r--r--. 1 root root 129 Dec 29 2013 .tcshrc -rw-------. 1 root root 1259 Jan 16 09:57 anaconda-ks.cfg ","date":"2021-12-03","objectID":"/libguestfs/:7:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-cat virt-cat 查看镜像内的文件内容，同 cat 命令 $ virt-cat -d centos /etc/passwd root:xx:0:0:root:/root:/bin/bash ... ... ","date":"2021-12-03","objectID":"/libguestfs/:8:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-log virt-log 查看镜像的日志信息 $ virt-log -d centos Jan 30 20:13:01 localhost rsyslogd: [origin software=\"rsyslogd\" swVersion=\"8.24.0-34.el7\" x-pid=\"3123\" x-info=\"http://www.rsyslog.com\"] rsyslogd was HUPed Jan 30 20:33:37 localhost qemu-ga: info: guest-shutdown called, mode: powerdown Jan 30 20:33:37 localhost systemd: Started Delayed Shutdown Service. ","date":"2021-12-03","objectID":"/libguestfs/:9:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tail virt-tail 监听文件内容，同 tail 命令 $ virt-tail -d centos /var/log/messages --- /var/log/messages --- ... ","date":"2021-12-03","objectID":"/libguestfs/:10:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-alignment-scan virt-alignment-scan 查看镜像分区是否对齐 $ virt-alignment-scan -a centos.qcow2 /dev/sda1 1048576 1024K ok /dev/sda2 1074790400 1024K ok ","date":"2021-12-03","objectID":"/libguestfs/:11:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-diff virt-diff 比较镜像间的不同 $ # virt-diff -a centos.qcow2 -A centos.img - d 0550 150 /root + d 0550 135 /root # changed: st_size - - 0644 4 /root/kvm.txt - d 1777 187 /tmp + d 1777 172 /tmp # changed: st_size - - 0644 4 /tmp/kvm.txt ","date":"2021-12-03","objectID":"/libguestfs/:12:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-sparisify virt-sparisify 用来消除镜像内的空洞文件，减少镜像大小 $ virt-sparsify centos.qcow2 -f qcow2 centos2.qcow2 [ 0.0] Create overlay file in /tmp to protect source disk [ 0.0] Examine source disk [ 3.4] Fill free space in /dev/centos/root with zero 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 33.5] Clearing Linux swap on /dev/centos/swap 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ --:-- [ 36.2] Fill free space in /dev/sda1 with zero [ 38.5] Copy to destination and make sparse [ 51.4] Sparsify operation completed with no errors. virt-sparsify: Before deleting the old disk, carefully check that the target disk boots and works correctly. 执行完成后生成 centos2.qcow2 文件: $ ll -h 总用量 4.0G -rw-r--r-- 1 root root 1.1G 1月 30 23:39 centos2.qcow2 -rw-r--r-- 1 root root 1.5G 1月 30 20:33 centos.img -rw-r--r-- 1 root root 1.5G 1月 30 20:43 centos.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:13:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-copy-in virt-copy-in 将本地文件复制到镜像中 $ virt-copy-in -a centos.qcow2 kvm.txt /tmp/ $ virt-ls -a centos.qcow2 /tmp/ kvm.txt ","date":"2021-12-03","objectID":"/libguestfs/:14:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-copy-out virt-copy-out 将镜像中的文件复制到本地 $ virt-copy-out -a centos.qcow2 /tmp/kvm.txt . ","date":"2021-12-03","objectID":"/libguestfs/:15:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-edit virt-edit 编译镜像内的文件，默认会打开本地的 Vim 进行编辑 $ virt-edit -a centos.qcow2 /tmp/kvm.txt $ virt-cat -a centos.qcow2 /tmp/kvm.txt kvm kvm11 ","date":"2021-12-03","objectID":"/libguestfs/:16:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-make-fs virt-make-fs 根据本地的目录创建一个镜像 $ mkdir /input $ echo \"input\" \u003e /input/1.txt $ virt-make-fs --partition=gpt --type=ntfs --size=1G --format=qcow2 /input sdb.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:17:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tar-in virt-tar-in tar 压缩文件拷贝进虚拟机并解压 $ virt-tar-in -a centos.qcow2 kvm.tar /root/ ","date":"2021-12-03","objectID":"/libguestfs/:18:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-tar-out virt-tar-out 镜像内指定目录文件拷贝并压缩 $ virt-tar-out -a centos.qcow2 /root root.tar ","date":"2021-12-03","objectID":"/libguestfs/:19:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"guestmount guestmount 将镜像中的文件系统分区挂载到本地目录 $ guestmount -a centos.qcow2 -m /dev/sda1 /mnt ","date":"2021-12-03","objectID":"/libguestfs/:20:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"guestumount guestumount 卸载 guestmount 挂载的目录 $ guestumount /mnt ","date":"2021-12-03","objectID":"/libguestfs/:21:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-rescue virt-rescue 进入救援模式，修复镜像 $ virt-rescue -a centos.qcow2 ","date":"2021-12-03","objectID":"/libguestfs/:22:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"virt-resize virt-resize 镜像分区缩容和扩容 给其中某个分区扩容 5G $ virt-filesystems --long -h --all -a olddisk $ truncate -r olddisk newdisk $ truncate -s +5G newdisk $ virt-resize --expand /dev/sda2 olddisk newdisk /boot 分区扩容 200MB bigger, 剩下的分配给 /dev/sda2: $ virt-resize --resize /dev/sda1=+200M --expand /dev/sda2 olddisk newdisk lvm 分区扩容 $ virt-resize --expand /dev/sda2 --LV-expand /dev/vg_guest/lv_root olddisk newdisk ","date":"2021-12-03","objectID":"/libguestfs/:23:0","tags":null,"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":null,"content":"linux上使用udev创建裸设备 需求和分析 在一次项目中需要将进行oracle数据库的备份，要求在oracle机器总是能认到备份的块设备的路径以保证备份和恢复的正常。同时还需要对磁盘进行修改，转化中asm格式的。 基于这种情况下，在linux中将磁盘转化成对应的裸设备是一种合适的方法。 简单的操作就是将配置写入/etc/udev/rule.d/1401-oracle-asmdevice.rules文件中，让udev管理。 udev 规则的匹配键 ACTION： 事件 (uevent) 的行为，例如：add( 添加设备 )、remove( 删除设备 )。 KERNEL： 内核设备名称，例如：sda, cdrom。 DEVPATH：设备的 devpath 路径。 SUBSYSTEM： 设备的子系统名称，例如：sda 的子系统为 block。 BUS： 设备在 devpath 里的总线名称，例如：usb。 DRIVER： 设备在 devpath 里的设备驱动名称，例如：ide-cdrom。 ID： 设备在 devpath 里的识别号。 SYSFS{filename}： 设备的 devpath 路径下，设备的属性文件“filename”里的内容。 例如：SYSFS{model}==“ST936701SS”表示：如果设备的型号为 ST936701SS，则该设备匹配该 匹配键。 在一条规则中，可以设定最多五条 SYSFS 的 匹配键。 ENV{key}： 环境变量。在一条规则中，可以设定最多五条环境变量的 匹配键。 PROGRAM：调用外部命令。 RESULT： 外部命令 PROGRAM 的返回结果。 配置文件 这里是CentOS 6的版本 [root@rac1 ~]# cat /etc/udev/rules.d/99-oracle-asmdevice.rules KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000020fa8\",NAME+=\"oracleasm/disks/HL_360000000000000000e00000000020fa8\",OWNER=\"grid\",GROUP=\"asmadmin\",MODE=\"0660\" 然后加载配置文件 [root@rac1 ~]# start_udev 正在启动 udev： [确定] [root@rac1 ~]# ll /dev/oracleasm/disks 总用量 0 brw-rw---- 1 grid asmadmin 8, 16 1月 23 14:30 HL_360000000000000000e00000000020fa8 注意 在CentOS6和CentOS7的配置有所不同。 一个是scsi_id命令，还有是udev规则变化。 KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000160fa8\",RUN+=\"/bin/sh -c 'mkdir -pv /dev/oracleasm/disks;mknod /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8 b 1 3; chown grid:oinstall /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8; chmod 0660 /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8'\" scsi_id命令需要安装systemd包，如果知道命令对应的软件包名称，可以使用yum命令查看 yum provides \"/*/scsi_id\" udev需要使用RUN来代替NAME，在RUN中能使用linux的命令，使用；分隔多个命令。 mknod是CentOS7中转化设备的新命令，格式为： mknod /dev/sdb \u003cDEVICE_TYPE\u003e \u003c主设备号\u003e \u003c次设备号\u003e 同时修改udev的命令也发生了变化。 [root@localhost ~]# /usr/sbin/udevadm trigger --type=devices --action=change 在同时添加多个设备时，后添加的设备同步较慢。比较好的方法是先全部添加到.rules文件中，最后再执行udevadm trigger加载。 ","date":"2021-12-03","objectID":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/:0:0","tags":null,"title":"linux上使用udev创建裸设备","uri":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/"},{"categories":null,"content":"Linux中断和异常 中断(interrupt)通常被定义为一个事件，该事件改变处理器执行的指令顺序。这样的事件与CPU芯片内外部硬件电路产生的点信号相对应。 中断通常分为同步 (synchronous) 中断和异步 (asynchornous) 中断: 同步中断是当指令执行时由 CPU 控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后 CPU 才会发出中断。 异步中断是由其他硬件设备依照 CPU 时钟信号随机产生的。 在 Intel 微处理器中，把同步和异步中断分别称为异常 (exception) 和中断 (interrupt)。 中断是由间隔定时器和I/O设备产生的，异常是由程序的错误产生的，或者是由内核必须处理的异常条件产生的。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:0:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"中断信号的作用 中断信号提供了一种特殊的方式，使处理器转而去运行正常控制流之外的代码。当一个中断信号达到是，CPU 必须停止它当前正在做的事情，并且切换到一个新的活动。所以要在内核态堆栈保存程序计数器的当前值(即eip和cs寄存器的内容)，并把与中断类型相关的一个地址放进程序计数器。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:1:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"中断和异常 中断: 可屏蔽中断 (maskable interrupt) : I/O 设备发出的所有中断请求(IRQ)都产生可屏蔽中断。可屏蔽中断可以处于两种状态: 屏蔽的 (masked) 或非屏蔽的 (unmasked)；一个屏蔽的中断只要还是屏蔽的，控制单元就忽略它。 非屏蔽中断 (nonmaskable interrupt) : 只有几个危急事件(如硬件故障)才引起非屏蔽中断。非屏蔽中断总是由CPU辨认。 异常: 处理器探测异常(processor-detected exception) : 当 CPU 执行指令时探测到一个反常条件所产生的异常。可以进一步分为三组，这取决于CPU控制单元产生异常是保存在内核态堆栈eip寄存器中的值。它们分别是故障(fault)、陷阱(trap) 和异常中止(abort)。 编程异常(programmed exception) : 在编程者发出请求时发生。是由 int 或 int3 指令触发的。当 into(检查溢出)和 bound(检查地址出界)指令查询的条件不为真时，也引起编程异常。控制单元把编程异常作为陷阱来处理。编程异常通常也叫做软中断(software interrupt)。这样的异常有两种常用的用途: 执行系统调用和给调试程序通报一个特定的事件。 处理器探测的异常: 故障: 通常可以纠正。一旦纠正，程序就可以在不失连贯性的情况下重新开始。保存在 eip 中的值是引起故障的指令地址。因此，当异常处理程序终止时，那条指令会被重新执行。 陷阱: 在陷阱指令执行后立即报告。内核把控制权返回给程度后就可以继续它的执行而不失连贯性。保存在 eip 中的值是一个随后要执行的指令地址。只有当没有必须要重新执行以终止的指令时，才触发陷阱。陷阱的主要用途是为了调试程序。 异常中止: 发送一个严重的错误，控制单元出了问题，不能在 eip 寄存器中保存引起异常的指令所在的确切位置。异常中止用于报告严重的错误，如硬件故障或系统表中无效的值或不一致的值。由控制单元发送的这个中断信号时紧急信号，用来把控制权切换到相应的异常中止处理程序，这个异常中止处理程序除了强制受影响的进程中止外，没有别的选择。 每个中断和异常是由0~255之间的一个数来标识。Intel 把这个8位的无符号整数叫做一个向量(vector)。非屏蔽中断的向量和异常的向量是固定的，而可屏蔽中断的向量可以通过对中断控制器的编程来改变。 ","date":"2021-12-03","objectID":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/:2:0","tags":null,"title":"Linux中断和异常","uri":"/linux%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/"},{"categories":null,"content":"Linux内存 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:0:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内存概论 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"虚拟内存 虚拟内存(virtual memory)是 Unix 系统中一种对内存的抽象。虚拟内存作为一种逻辑层，处于应用程序的内存请求与硬件内存管理单元(Memory Management Unit, MMU)之间。虚拟内存有很多用途和优点: 若干个进程可能并发地执行。 应用程序所需内存大于可用物理内存时也可以运行。 程序只有部分代码装入内存时进程可以执行它。 允许每个进程访问可用物理内存的子集。 进程可以共享库函数或程序的一个单独内存映象。 程序时可重定位的，也就是说，可以把程序放在物理内存的任何地方。 程序员可以编写与机器无关的代码，因为他们不必关心有关物理内存的组织结构。 虚拟内存子系统的主要成分是虚拟地址空间(virtual address space)的概念。进程所用的一组内存地址不同于物理内存地址。当进程使用一个虚拟地址时，内核和MMU协同定位其在内存中的实际物理地址位置。 现在的 CPU 包含了能自动把虚拟地址转换成物理地址的硬件电路。为了达到这个目标，把可用 RAM 划分成长度为 4KB 或 8KB 的页框(page frame)，并引入一组页表来指定虚拟地址与物理地址之间的对应关系。 一块连续的虚拟地址请求可以通过分配一组非连续的物理地址页框而得到满足。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"随机访问存储器(RAM)的使用 Unix 操作系统将 RAM 划分成两部分。其中若干兆字节专门用于存放内核映象(也就是内核代码和内核静态数据结构)。RAM的其余部分通常由虚拟内存系统来处理，并且用在以下三种可能的方面: 满足内核对缓冲区，描述符及其他动态内存数据结构的请求。 满足进程对一般内存区的请求及对文件内存映射的请求。 借助与高速缓存从磁盘及其他缓冲设备获得较好的性能。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内核内存分配器 内核内存分配器(Kernel Memory Allocator, KMA)是一个子系统，它试图满足系统中部分对内存的请求。其中一些请求来自内核其他子系统，它们需要一些内核使用的内存，还有一些请求来自于用户程序的系统调用，用来增加用户进程中地址空间。一个好的 KMA 应该具有下列特点: 必须快。因为它由所有的内核子系统(包括中断处理程序)调用。 必须把内存的浪费减到最少。 必须努力减轻内存的碎片(fragmentation)问题。 必须能与其他内存管理子系统合作，以便借用和释放页框。 基于不同的算法技术实现的KMA: 资源图分配算法(allocator) 2的幂次方空闲链表 McKusick-Karels 分配算法 伙伴 (Buddy) 系统 Mach 的区域 (Zone) 分配算法 Dynix 分配算法 Solaris 的 Slab 分配算法 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"进程虚拟地址空间处理 进程的虚拟地址空间包括了进程可以引用的所有虚拟内存地址。内核通常用一组内存区描述符描述进程虚拟地址空间。例如，当进程通过 exec() 类系统调用开始某个程序执行时，内核分配给进程的虚拟地址空间有以下内存区组成。 程序的可执行代码。 程序的初始化数据。 程序的未初始化数据。 初始程序栈(即用户态栈)。 所需共享库的可执行代码和数据。 堆(由程序董太太请求的内存)。 现代 Unix 操作系统采用了请求调页(demand paging)的内存分配策略。有了请求调页，进程可以在它的页还没有在内存时就开始执行。当进程访问一个不存在的页时，MMU产生一个异常，异常处理程序找到受影响的内存区，分配一个空闲的页，并用适当的数据把啊初始化。同理，当进程通过调用 malloc() 或 brk()(由malloc()在内部调用)系统调用动态地请求内存是，内核仅仅修改进程的堆内存区的大小。只有试图引进进程的虚拟内存而产生异常时，才给进程分配页框。 虚拟地址空间也采用其他更有效的策略，如写时复制策略。例如，当一个新进程被创建时，内核仅仅把父进程的页框赋给子进程的地址空间，但是把这些页框标记为只读。一旦父或子进程修改页中的内容时，一个异常就会产生。异常处理程序把新页框赋给受影响的进程，并用原来也中的内容初始化新页框。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:4","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"高速缓存 物理内存的一大优势就是用作磁盘和其他块设备的高速缓存。通常，在最早的 Unix 系统中就已经实现的一个策略是: 尽可能地推迟写磁盘的时间，因此，从磁盘读入内存的数据即使任何进程都不再使用它们，它们也继续留在 RAM 中。 新进程请求从磁盘读或写的数据，就是被撤销进程曾拥有的数据。当一个进程请求访问磁盘时，内核首先检查进程请求的数据是否在缓存中，如果在(把这种请求叫做缓存命中)，内核就可以为进程请求提供服务而不用访问磁盘。 sync() 系统调用把所有\"脏\"的缓冲区写入磁盘来强制磁盘同步。为了避免数据丢失，所有的操作系统都会注意周期性地把脏缓存区写回磁盘。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:1:5","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内存地址 x86微处理器的三种不同地址: 逻辑地址(logical address): 每一个逻辑地址都由一个段(segment)和偏移量(offset或displacement)组成，偏移量指明了从段开始的地方到实际地址之间的距离。 线性地址(linear address)(也称虚拟地址 virtual address): 线性地址通常用十六进制数字表示，值得范围从 0x00000000 到 0xffffffff。可以表示高达 4GB 的地址。 物理地址(physical address): 用于芯片级内存单元寻址。他们从微处理器的地址引脚发送到内存总线上的电信号相对应。 内存控制单元(MMU)通过分段单元(segmentation unit)的硬件电路把一个逻辑地址转换成线性地址。通过分页单元(paging unit)的硬件电路把线性地址转化成物理地址。 在多处理器系统中，所有 CPU 都共享同一内存。RAM芯片上的读和写操作必须串行执行，因此内存仲裁器(memory arbiter)的硬件电路插在总线和每个 RAM 芯片之间。其作用就是如果某个 RAM 芯片空闲，就准予一个 CPU 访问，如果该芯片忙于为另一个处理器提出的请求服务，就延迟这个 CPU 的访问。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:2:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件中的分段 80206 开始，Intel 微处理器具有两种方式执行地址转换： 实模式(real mode)。 保护模式(protected mode)。 实模式存在是处于兼容性考虑，主要还是保护模式。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"段选择符和段寄存器 一个逻辑地址由两部分组成：一个段标识符和一个指定段内相对地址的偏移量。段标识符是一个 16 位长的字段，称为段选择符(Segment Selector)。偏移量是一个 32 位长的字段。 专门存放段选择符的寄存器: cs, ss, ds, es, fs 和 gs。其中3个有专门的用途: cs 代码段寄存器，指向包含程序指令的段。 ss 栈段寄存器，指向包含当前程序栈的段。 ds 数据段寄存器，指向包含静态数据或者全局数据段。 其他3个段寄存器作一般用途，可以指向任意的数据段。 cs 寄存器还有一个很重要的功能: 它含有一个两位的字段，用以指明 CPU 的当前特权级 (Current Privilege Level, CPL)。值为0代表最高优先级，为值为3代表最低优先级。Linux 只用0级和3级，分别称之为内核态和用户态。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"段描述符 每个段由一个8字节的段描述符(Segment Descriptor)表示，它描述了段的特征。段描述符放在全局描述符表(Global Descriptor Table, GDT)或局部描述符表(Local Descriptor Table, LDT)中。 GDT 通常只有一个，在主存中的地址和大小存放在 gdtr 控制寄存器中，当前正被使用的 LDT 地址和大小放在 ldtr 控制寄存器中。 段描述符字段 字段 含义 Base 包含段的首字节的线性地址 G 粒度标志：如果改位清0，则大小以字节为单位，否则以4096字节的倍数计。 Limit 存放段中最后一个内存单元的偏移量，从而决定段的长度。如果 G 被置为0，则一个段的大小在1个字节到1MB之间变化；否则，将在 4KB 到 4GB 之间变化。 S 系统标志：如果它被清0，则这是一个系统段，存储诸如 LDT 这种关键的数据结构，否则它是一个普通的代码段或数据段。 Type 描述了段的类型特征和它的存取权限。 DPL 描述符特权级(Descriptor Privilege Level)字段：用于限制对这个段的存取。它表示为访问这个段而要求的CPU最小的优先级。因此，DPL设为0的段只能当 CPL 为0时(即在内核态)才是可访问的，而DPL设为3的段对任何CPL值都是可访问的 P Segment-Present标志：等于0表示段当前不在主存中。Linux总是把这个表示(第47位)设为1，因为它从来不把整个daunt交换到磁盘上去。 D 或 B 称为D或B的标志，取决于代码段还是数据段。D或B的含义在两种情况中有所区别，但是如果段偏移量的地址是32位长，就基本上把它置为1，如果这个偏移量是16位长，它被清0。 AVL 标志 可以由操作系统使用，但是被 Linux 忽略。 Linux 中被广泛采用的类型: 代码段描述符 数据段描述符 任务状态段描述符 段选择符字段: 字段 含义 index 指定了放在 GDT 或 LDT 中的相应段描述符的入口。 TI TI ((Table Indicator)标志：指明段描述符是在 GDT 中 (TI=0) 或在 LDT 中(TI=1))。 RPL 请求者特权级：当相应的段选择符装入到 cs 寄存器中时，指示出 CPU 当前的特权级；它还可以用于在访问数据段时有选择地削弱处理器的特权级。 为了加速逻辑地址到线性地址的转换，80x86处理器提供一种附加的非编程的寄存器，供6个可编程的段寄存器使用。现在，针对那个段的逻辑地址转化就可以不访问主存中的 GDT 或 LDT，处理器只需直接引用存放段描述符的CPU寄存器即可。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"分段单元 分段单元(segmentation unit)执行以下操作，将一个逻辑地址转换成相应的线性地址。 先检查段选择符的TI字段，以决定段描述符保存在哪一个描述表中。TI字段指明描述符是在GDT中(在这种情况下，分段单元从gdtr寄存器中得到GDT的线性基地址)还是在激活的LDT中(在这种情况下，分段单元从ldtr寄存器中得到LDT的线性基地址)。 从段选择符的 index 字段计算段描述符的地址，index字段的值乘以8(一个段描述符的大小)，这个结果与gdtr或ldtr寄存器中的内存相加。 把逻辑地址的偏移量与段描述符 Base 字段的值相加就得到了线性地址。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:3:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux 中的分段。 Linux 中使用分段的方式十分有限。分段可以给每个进程分配不同的线性地址空间，而分页可以把同一线性地址空间映射到不同的物理空间。与分段相比，Linux 中倾向采用分页方式，因为: 当所有的进程使用相同的段寄存器值时，内存管理变得更简单，也就是说它们能共享同样的一组线性地址。 Linux 设计目标之一是可以把它移植到绝大多数流行的处理器平台上。然而，RISC体系结构对分段的支持很有限。 2.6 版的 Linux 只有在 80x86 结构下才需要使用分段。 相应的段选择符由宏 __USER_CS, __USER_DS, __KERNEL_CS 和 __KERNEL_DS 分别定义。例如，为了对内存代码段寻址，内核只需要把 __KERNEL_CS 宏产生的值装进 cs 段寄存器即可。 所有段都从 0x00000000 开始，这可以得出另一个重要的结论，就是在 Linux 下逻辑地址与线性地址是一致的，机逻辑地址的偏移量字段的值与相应的线性地址的值总是一致的。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux GDT 在单处理器系统中只有一个 GDT，而在多处理器系统中每个 CPU 对应一个 GDT。所有的 GDT 都存放在 cpu_gdt_table 数组中。以下是 GDT 的布局示意图。每个 GDT 包含 18 个段描述符合 14 个空的，未使用的，或保留的项。 每一个 GDT 中包含 18 个段描述符指向下列的段: 用户态和内核态下的代码段和数据段共 4 个。 任务状态段 (TSS)，每个处理器有 1 个。 1 个包括缺省局部描述符表的段。 3 个局部线程存储。 与高级电源管理 (AMP) 相关的 3 个段。 与支持即插即用 (PnP) 功能的 BIOS 服务程序相关的 5 个段。 被内核用来处理“双重错误”(处理一个异常是可能引发另一个异常，在这个情况下产生的双重错误)异常的特殊 TSS 段。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux LDT 大多数用户态下的 Linux 程序不使用局部描述符表，这样内核就定义了一个缺省的 LDT 供大多数进程共享。缺省的局部描述符表存放在 default_ldt 数组中。 在某些情况下，进程仍然需要创建自己的局部描述符表，这对有些应用程序很有用，如 Wine 程序。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:4:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件中的分页 分页单元(paging unit)把线性地址转换成物理地址。线性地址被分成以固定长度为单位的组，称为页(page)。页内部连续的线性地址被映射到连续的物理地址中。 分页单元把所有的 RAM 分成固定长度的页框 (page frame) (有时叫做物理页)。每一个页框包含一个页 (page)，页就是说一个页框的长度与一个页的长度一致。 把线性地址映射到物理地址的数据结构称为页表 (page table)。页表放在主存中，并在启用分页单元之前必须由内核对页表进行适当的初始化。 从 80386 开始，所有的 80x86 处理器都支持分页，它通过设置 cr0 寄存器的 PG 标志启用。 当 PG=0 时，线性地址就被解释成物理地址。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"常规分页 从 80386 起，Intel 处理器的分页单元处理 4K 的页。 32 位的线性地址被分成 3 个域: Directory (目录) 最高 10 位。 Table (页表) 中间 10 位。 Offset (偏移量) 最低 12 位。 线性地址的转换分两步完成，每一步都基于一种转化表，第一种转换表称为页目录表 (page directory)，第二种转换表称为页表 (page table)。 正在使用的页目录的物理地址存放在控制寄存器 cr0 中。线性地址内的 Directory 字段决定目录中的目录项，而目录项指向适当的页表。地址的 Table 字段依次又决定页表中的表项，而表项含有页所在页框的物理地址。Offset 字段决定页框也的相对位置。由于它是 12 长，故每一页含有 4096 字节的数据。 假设进程需要读线性地址 0x20021406 中的字节。这个地址由分页单元按下面的方法处理: Directory 字段的 0x80 用于选择页目录的第 0x80 目录项，此目录项指向和该进程的页相关的页表。 Table 字段 0x21 用于选择页表的第 0x21 表项，此表项指向包含所需页的页框。 最后，Offset 字段 0x406 用于在目标页框中读偏移量为 0x406 中的字节。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"硬件高速缓存 当今的微处理器时钟频率接近几个 GHz，而动态 RAM 芯片的存取时间是时钟周期的数百倍。这意味着，当从 RAM 中取操作数或向 RAM 中存放结果这样的指令执行时，CPU 可能登台很长时间。 为了缩小 CPU 和 RAM 之间的速度不匹配，引入了硬件高速缓存内存(hardware cache memory)。硬件高速缓存基于著名的局部性原理(locality principle)，该原理既适用程序结构也适用数据结构。 80x86 体系结构中引入了一个叫行 (line) 的新单位。行由几十个连续的字节组成，它们以脉冲突发模式 (burst mode) 在慢速 DRAM 和快速的用来实现高速缓存的片上静态 RAM (SRAM) 之间传送，用来实现高速缓存。 如图，高速缓存单元插在分页单元和主内存之间。它包含一个硬件高速缓存内存 (hardware cache memory) 和一个高速缓存控制器 (cache controller)。高速缓存内存存放内存中真正的行。高速缓存控制器存放一个表项数组，每个表项对应高速缓存内存中的一个行。每个表项有一个标签(tag)和描述高速缓存行状态的几个标志(flag)。这种内存物理地址通常分为3组：最高几位对应标签，中间几位对应高速缓存控制器的子集索引，最低几位对应行内的偏移量。 当访问一个 RAM 存储单元时，CPU 从物理地址中提取出子集的索引号并把子集中所有行的标签与物理地址的高几位相比较。如果发现某一个行的标签与这个物理地址的高位相同，则 CPU 命中一个高速缓存 (cache hit)；否则，高速缓存没有命中 (cache miss)。 对于读操作，控制器从高速缓存行中选择数据并送到 CPU 寄存器。对于写操作，控制器可能采用以下两个基本策略之一: 通写(write-through): 控制器总是既写 RAM 也写高速缓存行，为了提高写操作的效率关闭高速缓存。 回写(write-back): 只更新高速缓存行，不改变 RAM 的内存，提供了更快的效率。 处理器的 cr0 寄存器的 CD 标志位用来启用或禁用高速缓存电路。这个寄存器中的 NW 标志指明高速缓存是使用通写还是回写策略。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:5:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux 中的分页 Linux 采用了一种同时适用于32位和64位的普通分页模型。在 2.6.10 版本之前，Linux 采用三级分页的模型。从 2.6.11 版本开始，采用了四级分页模型: 页全局目录 (Page Global Directory) 页上级目录 (Page Upper Directory) 页中间目录 (Page Middle Directory) 页表 (Page Table) 页全局目录包含若干页上级目录的地址，页上级目录有一次包含若干页中间目录的地址，而页中间目录又包含若干页表的地址。每一个页表项指向一个页框。线性地址因此被分成五个部分。 Linux 的进程处理很大程度上依赖于分页。事实上，线性地址到物理地址的自动转换使下面的设计目标变得可行: 给每一个进程分配一块不同的物理地址空间，这确保了可以有效地防止寻址错误。 区别页(即一组数据)和页框(即主存中的物理地址)的不同。这就允许存放在某个页框中的一个页，然后保存到磁盘上，以后重新装入这同一页是又可以被装载不同的页框中。这就是虚拟内存机制的基本要素。 每一个进程有它自己的页全局目录和自己的页表集。当发生进程切换时，Linux 把 cr3 控制寄存器的内存保存在前一个执行进程的描述符中，然后把下一个要执行进程的描述符的值装入 cr3 寄存器中。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:0","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"线性地址字段 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:1","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"页表处理 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:2","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"物理内存布局 在初始化阶段，内核必须建立一个物理地址映射来指定哪些物理地址范围对内核可用而哪些不可用。 内核将下列页框记为保留: 在不可用的物理地址范围内的页框。 含有内核代码和已初始化的数据结构的页框。 从 0x07ff0000 到 0x07ff2fff 的物理地址范围中存有加电自检(POST)阶段由BIOS写入的系统硬件设备信息。在初始化阶段，内核把这些信息拷贝到一个合适的内核数据结构中，然后认为这些页框是可用的。相反，从 0x07ff3000 到 0x07ffffff 的物理地址范围被映射到硬件设备的 ROM 芯片。从 0xffff0000 开始的物理地址范围标记为保留，因为它由硬件地址映射到 BIOS 的 ROM 芯片。 Linux 用 PC 体系结构未保留的页框来动态存放所分配的页。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:3","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"进程页表 进程的线性地址空间分成两部分: 从 0x00000000 到 0xbfffffff 的线性地址，无论进程运行在用户态还是内核态都可以寻址。 从 0xc0000000 到 0xffffffff 的线性地址，只有内核态的进程才能寻址。 当进程运行在用户态时，它产生的线性地址小于 0xc0000000；当进程运行在内核态时，它执行内核代码，所产生的地址大于等于 0xc0000000。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:4","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"内核页表 内核维持着一组自己使用的页表，驻留在主内核页全局目录(master kernel Page Global Directory)中。 内核如何初始化自己的页表: 内核创建一个有限的地址空间，包括内核的代码段和数据段、初始页表和用于存放动态数据结构的128KB大小的空间。这个最小限度的地址空间仅够将内核装入RAM和对其初始化的数据结构。 内核充分利用剩余的RAM并适当地建立分页表。 建立分页表的详细步骤: 临时页全局目录放在 swapper_pg_dir 变量中，临时页表在 pg0 变量出开始存放，紧接在内核未初始化的数据段后面。内核在初始化的第一阶段，可以通过与物理地址相同的线性地址或者通过从 0xc0000000 开始的 8MB 线性地址对 RAM 的前 8MB 进行寻址。 内核通过把 swapper_pg_dir 所有项都填充为0来创建期望的映射，0、1、0x300(768)和0x301(769)除外，它们的初始化如下： 0 项和 0x300 项的地址字段置为 pg0 的物理地址，而 1 项和 0x301 项的地址字段置为紧随 pg0 后的页框的物理地址。 把这四个项中的 Present、Read/Write 和 User/Supervisor 标志置零。 把这四个项中的 Accessed、Dirty、PCD、PWD 和 Page Size 标志请0。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:5","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"固定映射的线性地址 我们看到内核线性地址第四个GB的初始化部分映射系统的物理内存。但是，至少128MB的线性地址总是留作它用，因为内核使用这些线性地址实现非连续内存分配和固定映射的线性地址。 固定映射的线性地址(fix-mapped linear address)基本上是一种类似于 0xffffc000 这样的常量线性地址，其对应的物理地址不必等于线性地址减去 0xc000000。内核使用固定映射的线性地址来代替指针变量，因为这些指针变量的值从不改变。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E5%AD%98/:6:6","tags":null,"title":"Linux内存","uri":"/linux%E5%86%85%E5%AD%98/"},{"categories":null,"content":"Linux内核同步 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:0:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"内核抢占 抢占内核的主要特点是: 一个在内核态运行的进程，可能在执行内核函数期间被另外一个进程取代。 用实例来说明抢占内核和非抢占内核的区别: 在进程A执行异常处理程序时，一个具有较高优先级的进程B变为可执行状态。这种情况是有可能出现的，例如，发生了中断请求而且相应的处理程序唤醒了进程B。如果内核是抢占的，就会发生强制性进程切换，让进程B取代进程A。异常处理程序的执行被暂停，直到调度程序再次选择进程A时才恢复它的执行。相反，如果内核是非抢占的，在进程A完成异常处理程序的执行之前，是不会发生进程切换的，除非进程A自动放弃CPU。 一个执行异常处理程序的进程已经用完了它的时间配额，如果内核是抢占的，进程可能会立即被取代，但如果内核是非抢占的，进程继续运行直到它执行完异常处理程序或自动放弃CPU。 使内核可抢占的目的是减少用户态进程的分派延迟(dispatch letency)，即从进程变为可执行状态到它实际开始运行之间的时间间隔。 只有当内核正在执行异常处理程序(尤其是系统调用)，而且内核抢占没有显式地禁用时，才可能抢占内核。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:1:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"同步原语 技术 说明 适用范围 每CPU变量 在CPU之间复制数据结构 所有CPU 原子操作 对一个计数器原子地\"读-修改-写\"的指令 所有CPU 内存屏障 避免指令重新排序 本地CPU或所有CPU 自旋锁 加锁时忙等 所有CPU 信号量 加锁时阻塞等待(睡眠) 所有CPU 顺序锁 基于访问计数器的锁 所有CPU 本地中断的禁止 禁止单个CPU上的中断处理 本地CPU 本地软中断的禁止 禁止单个CPU上的可延迟函数处理 本地CPU 读-拷贝-更新(RCU) 通过指正而不是锁来访问共享数据结构 所有CPU ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:0","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"每CPU变量 最简单也是最重要的同步技术包括把内核变量声明为每CPU变量(per-cpu variable)。每CPU变量主要是数据结构的数组变量主要是技术结构的数组，系统的每个CPU对应数组的一个元素。 虽然每CPU变量为来自不同CPU的并发访问提供保护，但对来自异步函数(中断处理程序和可延迟函数)的访问不提供保护，在这种情况下需要另外的同步原语。 此外，在单处理器和多处理器系统中，内核抢占都可能是每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:1","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"原子操作 通过原子操作指令完成。 80x86 指令: 进行零次或一次对齐内存访问的汇编指令是原子的。 如果在读操作之后，写操作之前没有其他处理器占用内存总线，那么从内存中读取数据，更新数组并把更新后数组写回内存中的这些\"读-修改-写\"汇编语言指令(例如inc或dec)是原子的。当然，在单处理器系统中，永远都不会发生内存总线窃用的情况。 操作吗前缀是 lock 字节(0xf0)的\"读-修改-写\"汇编语言指令即使在多处理器系统中也是原子的。当控制单元检测到这个前缀时，就\"锁定\"内存总线，知道这条指令执行完成为止。因此，当加锁的指令执行时，其他处理器不能访问这个内存单元。 操作码前缀是一个rep字节(0xf2,0xf3)的汇编语言执行不是原子的，这条指令强行让控制单元多次重复执行相同的指令。控制单元在执行新的循环之前要检查挂起的中断。 Linux 内核提供了一个专门的 atomic_t 类型(一个原子访问计数器)和一些专门的函数和宏，这些函数和宏作用于 atomic_t 类型的变量，并当作单独的、原子的汇编语言指令来使用。在多处理器系统中，每条这样的指令都有一个 lock 字节的前缀。 另一类原子函数操作作用于位掩码 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:2","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"优化和内存屏障 当使用优化的编译器时，编译器可能重新安排汇编语言指令已使寄存器以最优的方式使用。此外，现代CPU通常并行地执行若干条指令，且可能重新安排内存访问。然而，当处理同步时，必须避免指令重新排序。 优化屏障(optimization barrier) 原语保证编译程序不会混淆放在原语操作之前的汇编语言指令和放在原语操作之后的汇编语言指令，这些汇编语言指令在C中都有对应的语句。在Linux中，优化屏障就是 barrier() 宏，它展开 asm volatile(\"\":::\"memory\") 。指令 asm 告诉编译程序要插入汇编语言片段(这种情况下为空)。volatile 关键字禁止编译器把asm指令与程序中的其他指令重新组合。memory 关键字强制编译器假定RAM中的所有内存单元已经被汇编语言指令修改。 内存屏障(memory barrier)原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。因此，内存屏障类似于防火墙，让任何汇编语言指令都不能通过。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:3","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"自旋锁 自旋锁(spin lock)是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁\"开着\"，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径\"锁着\"，就在周围\"旋转\"，反复执行一条紧凑的循环指令，直到锁被释放。 自旋锁的循环指令表示\"忙等\"。即使等待的内核控制路径无事可做，它也在CPU上保持运行。不过，自旋锁通常非常方便，因为很多内核资源只锁1毫秒的时间片段；所以说，释放CPU和随后有获得CPU都不会消耗多少时间。 一般来说，由自旋锁保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这中锁本身并不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。需要注意的是，自旋转忙等期间，内核抢占还是有效的，因此，等待自旋锁释放的进程有可能被更高优先级的进程替代。 读/写自旋锁 读/写自旋锁的引入是为了增加是内核的并发能力。只要没有内核控制路径对数据结构进行修改，读/写自旋锁就允许多个内核控制路径同时读同一数据结构。如果一个内核控制路径想对这个结构进行写操作，那么它必须首先获取读/写锁的写锁，写锁授权独占访问这个资源。当然，允许对数据结构并发读可以提高系统性能。 顺序锁 Linux 2.6 中引入顺序锁(seqlock)，它与读/写自旋锁非常相似，只是它为写者赋予了较高的优先级；事实上，即使在读者正在读的时候，也允许写者继续运行。这种策略的好处是写者永远不会等待(除非另外一个写者正在写)，缺点是有些时候读者不得不反复多次读相同的数据直到它获得有效的副本。 每个读者都必须在读数据前后两次读顺序计数器，并检查零次读到的值是否相同，如果不相同，说明新的写者已经开始写并增加了顺序计数器，因此暗示读者刚读到的数据是无效的。 一般来说，必须在满足下述条件是才能使用顺序锁: 被保护的数据结构不包括被写者修改和被读者间接引用的指针。 读者的临界代码没有副作用。 读-拷贝-更新(RCU) 读-拷贝-更新(RCU)是为了保护在多数情况下被多个CPU读的数据结构而设计的零一种同步技术。RCU允许多个读者和写者并发执行(相对于只允许一个写者执行的顺序锁有了改进)。而且，RCU是不使用锁的，就是说，它不使用被所有CPU共享的锁或计数器，在这一点上与读/写自旋锁和顺序锁(由于高速缓存行窃用和失效有很高的开销)相比，RCU 具有更大的优势。 RCU 是如何不是用共享数据结构而令人惊讶地实现多个CPU同步呢？其关键的思想包括限制RCU的范围，如下所述: RCU 只保护被动态分配并通过指针引用的数据结构。 在被 RCU 保护的临界区中，任何内核控制路径都不能睡眠。 当内核控制路径要读取 RCU 保护的数据结构时，执行 rcu_read_lock()，它等同于 preempt_disable()。接下来，读者间接引用该数据结构指针所对应的内存单元并开始读这个数据结构。正如在前面所强调的，读者在完成对数据结构的读操作之前，是不能睡眠的。用等同于 preempt_enable() 的宏 rcu_read_unlock() 标记临界区的结束。 由于读者几乎不做任何事情来防止竞争条件的出现，所以写者不得不做得更多一些。事实上，当写者要更新数据结构是，它间接引用指针并生成整个数据结构的副本。接下来，写者修改这个副本。一旦修改完毕，写者改变指向数据结构的指针，以使它指向被修改后的副本。由于修改指针值的操作是一个原子操作，所以旧副本和新副本对每个读者或写者都是可见的，在数据结构中不会出现数据崩溃。尽管如此，还需要内存屏障来保证: 只有在数据结构被修改之后，已更新的指针对其他CPU才是可见的，如果把自旋锁与RCU结合起来以禁止写者的并发执行，就隐含地引入了这样的内存屏障。 然而，使用 RCU 技术的真正困难在于: 写者修改指针时不能立即释放数据结构的就副本。实际上，写者开始修改时，正在访问数据结构的读者可能还在读副本。只有在CPU上所有(潜在的)读者都执行完宏 rcu_read_unlock() 之后，才可以释放就副本。内核要求每个潜在的读者在下面的操作之前执行 rcu_read_unlock() 宏: CPU 执行进程切换 CPU 开始在用户态执行 CPU 执行空循环 对上述每种情况，我们说CPU已经过了静止状态(quiescent state)。 写者调用函数 call_rcu() 来释放数据结构的就副本。当所有的 CPU 都通过静止状态之后，call_rcu() 接受 rcu_head 描述符的地址和将要调用的回调函数的地址作为参数。一旦回调函数被执行，它通常释放数据结构的就副本。 函数 call_rcu() 把回调函数和其参数的地址存放在 rcu_head 描述符中，然后把描述符插入回调函数的每个 CPU (per-CPU) 链表中。内核每经过一个时钟滴答就周期性地检查本地CPU是否进过了一个静止状态。如果所有CPU都经过了静止状态，本地 tasklet (它的描述符存放在每CPU变量 rcu_tasklet 中)就执行链表中的所有回调函数。 RCU 是 Linux 2.6 中新加的功能，用在网络层和虚拟文件系统中。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:4","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"信号量 Linux 提供两种信号量 : 内核信号量，由内核控制路径使用。 System V IPC 信号量，由用户态进程使用。 内核信号量类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。然而，当内核控制路径试图获取内核信号量所保护的忙资源时，相应的进程被挂起。只有在资源被释放时，进程才再次变为可运行的。因此，只有可以睡眠的函数才能获取内核信号量；中断处理程序和可延迟函数都不能使用内核信号量。 内核信号量是 struct semaphore 类型的对象，包含下面这些字段: count: 存放 atomic_t 类型的一个值。如果该值大于 0，那么资源就是空闲的，也就是说，该资源现在可以使用。相反，如果 count 等于0。那么信号量是忙的，但没有进程等待这个被保护的资源。最后，如果 count 为负数，则资源时不可用的，并至少有一个进程等待资源。 wait: 存放等待队列链表的地址，当前等待资源的所有睡眠进程都放在这个链表中。当然，如果 count 大于或等于 0，等待队列就为空。 sleepers: 存放一个标志，表示是否有一些进程在信号量上睡眠。 可以用 init_MUTEX() 和 init_MUTEX_LOCKED() 函数来初始化互斥访问所需的信号量。 当进程希望释放内核信号量锁时，就调用 up() 函数。相反，当进程希望获取内核信号获取内核信号量锁时，就调用 down() 函数。 读/写信号量类似于\"读/写自旋锁\"，不同的是：在信号量再次变为打开之前，等待进程挂起而不是自旋。 很多内核控制路径为读可以并发地获取读/写信号量。但是，任何写者内核控制路径必须有被保护资源的互斥访问。因此，只有在没有内核控制路径为读访问或写访问持有信号量时，才可以为写获取信号量。读/写信号量可以提供内核中的并发度，并改善了这个系统的性能。 内核以严格的FIFO顺序处理等待读/写信号量的所有进程。如果读者或写者进程发现信号量关闭，这些进程就被插入到信号量等待队列链表的末尾。当信号量被释放时，就检查处于等待队列链表第一个位置的进程。第一个进程常被唤醒。如果是一个写者进程，等待队列上其他的进程就继续睡眠。如果是一个读者进程，那么紧跟第一个进程的其他所有读者进程也被唤醒并获得锁。不过，在写者进程之后排队的读者进程继续睡眠。 每个读/写信号量都是由 rw_semaphore 结构描述的，它包含下列字段: count: 存放两个16位计数器。其中最高16位计数器以二进制补码形式存放非等待写者进程的总数(0或1)和等待的写内核控制路径数。最低16位计数器存放非等待的读者和写者的总数。 wait_list: 指向等待进程的链表。链表中的每个元素多是一个 rwsem_waiter 结构，该结构包含一个指针和一个标志，指针指向睡眠进程的描述符，标志表示进程是为读需要信号量还是为需要信号量。 wait_lock: 一个自旋锁，用户保护等待队列链表和 rw_semphore 结构本身。 down_read() 和 down_write() 函数分别为读或写获取读/写信号量。同样，up_read() 和 up_write() 函数为读或写释放以前获取的读/写信号量。 down_read_trylock() 和 down_write_trylock() 函数分别类似于 down_read() 和 down_write() 函数，但是，在信号量忙的情况下，它们不阻塞进程。最后，函数 downgrade_write() 自动把写锁转换成读锁。 ","date":"2021-12-03","objectID":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/:2:5","tags":null,"title":"Linux内核同步","uri":"/linux%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5/"},{"categories":null,"content":"Linux进程 进程时程序执行的一个实例，可以把它看作充分描述程序已经执行到何种程度的数据结构的汇集。在 Linux 源代码中，常把进程称为任务(task)或线程(thread)。 Linux 使用轻量级进程(lightweight process)对多线程应用提供更好的支持。两个轻量级进程基本上可以共享一些资源，诸如地址空间、打开的文件等等。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:0:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程描述符 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程状态 进程状态符中的 state 字段描述了进程所处的状态: 可运行状态 (TASK_RUNNING) : 进程要么在 CPU 上执行，要么准备执行。 可中断的等待状态 (TASK_INTERRUPTIBLE) : 进程被挂起 (睡眠)，直到某个条件表为真。产生一个硬件中断，释放进程正等待的系统资源，或传递一个信号都是可以唤醒进程的条件(把进程的状态放回到 TASK_RUNNING)。 不可中断的等待状态 (TASK_UNINTERRUPTIBLE) : 与可中断的等待状态类似，但有一个例外，把信号传递到睡眠不能改变它的状态。这种状态很少用到，但在一些特定的情况下(进程必须等待，直到一个不能被中断的事件发生)，这种状态是很有用的。例如，当进程打开一个设备文件，其相应的设备驱动程序开始探测相应的硬件设备时会用到这种状态。探测完成以前，设备驱动程序不能被中断，否则，硬件设备会处于不可预知的状态。 暂定状态 (TASK_STOPPED) : 进程的执行被暂停。当进程接收到 SIGSTOP、SIGTSTP、SIGTTIN 或 STGTTOU 信号，进程暂停状态。 跟踪状态 (TASK_TRACED) : 进程的执行已由 debugger 程序暂停。当一个进程被另一个进程监控时(例如 debugger 执行 ptrace() 系统调用监控一个测试程序)，任何信号都可以把这个进程置于 TASK_TRACED 状态。 还有两个进程状态是既可以存放在进程描述符的 state 字段中，也可以存放在 exit_state 字段中。从这两个字段的名称可以看出，只有当进程的执行被终止时，进程的状态才会变为这两种状态中的一种: 僵死状态 (EXIT_ZOMBIE) : 进程的执行被终止，但是，父进程还没有发布 wait4() 或 waitpid() 系统调用来返回有关死亡进程的信息。发布 wait() 类系统调用前，内核不能丢弃包含在死进程描述符中的数据，因为父进程可能还需要它。 僵死撤销状态 (EXIT_DEAD) : 最终状态：由于父进程刚发出 wait4() 或 waitpid() 系统调用，因而进程由系统删除。为了防止其他执行线程在同一个进程上也执行 wait() 类系统调用，而把进程的状态由 (EXIT_ZOMBIE) 状态改为僵死撤销状态 (EXIT_DEAD)。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"标识一个进程 标识一个进程有两种方式: 进程描述符指针: 进程和进程描述符之间有非常严格的一一对应关系，这使得用32位进程描述符地址标识进程成为一种方便的方式。 PID: PID 存放在进程描述符的 pid 字段中。 PID 被顺序编号，新创建进程的 PID 通常是前一个进程的 PID 加1。PID 存在上限，当内核使用的 PID 达到这个上限值的时候就必须开始循环使用已闲置的 PID 号。 PID 的默认最大值是32767(PID_MAX_DEFAULT-1)。可以通过修改 /proc/sys/kernel/pid_max 文件改变 PID 上限值。 内核通过管理一个 pidmap-array 位图来表示当前已分配的 PID 号和闲置的 PID 号。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:1:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程的切换 为了控制进程的执行，内核必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。这个中行为被称为进程切换 (process switch)、任务切换 (task switch) 或上下文切换 (context switch)。 所有进程共享 CPU 寄存器，所以在恢复一个进程的执行之前，必须确保每个寄存器装入了挂起进程时的值。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"硬件上下文 进程恢复执行前必须装入寄存器的一组数据称为硬件上下文 (hardware context)。在 Linux 中，进程硬件上下文的一部分存放在 TSS 段，而剩余部分存放在内核态堆栈中。 进程切换只发生在内核态，在执行进程切换之前，用户态进程使用的所有寄存器内容都已保存在内核态堆栈上，这也包括 ss 和 esp 这对寄存器的内容 (存储用户态堆栈指针的地址)。 Linux 使用软件切换上下文 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"任务状态段 80x86 体系结构包括了一个特殊的但类型，叫任务状态段 (Task State Segment, TSS) 来存放硬件上下文。Linux 不使用硬件上下文切换，但是强制为每个不同CPU创建一个TSS。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"执行进程切换 进程切换的核心点在于 scheduler() 函数。 从本质上说，每个进程切换由两步组成: 切换页全局目录以安装一个新的地址空间。 切换内核态堆栈和硬件上下文，因为硬件上下文提供了内核执行新进程所需要的所有信息，包含 CPU 寄存器 (重点在 switch_to() 函数)。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:2:3","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"创建进程 Linux 中创建一个进程的方式: fork() -\u003e sys_fork() -\u003e do_fork() -\u003e copy_process() ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"内核进程 传统的 Unix 系统把一些重要的任务委托给周期性执行的进程，这些进程只运行在内核态，称作内核线程(kernel thread)，内核线程不受不必要的用户态上下文的拖累。内核线程和普通进程的区别: 内核线程只运行在内核态，而普通进程既可以运行在内核态，也可以运行在用户态。 因为内核线程只运行在内核态，它们只使用大于 PAGE_OFFSET 的线性地址空间。另一方面，不管在用户态还是在内核态，普通进程可以用 4GB 的线程地址空间。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程 0 所有进程的祖先叫做进程0，idle 进程或 swapper 进程，它是在 Linux 的初始化阶段从无到有创建的一个内核线程。start_kernel() 函数初始化内核需要的所有数据结构，激活中断，创建另一个叫进程1的内核线程(init进程)。 新创建的内核线程的 PID 为1，并与进程0共享每进程所有的内核数据结构。此外，当调度程序选择到它时，init 进程开始执行 init() 函数。 创建init进程后，进程0执行 cpu_idle() 函数，该函数本质上是在开中断的情况下重复执行 hlt 汇编语言指令。只有当没有进程处于 TASK_RUNNING 状态是，调度程序才选择进程0。 在多处理器系统中，每个 CPU 都有一个进程 0。只要打开机器电源，计算机的 BIOS 就启动某一个 CPU，同时禁用其他 CPU。运行在 CPU 0 上的 swapper 进程初始化内核数据结构，然后激活其他的CPU，并通过 copy_process() 函数创建另外的 swapper 进程，把 0 传递给新创建的 swapper 进程作为它们的新 PID。此外，内核把适当的 CPU 索引赋给内核所创建的每个进程的 thread_info 描述符的 cpu 字段。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程 1 由进程0创建的内核线程执行 init() 函数，init() 依次完成内核初始化。init() 调用 execve() 系统调用装入可执行程序 init。结果，init 内核线程变为一个普通进程，且拥有自己的每进程(per-process)内核数据结构。在系统关闭之前，init 进程一直存活，因为它创建和监控在操作系统外层执行的所有进程的活动。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:3","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"其他内核线程 keventd(也被称为事件): 执行 keventd_wq 工作队列中的函数。 kapmd: 处理与高级电源管理(APM)相关的事件。 kswapd: 执行内存回收。 pdflush: 刷新 “脏” 缓冲区中的内容到磁盘回收内存。 blockd: 执行 kblockd_workqueue 工作队列中的函数。 ksoftirqd: 运行 tasklet; 系统中每个 CPU 都有这样一个内核线程。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:3:4","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"撤销进程 进程终止的一般方式是调用 exit() 库函数。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:0","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程终止 终止用户态应用的系统调用: exit_group() 系统调用，它终止整个线程组，即整个基于多线程的应用。do_group_exit() 是实现这个系统调用的主要内核函数。 exit() 系统调用，它终止某一个线程，而不管该线程所属线程组中的所有其他进程。do_exit() 是实现这个系统调用的主要内核函数。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:1","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"进程删除 进程通过调用 wait() 类函数来检查子进程是否终止，在子进程已终止，但是父进程还未接收到 wait() 类函数的通知之前，子进程处于僵死状态。这时系统资源已经释放，但还占用进程描述符。 如果父进程在接收到子进程前就终止，子进程就会被init进程接管。 ","date":"2021-12-03","objectID":"/linux%E8%BF%9B%E7%A8%8B/:4:2","tags":null,"title":"Linux进程","uri":"/linux%E8%BF%9B%E7%A8%8B/"},{"categories":null,"content":"Nginx多组代理配置 一、需求 具体实现以下功能：使用 nginx 作为对外的服务机器，让客户端通过访问 nginx 所在的IP+端口的方式能访问内部多个系统，这样一来通过对单台机器作访问控制就可以保证内部系统的访问安全。实现思路如下：在对外的机器上部署 nginx 服务，通过 nginx 虚拟机功能和代理功能相结合实现多组代理。具体场景如下： 代理服务器 代理服务 nginx 192.168.10.10:8080 192.168.10.11:8080 nginx 192.168.10.10:8081 192.168.10.11:9000 二、环境 测试环境如下： 代理服务器：ip 192.168.10.10；系统 CentOS7 ;  需要代理的服务：192.168.10.11:8080 nginx ；192.168.10.11:9000 tomcat 三、配置代理 假如有两个服务需要配置代理，一个 web，一个 tomcat。web 运行在 192.168.10.11:8080 tomcat 运行在 192.168.10.11:9000 现在配置 nginx 代理。 1.安装 nginx先在代理服务器上安装 nginx，使用命令： $ yum install -y nginx 安装成功后就可以尝试启动 nginx 服务器： $ systemctl start nginx 启动服务成功后，nginx 就运行在 80 端口。 2.修改配置文件安装nginx就可以修改配置文件，配置文件的默认路径为  $ ll /etc/nginx/nginx.conf -rw-r--r-- 1 root root 1822 Nov 24 19:30 /etc/nginx/nginx.conf 修改 nginx.conf 如下 # 系统用户 user nginx; # 工作进程数，配置高的机器可以适当增加 worker_processes 4; # 错误日志 error_log /var/log/nginx/error.log; # pid 文件存放目录 pid /run/nginx.pid; events { # linux 使用 epoll 事件机制 use epoll; # 连接数 worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # 配置虚拟机，在该目录下配置多个配置文件对应多台需要代理的机器 include /etc/nginx/conf.d/*.conf; # 配置 https # Settings for a TLS enabled server. # # server { # listen 443 ssl http2 default_server; # listen [::]:443 ssl http2 default_server; # server_name _; # root /usr/share/nginx/html; # # ssl_certificate \"/etc/pki/nginx/server.crt\"; # ssl_certificate_key \"/etc/pki/nginx/private/server.key\"; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 10m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # location / { # } # # error_page 404 /404.html; # location = /40x.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } # } } 注意 23 行的配置：include /etc/nginx/conf.d/*.conf; 这个目录下就是要存放代理的配置文件。一般这个文件默认是存在的，如果目录不存在，就创建并修改权限。 $ mkdir /etc/nginx/conf.d $ chmod 755 /etc/nginx/conf.d 3.配置代理文件在这个目录下存放代理服务的文件，最好一个代理对应一个配置文件。我们之前需求上需要代理的服务是两个，直接创建两个代理文件，并修改 # /etc/nginx/conf.d/nginx.conf # 代理的节点 # upstream \u003c代理名称 唯一\u003e upstream nginx_server { # 代理的ip:port,可添加多个ip地址就行负载均衡 server 192.168.10.11:8080; } server { # 监听的地址和端口 # 对应一个代理一个端口 listen 192.168.10.10:8080; # 对外的域名 server_name aaa.test.com; location / { # 代理配置，名称和以上的代理名称对应 proxy_pass http://nginx_server; # 配置使用真实的地址访问，如果不配置此项会导致代理tomcat服务器 400 错误 proxy_set_header Host $host; } } # cat /etc/nginx/conf.d/tomcat.conf upstream tomcat_server { server 192.168.10.11:9000; } server { listen 192.168.10.10:8081; server_name bbb.test.com; location / { proxy_pass http://tomcat_server; proxy_set_header Host $host; } } 修改并保存后，使用 nginx 命令来验证文件的语法： $ # nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 之后就可以重启 nginx 服务 $ systemctl restart nginx $ netstat -tnlp | grep nginx tcp 0 0 192.168.10.10:8080 0.0.0.0:* LISTEN 11643/nginx: master tcp 0 0 192.168.10.10:8081 0.0.0.0:* LISTEN 11643/nginx: master 可以看到成功绑定两个端口，代理两个服务。通过浏览器访问8080和8081![image.png] 到这里配置就完成了。如果需要再代理，在 /etc/nginx/conf.d 目录下再添加相应的配置文件就可以。如果没有访问成功，请检查各种防火墙和安全策略。 ","date":"2021-12-03","objectID":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:0:0","tags":null,"title":"Nginx多组代理配置","uri":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"postgresql 实战一：安装和使用 安装 这里直接使用 docker 安装 postgresql-13 docker run --name postgresql13 -e POSTGRES_PASSWORD=123456 -p 54322:5432 -d postgres:13 安装成功后会绑定主机端口 54322。直接进入 postgresql13 容器，使用 pgsql。 [root@localhost ~]# docker exec -it 3e3b03e3 /bin/bash root@3e3b03e3e442:/# psql -h localhost -p 5432 -U postgres psql (13.0 (Debian 13.0-1.pgdg100+1)) Type \"help\" for help. postgres=# psql 是 pgsql 的客户端命令，使用参数如下： -h：指定 pgsql 的地址 -p：指定 pgsql 的绑定端口 -U：指定登录的用户名，默认为 postgres。后面可以紧接 “database”，直接进入指定的数据库。 数据库的操作 postgresql 支持的数据库操作有 增、删、查、改 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:0:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"创建数据库 创建数据库的命令为： create database \u003cdatabasename\u003e [encoding 'UTF-8']  postgres=#createdatabasetestencoding'UTF-8';CREATEDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:1:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查询数据库 查询数据库的命令有两种：第一种是 \\l ，只能在 psql 中使用： postgres=#\\lListofdatabasesName|Owner|Encoding|Collate|Ctype|Accessprivileges-----------+----------+----------+------------+------------+----------------------- postgres|postgres|UTF8|en_US.utf8|en_US.utf8|template0|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestemplate1|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestest|postgres|UTF8|en_US.utf8|en_US.utf8|testdb|postgres|UTF8|en_US.utf8|en_US.utf8|(5rows) 另一种命令为： select * from pg_databse  postgres=#selectdatnamefrompg_database;datname----------- postgrestemplate1template0testdbtest(5rows) ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:2:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"修改数据库 修改数据库使用关键字 alter  postgres=#alterdatabasetestxrenametotest;ALTERDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:3:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"删除数据库 postgres=#dropdatabasetest;DROPDATABASE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:4:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"选择数据库 选择数据和切换数据的命令是相同的，使用命令 \\c databasename  postgres=#\\ctest;Youarenowconnectedtodatabase\"test\"asuser\"postgres\".test=#\\cpostgres;Youarenowconnectedtodatabase\"postgres\"asuser\"postgres\". 表的操作 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:5:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"创建表 创建 postgresql 表的语法为： CREATETABLEtable_name(column1datatype,column2datatype,column3datatype,.....columnNdatatype,PRIMARYKEY(oneormorecolumns)); 创建一张名为 COMPANY 的表： testdb=#CREATETABLECOMPANY(IDINTPRIMARYKEYNOTNULL,NAMETEXTNOTNULL,AGEINTNOTNULL,ADDRESSCHAR(50),SALARYREAL);CREATETABLE ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:6:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查询表 查询表使用 \\d ： testdb=#\\dListofrelationsSchema|Name|Type|Owner--------+---------+-------+---------- public|company|table|postgrespublic|person|table|postgres 但是这种方式只能在 psql 命令中中使用，还可以使用 select 命令： testdb=#select*frompg_tableswhereschemaname='public';schemaname|tablename|tableowner|tablespace|hasindexes|hasrules|hastriggers|rowsecurity------------+-----------+------------+------------+------------+----------+-------------+------------- public|person|postgres||f|f|f|fpublic|company|postgres||t|f|f|f(2rows ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:7:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"查看表结构 查看表结构也是使用 \\d 命令： Table\"public.company\"Column|Type|Collation|Nullable|Default---------+---------------+-----------+----------+--------- id|integer||notnull|name|text||notnull|age|integer||notnull|address|character(50)|||salary|real|||Indexes:\"company_pkey\"PRIMARYKEY,btree(id) 也可以使用 sql 实现： testdb=#SELECTa.attnum,a.attnameASfield,t.typnameAStype,a.attlenASlength,a.atttypmodASlengthvar,a.attnotnullASnotnull,b.descriptionAScommentFROMpg_classc,pg_attributeaLEFTJOINpg_descriptionbONa.attrelid=b.objoidANDa.attnum=b.objsubid,pg_typetWHEREc.relname='company'ANDa.attnum\u003e0ANDa.attrelid=c.oidANDa.atttypid=t.oidORDERBYa.attnum;attnum|field|type|length|lengthvar|notnull|comment--------+---------+--------+--------+-----------+---------+--------- 1|id|int4|4|-1|t|2|name|text|-1|-1|t|3|age|int4|4|-1|t|4|address|bpchar|-1|54|f|5|salary|float4|4|-1|f|(5rows) ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:8:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"修改表结构 ALTER TABLE 语句用于添加、修改、删除表中的列：在现有表中添加列： ALTERTABLEtable_nameADDcolumn_namedatatype; 在现有表中删除列： ALTERTABLEtable_nameDROPCOLUMNcolume_name; 在现有表中修改字段类型： ALTERTABLEtable_nameALTERCOLUMNcolume_nameTYPEdatatype; 向表中的列添加 NOT NULL 约束： ALTERTABLEtable_nameMODIFYcolume_namedatatypeNOTNULL; 添加约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK  ALTERTABLEtable_nameADDCONSTRAINTMyUniqueConstraintUNIQUE(colume_name1,colume_name2...); 删除约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK ALTERTABLEtable_nameDROPCONSTRAINTMyUniqueConstraintUNIQUE; ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:9:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"删除表 DROP 用于删除表： testdb=#droptablecompany;DROPTABLE JSON 类型的支持 PostgreSQL 支持存储 JSON 类型的数据，提供了两种类型： json 和 jsonb 。 json数据类型存储输入文本的精准拷贝，处理函数必须在每 次执行时必须重新解析该数据。 jsonb数据被存储在一种分解好的 二进制格式中，它在输入时要稍慢一些，因为需要做附加的转换。但是 jsonb在处理时要快很多，因为不需要解析。jsonb也支持索引，jsonb不保留空格、不 保留对象键的顺序并且不保留重复的对象键。 关于 JSONB 的详细信息可以参考 JSON 类型，这里只介绍 JSONB 类型数据的使用。 创建 JSONB 类型的表 CREATETABLEposts(IDINTPRIMARYKEYNOTNULL,specJSONB); 插入数据，使用的关键字为 INSERT INTO 。 -- 插入第一条数据 insertintopostsvalues(1,'{\"name\": \"first posts\", \"content\": \"This is a simple post\", \"author\": \"a\", \"time\": \"2020/10/15\"}');-- 插入第二条数据 insertintopostsvalues(2,'{\"name\": \"jsonb\", \"content\": \"jsonb is PostgreSQL inner type\", \"author\": \"bb\", \"time\": \"2020/10/12\", \"tag\": [\"database\", \"PgSQL\"]}'); 添加 key/value 索引： -- 给所有 key/values 添加索引 CREATEINDEXidx_posts_specONpostsUSINGgin(spec);-- 给指定的 key/values 添加索引 CREATEINDEXidx_posts_spec_authorONpostsUSINGgin((spec-\u003e'author')); 数据查询 SELECT ，全表查询： testdb=#select*fromposts;id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 1|{\"name\":\"first posts\",\"time\":\"2020/10/15\",\"author\":\"a\",\"content\":\"This is a simple post\"}2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(2rows) 查询 JSONB 内的数据： -- spec-\u003e'name' 输出的数据格式为原生格式 testdb=#selectid,spec-\u003e'name'fromposts;id|?column?----+--------------- 1|\"first posts\"2|\"jsonb\"(2rows)-- spec-\u003e\u003e'name' 输出格式为 TEXT testdb=#selectid,spec-\u003e\u003e'name'fromposts;id|?column?----+------------- 1|firstposts2|jsonb(2rows)testdb=#insertintopostsvalues(3,'{\"name\": \"other\", \"content\": \"other data\", \"author\": \"bb\", \"other\": {\"name\": \"other\"}}');INSERT01-- 使用 -\u003e 操作符查询多级 json 格式的数据 testdb=#selectid,spec-\u003e'name'asspec_name,spec-\u003e'other'-\u003e'name'asspec_other_namefromposts;id|spec_name|spec_other_name----+---------------+----------------- 1|\"first posts\"|2|\"jsonb\"|3|\"other\"|\"other\"-- 使用 ? 查询 key 是否存在 testdb=#selectid,specfrompostswherespec?'tag';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(1row)-- 使用 ? 查询 values testdb=#selectid,specfrompostswherespec-\u003e'author'?'bb';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(2rows)-- 使用 @\u003e 来精确查询 testdb=#selectid,specfrompostswherespec@\u003e'{\"other\": {\"name\": \"other\"}}'::jsonb;id|spec----+---------------------------------------------------------------------------------------- 3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(1row) JSONB 支持的其他函数和操作符可以参考 这里。 ","date":"2021-12-03","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:10:0","tags":null,"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":null,"content":"Windows Bat总结 最近项目需要再 windows 上做开发，而且一些自动化的处理需要使用 windows 的的脚本。所以做些记录，防止遗忘。 基本的语法 首先从基础开始吧，之前都是使用 linux bash 的。可以说 windows bat 脚本和 linux bash 脚本还是有很多区别的。 ","date":"2021-12-03","objectID":"/bat/:0:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"设置变量 变量设置使用的命令为set。 set a=\"hello world\" echo %a% 从上面的脚本中可以知道，使用set来设置变量，语法为set var=\u003c值\u003e。如果要引用这个变量的话就使用%var%。 注：bat 脚本不能像 bash 中一样设置临时变量，只用将变量设置为环境变量。 set命令的功能还是比较强大的，比如获取从键盘中输入的字符： set /p a=\"Input a number:\" echo %a% 支持算术： set /a a=1+2 echo %a% set /a a-=1 echo %a% set /a a*=3 echo %a% set /a a/=3 echo %a% 这个关键在于set /a 还有字符串的修改和截取： :::::::::: 字符串的截取 :::::::::: set a=Hello Windows Bat :: 截取所有 set a=%a:~0% :: 截取指定的 set a=%a:~1,-1% set a=%a:~2,4% :::::::::: 字符串的替换 :::::::::: set a=Hello Windows :: 将Windows替换成Linux set a=%a:Windows=Linux% ","date":"2021-12-03","objectID":"/bat/:1:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"注释 bat 中能实现注释功能的有两个::和rem。 它们的不同点是：rem是一条命令，在运行的时候相当于把rem本身及其后面的内容置空。既然它是一条命令，就必须处于单独的一行或者有类似 “\u0026” 的连接符号连接。 bat 遇到以冒号 “:” 开头的行时（忽略冒号前的空格），会将其后的语句识别为“标记”而不是命令语句，因此类似 “:label” 这样的在 bat 中仅仅是一个标记。 注: 使用 bat 中的注释时需要注意一点，不要再 () 的边上使用注释。 ","date":"2021-12-03","objectID":"/bat/:2:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"条件判断 bat 中的条件判断也是使用if。 set a=1 if %a%==1 ( echo OK ) else ( echo ERROR ) 如果时判断字符串使用为空时,可以这样处理: set a=\"hello\" if (%a%)==() ( echo OK ) else ( echo ERROR ) ","date":"2021-12-03","objectID":"/bat/:3:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"循环语句 bat 中的循环有些不同。关键字也是for。还是先来看一个例子： for /f \"delims=: tokens=1,2,3\" %%i in ( \"2018:04:11\" ) do ( echo %%i echo %%j ) 这段脚本中需要注意的点是：delims=:表示使用 “:” 来分割字符串，而tokens=1,2,3则表示取出分割后的字符串的部分，从1开始。%%i是循环中的每个项。输出时%%i和%%j分别对应的就是截取的字段1和2。如果还需要输出第三个，也是使用%%k表示，依次类推。 但 bat 中的for会存在延迟赋值的情况，先来看一段脚本: for /f \"delims=: tokens=2\" %%i in ( 'ipconfig /all ^| findstr /i \"ipv4\" ' ) do ( echo %%i set a=%%i echo %a% ) 输出结果: IPv4 地址 . . . . . . . . . . . . : 192.168.168.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.157.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 %a%的值一直等于最后一项。 ","date":"2021-12-03","objectID":"/bat/:4:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"函数 bat 中函数是使用:label方式定义的，使用call来调用: call :test Hello World goto EXIT :test echo %1 %2 :EXIT 脚本中的goto用来跳转退出，而且函数要放在脚本的尾部，存在多个函数时还需要使用goto直接跳转，因为脚本是会按顺序执行下去的。 实战操作 @echo off set option=%1 set address=%2 if (%option%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if (%address%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if %option% == start ( call :start %address% ) else if %option% == stop ( call :stop %address% ) else ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) ::sc config msiscsi start=auto ::net start msiscsi goto EXIT :: 连接iscsi服务器 :start iscsicli QAddTargetPortal %1 for /f \"delims= tokens=1\" %%i in ( 'iscsicli ListTargets t ^| findstr /i \"iqn.2018-11\" ' ) do ( iscsicli qlogintarget %%i ) goto EXIT :: 断开iscsi服务器 :stop set a= for /f \"delims=: tokens=2\" %%i in ('iscsicli SessionList ^| findstr /i \"fffffa8\"') do ( set a=%%i goto return ) :return set a=%a: =0x% set a=%a:-=-0x% iscsicli LogoutTarget %a% iscsicli RemoveTargetPortal %1 3260 goto EXIT :EXIT 这个脚本是用来连接和断开iscsi服务器的。脚本有两个入参，option 和 address。连接和断开iscsi服务器。脚本的思路很简单，开始判断输入参数是否正确。然后根据 option 选择执行对应的函数。特别在:stop中，因为延时复制的关系，所以循环体中只放简单的复制，处理部分在外面进行处理。 后记 ","date":"2021-12-03","objectID":"/bat/:5:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"延时赋值问题 bat 的延时赋值有对应的解决方法： SETLOCAL ENABLEDELAYEDEXPANSION set a=hello set a=!a! set a=!a:~1! ","date":"2021-12-03","objectID":"/bat/:6:0","tags":null,"title":"Windows Bat总结","uri":"/bat/"},{"categories":null,"content":"搭建lamp环境 lamp即 apache + mysql + php，是互联网常用架构。 要注意的是php依赖apache和mysql，所以要最后安装。系统环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2021-12-03","objectID":"/lamp/:0:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2021-12-03","objectID":"/lamp/:1:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2021-12-03","objectID":"/lamp/:2:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2021-12-03","objectID":"/lamp/:3:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2021-12-03","objectID":"/lamp/:4:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2021-12-03","objectID":"/lamp/:5:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2021-12-03","objectID":"/lamp/:6:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2021-12-03","objectID":"/lamp/:7:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2021-12-03","objectID":"/lamp/:8:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装httpd 使用apache的httpd提供网络web服务 ","date":"2021-12-03","objectID":"/lamp/:9:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载httpd wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.2.31.tar.gz ","date":"2021-12-03","objectID":"/lamp/:10:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 tar -zxvf httpd-2.2.31.tar.gz ","date":"2021-12-03","objectID":"/lamp/:11:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"编译安装 # 编译 ./configure --prefix=/usr/local/apache \\ \u003e-with-include-apr --enable-so \\ \u003e--enable-deflate=shared \\ \u003e--enable-rewrite=shared \\ \u003e--enable-expires=shared \\ \u003e-with-pcre \\ \u003e-with-mpm=prefork make # 安装 make install 编译选项记录在/usr/local/apache/build/config.nice 中 ","date":"2021-12-03","objectID":"/lamp/:12:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"启动httpd /usr/local/apache/bin/apachectl start /usr/local/apache/bin/apachectl -M ：查看各种库 静态库(编译时直接放入下列文件) /usr/local/apache/bin/httpd 动态库(用到时加载) /usr/local/apache/modules/ /usr/local/apache/bin/apachectl -l ：查看静态库以及apache工作模式 /usr/local/apache/bin/apachectl -t ：查看配置文件有无语法错误 配置文件 /usr/local/apache/conf/httpd.conf /usr/local/apache/bin/apachectl graceful 加载配置文件 启动httpd时的警告： httpd: apr_sockaddr_info_get() failed for 【linux】 httpd: Could not reliably determine the server's fully qualified domain name, using 127.0.0.1 for ServerName 解决方法(问题在于主机名不匹配) 警告1 ：在/etc/hosts中的127.0.0.1行后添加linux 警告2 ：在httpd的配置文件/usr/local/apache/conf/httpd.conf中的ServerName行中改为 ServerName linux:80 ","date":"2021-12-03","objectID":"/lamp/:13:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"开机启动 修改启动脚本 cp /usr/local/apache/bin/apachectl /etc/init.d/httpd vim /etc/init.d/httpd 在#!/bin/bash下加入 #chkconfig:345 61 61 #description:Apache httpd 设置开机启动 chkconfig --add httpd chkconfig --level 345 httpd on 安装php ","date":"2021-12-03","objectID":"/lamp/:14:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"下载php wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2021-12-03","objectID":"/lamp/:15:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2021-12-03","objectID":"/lamp/:16:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-apxs2=/usr/local/apache/bin/apxs --with-config-file-path=/usr/local/php/etc --with-mysql=/usr/local/mysql --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif --disable-ipv6 #出现错误： configure: error: jpeglib.h not found. # 解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. #解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2021-12-03","objectID":"/lamp/:17:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"修改配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini vim /usr/local/apache/conf/httpd.conf 在 AddType application/x-compress .Z AddType application/x-gzip .gz .tgz 两行下加入 AddType application/x-httpd-php .php 将 DirectoryIndex index.html 后添加 1.php DirectoryIndex index.html 1.php ","date":"2021-12-03","objectID":"/lamp/:18:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"测试 在Apache的安装文件中添加php文件 /usr/local/apache/htdocs/目录下创建 vim 1.php \u003c?php echo \"Welcome to 1.php\" ; ?\u003e ","date":"2021-12-03","objectID":"/lamp/:19:0","tags":null,"title":"搭建lamp环境","uri":"/lamp/"},{"categories":null,"content":"搭建lnmp环境 lnmp即：nginx + mysql + php 与lamp不同的是，lnmp的php不在只是httpd中的一个库，lnmp架构中php作为一个服务，专门解析php。 同样的php依赖mysql，所以首先安装mysql 这里环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2021-12-03","objectID":"/lnmp/:0:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2021-12-03","objectID":"/lnmp/:1:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:2:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2021-12-03","objectID":"/lnmp/:3:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2021-12-03","objectID":"/lnmp/:4:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2021-12-03","objectID":"/lnmp/:5:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2021-12-03","objectID":"/lnmp/:6:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2021-12-03","objectID":"/lnmp/:7:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2021-12-03","objectID":"/lnmp/:8:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装php ","date":"2021-12-03","objectID":"/lnmp/:9:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载 wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2021-12-03","objectID":"/lnmp/:10:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2021-12-03","objectID":"/lnmp/:11:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --enable-fpm --with-fpm-user=php-fpm --with-fpm-group=php-fpm --with-mysql=/usr/local/mysql --with-mysql-sock=/tmp/mysql.sock --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-ftp --enable-mbstring --enable-exif --enable-zend-multibyte --disable-ipv6 --with-pear --with-curl # 出现错误： configure: error: jpeglib.h not found. #解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. # 解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2021-12-03","objectID":"/lnmp/:12:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"php的配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini ","date":"2021-12-03","objectID":"/lnmp/:13:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"php开机启动 cp /usr/src/php-5.4.45/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm mv /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf #服务启动的脚本配置文件 chkconfig --add php-fpm chkconfig --level 345 php-fpm on ","date":"2021-12-03","objectID":"/lnmp/:14:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"启动php useradd -s /sbin/nologin php-fpm chmod +x /etc/init.d/php-fpm service php-fpm start 安装nginx ","date":"2021-12-03","objectID":"/lnmp/:15:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"下载nginx cd /usr/src wget http://nginx.org/download/nginx-1.6.2.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:16:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"解压 tar -xvf nginx-1.6.2.tar.gz ","date":"2021-12-03","objectID":"/lnmp/:17:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"编译安装 ./configure --prefix=/usr/local/nginx --with-pcre #出现错误： ./configure: error: the HTTP rewrite module requires the PCRE library. #解决方法： yum install -y pcre-devel make make install ","date":"2021-12-03","objectID":"/lnmp/:18:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"启动 编辑启动脚本 vim /etc/init.d/nginx #!/bin/bash # chkconfig: - 30 21 # description: http service. # Source Function Library . /etc/init.d/functions # Nginx Settings NGINX_SBIN=\"/usr/local/nginx/sbin/nginx\" NGINX_CONF=\"/usr/local/nginx/conf/nginx.conf\" NGINX_PID=\"/usr/local/nginx/logs/nginx.pid\" RETVAL=0 prog=\"Nginx\" start() { echo -n $\"Starting $prog: \" mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL } stop() { echo -n $\"Stopping $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL } reload(){ echo -n $\"Reloading $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL } restart(){ stop start } configtest(){ $NGINX_SBIN -c $NGINX_CONF -t return 0 } case \"$1\" in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $\"Usage: $0{start|stop|reload|restart|configtest}\" RETVAL=1 esac exit $RETVAL 保存后，更改权限: chmod 755 /etc/init.d/nginx chkconfig --add nginx 开机启动 chkconfig nginx on 启动服务 service nginx start ","date":"2021-12-03","objectID":"/lnmp/:19:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"测试解析php 编辑配置文件/usr/local/nginx/conf/nginx.conf 修改制定行 ...... location ~ \\.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; #路径为网站根目录 include fastcgi_params; } ...... 在/usr/local/nginx/html/下创建一个info.php文件 \u003c?php phpinfo(); ?\u003e 浏览器访问：http://127.0.0.1/info.php测试 ","date":"2021-12-03","objectID":"/lnmp/:20:0","tags":null,"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":null,"content":"深入理解计算机系统 ","date":"2021-12-03","objectID":"/csapp/:0:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"一、计算机系统漫游 计算机系统是由硬件和软件组成。 ","date":"2021-12-03","objectID":"/csapp/:1:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.1 信息就是位 + 上下文 系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串 bit 表示的。区分不同数据对象的唯一方法是我们读到这些数据对象是的上下文。 ","date":"2021-12-03","objectID":"/csapp/:1:1","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.2 程序被其他程序翻译成不同的格式 ","date":"2021-12-03","objectID":"/csapp/:1:2","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.3 了解编译系统如何工作是大有益处的 为什么程序员必须要知道编译系统是如何工作的? 优化程序性能。 理解链接时出现的错误。 避免安全漏洞。 ","date":"2021-12-03","objectID":"/csapp/:1:3","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.4 处理器读并解释储存在内存中指令 系统硬件组成 总线: 贯穿整个系统的一组电子管道，称作总线，他携带信息字节并负责在各个部件间传递。 I/O 设备: 系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器或者适配器与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是 I/O 设备本身或者系统的主印制电路板上的芯片组。而适配器则是一块插在主板插槽上的卡。 主存: 主存是一个临时存储设备，在处理执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存储存储器 (DRAM) 芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址(数组索引)，这些地址是从零开始的。 处理器：中央处理单元 (CPU)，简称处理器，是解释(或)执行存储在主存中指令的引擎、处理器的核心是一个大小与一个字的存储设备(或寄存器)，称为程序计数器(PC)。在任何时刻，PC 都指向主存中的某条机器语言指令。 系统执行一个 Hello World 程序时，硬件运行流程。 键盘输入命令时，shell 程序将字符逐一读入寄存器，再存放到内存中。 键入回车键后，shell 执行一系列指令来加载可执行的 hello 文件，将 hello 目标文件中的代码和数据从磁盘复制到内存。 处理器开始执行 hello 程序 main 程序中的机器语言指令。 这些指令将输出的字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。 ","date":"2021-12-03","objectID":"/csapp/:1:4","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.5 高速缓存至关重要 系统运行时会频繁的挪动信息，而不同存储设备之间的读写性能有严重偏差 (从寄存器中读取数据比从主存中读取快 100 被，从主存中读取又比磁盘中快 1000 万倍)。所以不同存储设备间需要高速缓存来提供系统运行速度。 这里的高速缓存是相对概念。 ","date":"2021-12-03","objectID":"/csapp/:1:5","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.6 存储设备形成层次结构 ","date":"2021-12-03","objectID":"/csapp/:1:6","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.7 操作系统管理硬件 我们并不直接访问硬件，而是通过操作系统。所有应用程序对硬件的操作尝试都必须通过操作系统。 操作系统有两个基本功能: 防止硬件被失控的应用程序滥用。 向应用程序提供简单一致的机制来控制复杂而又通常不大相同的低级硬件设备。 操作系统通过几个基本抽象概念来实现这两个功能。 进程: 操作系统对一个正在运行的程序的一种抽象。 上下文: 操作系统保持跟踪进程运行所需的所有状态信息，其中包含 PC 和寄存器文件的当前值，以及主存的内存。 在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换。这一过程有操作系统内核 (kernel) 管理。 线程: 现代操作系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都裕兴在进程的上下文中，并共享同样的代码和全局数据。 虚拟机内存是一个抽象概念，它为每个进程提供一个假象，即每个进程都在独占地使用主存，每个进程看到的内存都是一致的，称为虚拟地址空间。 虚拟地址空间从下至上依次为: 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。 堆。堆可以在运行时动态地扩展和收缩。 共享库。存放 C 标准库和数学库这些共享库的代码和数据。 栈。位于用户虚拟地址空间顶部，编译器用它来实现函数调用，它和堆一样在程序运行期间可以动态地扩展和收缩。每次调用一个函数时，栈就会增长，从一个函数返回时，栈就会收缩。 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，他们必须调用内核来执行这些操作。 文件就是字节序列！每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成文件。 ","date":"2021-12-03","objectID":"/csapp/:1:7","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.8 系统之间利用网络通信 硬件和软件组合成一个系统，而通过网络间不同的主机连接成一个更广大的现代系统。 ","date":"2021-12-03","objectID":"/csapp/:1:8","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"1.9 重要主题 并发 (concurrency): 一个同时具有多个活动的系统。 并行 (parallelism): 用并发来是一个系统运行得更快。 超线程：有时称为同时多线程 (simultaneous multi-threading)，是一项允许一个 CPU 执行多个控制流的技术。 抽象的使用是计算机科学中最为重要的概念之一。这里介绍四个抽象: 文件是对 I/O 设备的抽象。 虚拟内存是对程序存储器的抽象。 进程是对一个正在运行的程序的抽象。 虚拟机是对整个计算机的抽象。 ","date":"2021-12-03","objectID":"/csapp/:1:9","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"三、程序的机器级表示 ","date":"2021-12-03","objectID":"/csapp/:2:0","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.1 历史观点 Intel 处理器系列俗称 x86。 摩尔定律: 1965 年， Gordon Moore, Intel 公司的创始人根据当时的芯片技术做出推断，预测在未来 10 年，芯片上的晶体管数量每年都会翻一番。这个预测就成为摩尔定律。 ","date":"2021-12-03","objectID":"/csapp/:2:1","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.2 程序编码 机器级编程重要的两种抽象: 由指令级体系结构或指令集架构(Instruction Set Architecture, ISA) 来定义机器级程序的格式和行为，它定义了处理器状态、指令的格式，以及每条指令对状态的影响。 机器级程序使用的内存地址是虚拟地址，提供的内存模型看上去是一个非常大的字节数组。 汇编代码非常接近于机器代码，它的主要特点是它用可读性更好的文本格式表示。 程序内存包含：程序的可执行机器代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，以及用户分配的内存块。 一条机器指令只能执行一个非常基本的操作。 ","date":"2021-12-03","objectID":"/csapp/:2:2","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.3 数据格式 Intel 中数据格式： 字 word: 表示 16 位数据类型 双字 double words: 32 位数 四字 qoad words: 64 位数 C 语言数据类型在 x86-64 中的大小。在 64 为机器中，指针长 8 字节。 大多数GCC生成的汇编代码指令都有一个字符的后缀，表明操作数的大小。例如。数据传送指令有四个变种： movb: 传送字节 movw: 传送字 movl: 传送双字 movq: 传送四字 ","date":"2021-12-03","objectID":"/csapp/:2:3","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.4 访问信息 一个 x86-64 的中央处理单元 CPU 包含一组 16 个存储 64 位值的通用目的寄存器，这些寄存器用来存储整数数据和指针。 关于寄存器的说明可以参考: X86-64 寄存器和栈帧 x86_64 寄存器介绍 大多数指令有一个或多个操作数(operand)，指示出执行一个操作中要使用到的源数据值，以及放置结果的目的位置。 存放操作数的类型： 立即数(immediate)，用来表示常数值。格式是 ‘$’ 后面跟一个标准 C 表示法表示的整数。比如 $-577或$0x1F。 寄存器(register)，它表示某个寄存器的内容，用符号 $R_a$ 表示。 内存引用，它会根据计算出来的地址(通常称为有效地址)访问某个内存位置。使用 $M_b$[Addr] 表示对存储在内存中从 Addr 开始的 b 个字节值的引用。 多种不同的寻址方式，允许不同形式的内存引用。 Imm($r_b$, $r_i$, s) : 一个立即数偏移 Imm，一个基址寄存器 $r_b$，一个变址寄存器 $r_i$ 和一个比例因子 s，s 必须是 1、2、4、8。基址和变址寄存器都必须是 64 位寄存器。有效地址为 Imm+R[$r_b$]+R[$r_i$]*s。 计算题: 有以下内存地址和寄存器的值: 得出以下操作数的值: 操作数 值 注释 %rax 0x100 寄存器 0x104 0xAB 绝对地址 $0x108 0x108 立即数 (%rax) 0xFF 地址 0x100 4(%rax) 0xAB 地址 0x104 9(%rax,%rdx) 0x11 地址 0x10C 260(%rax,%rdx) 0x13 地址 0x108 OxFC(,%rcx,4) 0xFF 地址 0x100 (%rax,%rdx,4) 0x11 地址 0x10C 数据传送指令: 将数据从一个位置复制到另一个位置。 源操作数指定的值是一个立即数，存储在寄存器或者内存中。目的操作数指定一个位置，寄存器或者内存地址。 x86-64 中传送指令的两个操作数不能都指向内存位置，内存间的复制需要两条指令。 MOV 的五种可能组合: movl $0x4050, $eax ; Immediate -- Register, 4 bytes movw %bp, %sp ; Register -- Register, 2 bytes movb (%bp, %rcx), %al ; Memory -- Register, 1 bytes movb $-17, (%rsp) ; Immediate -- Memory, 1 bytes movq %rax, -12(%rbp) ; Register -- Memory, 8 bytes MOVZ 类中指令把目的中剩余的字节填充为0。 MOVS 类中的指令通过符号扩展来填充，把源操作的最高为进行复制。 下面是一个数据传送示例: long exchange(long *xp, long y) { long x = *xp; *xp = y; return x; } 执行命令 gcc -Og -S main.c 生成以下汇编内容: exchange: movq (%rdi), %rax movq %rsi, (%rdi) ret 可以看出: C 语言的 “指针” 其实就是地址。间接引用指针就是间该指针放在一个寄存器中，然后再内存引用中使用这个寄存器。 最后的两个数据传送操作: 将数据压入程序栈中，从程序栈中弹出数据。 pushq %rbp ; 栈指针减8，然后将值写到新的栈顶地址。 ; 等同于 subq $8, %rsp ; Decrement stack pointer movq %rbp, (%rsp) ; Store %rbp on stack 操作示意图: popq %rbp ; 弹出一个四字的操作包括从栈顶位置读出数据，然后减栈指针加8。 ; 等同于 movq %rsp, (%rax) ; Read %rax from stack addq $8, %rsp ; Increment stack pointer ","date":"2021-12-03","objectID":"/csapp/:2:4","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.5 算术和逻辑操作 指令类 ADD 由四条加法指令组成: addb 字节加法、addw 字加法、addl 双字加法 和 addq 四字加法。 这些操作被分成四组: 加载有效地址、一元操作、二元操作和移位。 加载有效地址(load effective address)指令 leaq 实际上是 movq 指令的变形。它的指令形式是从内存读数据到寄存器，但实际上它根本就没有引用内存。 long scale(long x, long y, long z) { long t = x + 4 * y + 12 * z; return t; } 得到汇编命令: _scale: ## @scale .cfi_startproc ## %bb.0: pushq %rbp movq %rsp, %rbp leaq (%rdi,%rsi,4), %rax leaq (%rdx,%rdx,2), %rcx leaq (%rax,%rcx,4), %rax popq %rbp retq 一元操作数只有一个操作数，既是源又是目的。如 incq (%rsp)。 二元操作数，第二个操作数既是源又是目的。如 subq %rax,%rdx。 移位操作，先给出移位量，然后第二项是要移位。可以进行算术和逻辑右移。位移量可以是一个立即数，或者放在单字节寄存器 %cl 中(移位操作指令只允许以这个特定的寄存器作为操作数)。 特殊的算术操作 以下的 C 代码: #include \u003cinttypes.h\u003e typedef unsigned __int128 uint128_t; void store_uprod(uint128_t *dest, uint64_t x, uint64_t y) { *dest = x * (uint128_t) y; } void remdiv(long x, long y, long *qp, long *rp) { long q = x / y; long r = x%y; *qp = q; *rp = r; } 生成汇编 store_uprod: movq %rsp, %rbp movq %rdx, %rax ; Copy x to multiplicand mulq %rsi ; Multiply by y movq %rdx, 8(%rdi) ; Store upper 8 bytes at dest+8 movq %rax, (%rdi) ; Store lower 8 bytes at dest retq remdiv: movq %rsp, %rbp movq %rdx, %r8 ; Copy qp movq %rdi, %rax ; Move x to lower 8 bytes of dividend cqto ; Sign-extend to upper 8 bytes of dividend idivq %rsi ; Divide by y movq %rax, (%r8) ; Store remainder at rp movq %rdx, (%rcx) ; Store quotient at qp retq ","date":"2021-12-03","objectID":"/csapp/:2:5","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.6 控制 CPU 还维护着一组单个位的条件码 (condition code) 寄存器，它们描述了最近的算术或逻辑操作的属性。可以检测这些寄存器来执行条件分支指令。最常用的条件码有: CF: 进位标志。最近的操作使最高位产生了进位。可以来检查无符号操作的溢出。 ZF: 零标志。最近的操作得出的结果为0。 SF: 符号标志。最近的操作得到的结果为负数。 OF: 溢出标志。最近的操作导致一个补码溢出 —— 正溢出或负溢出。 条件码通常不会直接读取，常用的使用方法有三种: 可以根据条件码的某种组合，将一个字节设置为 0 或者 1。 可以条件跳转到程序的某个其他部分。 可以有条件地创送数据。 SET 指令是根据条件码的某种组合，将一个字节设置为 0 或者 1的一整类指令。这些指令的后缀表示不同的条件而不是操作数的大小。如 setl 表示 “小于时设置 (set less)”。 setb 表示 “低于时设置 (set below)”。 一条 SET 指令的目的操作数是低位单字节寄存器元素之一，或者是一个字节的内存位置，指令会将这个字节设置成 0 或者 1。 跳转 (jump) 指令会导致执行切换到程序中一个全新的位置。在汇编代码中，这些跳转的目的地通常用一个标号 (label) 指明。 movq $0,%rax ; Set %rax to 0 jmp .L1 ; Goto .L1 movq (%rax), %rdx ; Null pointer dereference (skipped) .L1: popq %rdx ; Jump target 实现条件操作的传统方法是通过使用控制的条件转移。当条件满足时，程序沿着一条执行路径执行，而当条件不满足是，就走另一条路径。但这个方法在现代处理器上可能会非常低效。 另一种策略是使用数据的条件转移。这个方法计算一个条件操作的两种结果，然后再根据条件是否满足从中选取一个。 汇编中没有循环指令存在，可以用条件测试和跳转组合起来实现循环效果。 long fact_do(long n) { long result = 1; do { result *= n; n = n - 1; } while (n \u003e 1); return result; } 生成汇编代码: _fact_do: ## @fact_do pushq %rbp movq %rsp, %rbp movl $1, %eax LBB0_1: ## =\u003eThis Inner Loop Header: Depth=1 imulq %rdi, %rax decq %rdi cmpq $1, %rdi jg LBB0_1 popq %rbp retq switch 语句可以根据一个整数索引值进行多重分支 (multiway branching)。switch 会被转化成跳转表 (jump table)。跳转表示一个数组，表项 i 是一个代码段的地址，这个代码段实现当开关索引值等于 i 时程序应该采取的动作。程序代码用开关索引值来执行一个跳转表内的数组引用，确定跳转指令的目标。和使用一组很长的 if-else 语句对比，使用跳转表的优点是执行开关语句的时间与开关情况的数量无关。 C switch 代码: void switch_eg(long x, long n, long *dest) { long val = x; switch (n) { case 100: val *= 13; break; case 102: val += 10; case 103: val += 11; break; case 104: case 106: val *= val; break; default: val = 0; } *dest = val; } 生成汇编: .section __TEXT,__text,regular,pure_instructions .build_version macos, 10, 15, 4 sdk_version 10, 15, 4 .globl _switch_eg ## -- Begin function switch_eg .p2align 4, 0x90 _switch_eg: ## @switch_eg ## %bb.0: pushq %rbp movq %rsp, %rbp xorl %eax, %eax addq $-100, %rsi cmpq $6, %rsi ja LBB0_7 ## %bb.1: leaq LJTI0_0(%rip), %rcx movslq (%rcx,%rsi,4), %rsi addq %rcx, %rsi jmpq *%rsi LBB0_5: imulq %rdi, %rdi jmp LBB0_6 LBB0_2: leaq (%rdi,%rdi,2), %rax leaq (%rdi,%rax,4), %rax jmp LBB0_7 LBB0_3: addq $10, %rdi LBB0_4: addq $11, %rdi LBB0_6: movq %rdi, %rax LBB0_7: movq %rax, (%rdx) popq %rbp retq ","date":"2021-12-03","objectID":"/csapp/:2:6","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.7 过程 过程是软件中一种很重要的抽象。它提供了一种封装代码的方式，用一组指定的参数和一个可选的返回值实现了某种功能。然后，可以在程序中不同的地方调用这个函数。设计良好的如软件用过程作为抽象机制，隐藏某个行为的具体实现，同时又提供清晰简洁的接口定义，说明要计算的是哪些值，过程会对程序状态产生说明样的影响。 不同编程语言中，过程的形式: 函数 (function) 方法 (method) 子例程 (subroutine) 处理函数 (handler) 假设过程 P 调用过程 Q，Q 执行后返回 P。过程可能用到的一个或多个机制: 传递控制。在进入过程 Q 的时候，程序计数器必须被设置为 Q 的代码的起始地址，然后再返回时，要把程序计数器设置为 P 中调用 Q 后面那条指令的地址。 传递数据。P 必须能够向 Q 提供一个或多个参数，Q 必须能够向 P 返回一个值。 分配和释放内存。在开始是，Q 可能需要为局部变量分配空间，而在返回前，又必须释放这些存储空间。 3.7.1 传递控制 C 语言过程调用中使用栈数据结构提供的后进先出的内存管理原则。 程序可以用栈来管理它的过程所需要的存储空间，栈和程序寄存器存放这传递控制和数据、分配内存所需要的信息。当 P 调用 Q 时，控制和数据信息添加到栈尾。当 P 返回时，这些信息会释放掉。 当 x86-64 过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间。这个部分称为过程的栈帧(stack frame)。当前正在执行的过程的帧总是在栈顶。 3.7.2 转移控制 将控制从函数 P 转移到函数 Q 只需要简单地把程序计数器(PC)设置为 Q 的代码的起始位置。不过，当稍后从 Q 返回的时候，处理器必须记录好需要继续 P 的执行的代码位置。在 x86-64 机器中，这个信息是用指令 call Q 调用过程 Q 来记录的。该指令会把地址 A 压入栈中，并将 PC 设置为 Q 的起始地址。压入的地址 A 被称为返回地址，是紧跟在 call 指令后面的那条指令的地址。对应的指令 ret 会从栈中弹出地址 A，并把 PC 设置为 A。 call 指令有一个目标，即指明被调用过程起始的指令地址。同调整一样，调用可能是直接的，也可以是间接的。在汇编代码中，直接调用的目标是一个标号，而间接调用的目标是 * 后面跟讴歌操作数指示符。 3.7.3 数据创送 数据传送: 当调用一个过程时，除了要把控制传递给它并在过程返回时再传递回来之外，过程调用还可能包括吧数据作为参数传递，而从过程返回还有可能包括返回一个值。 x86-64中，可能通过寄存器最多传递 6 个整型(例如整数和指针)参数。寄存器的使用是由特殊顺序的，寄存器使用的名字取决于要传递的数据类型的大小。 如果一个函数有大于 6 个整型参数，超出 6 个的部分就要通过栈来传递。 void proc(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) { *a1p += a1; *a2p += a2; *a3p += a3; *a4p += a4; } 3.7.4 栈上的局部存储 需要栈上局部存储的情况: 寄存器不能足够存放素有的本地数据。 对一个局部变量使用地址运算符 ‘\u0026’, 因此必须能够为他产生一个地址。 某些局部变量是数组或结构，因此必须能够通过数据或结构引用被访问到。 long call_proc() { long x1 = 1; int x2 = 2; short x3 = 3; char x4 = 4; proc(x1, \u0026x1, x2, \u0026x2, x3, \u0026x3, x4, \u0026x4); // 创建栈帧 return (x1 + x2) * (x3 - x4); } 3.7.5 寄存器中的局部存储空间 寄存器组是唯一被所有过程共享的资源，为了防止寄存器的值在被一个过程使用时，不被其他过程调用导致值被覆盖，x86-64 采用一组统一的寄存器使用惯例: 寄存器 %rbx、%rbp 和 %r12~%r15 被划分为被调用者寄存器，Q 过程必须保证寄存器值的安全。 除了栈指针 %rsp, 都分类为调用者保存寄存器。 3.7.6 递归过程 递归调用一个函数本身与调用其他函数时一样的。栈规则提供了一种机制，每次函数调用都有它自己私有的状态信息(保存的返回位置和被调用者保存寄存器的值)存储空间。如果需要，它还可以提供局部变量的存储。栈分配和释放的规则很自然就与函数调用-返回的循序匹配。这种实现函数调用和返回的方法甚至对更复杂的情况也适用，暴扣互相递归调用。 long rfact(long n) { long result; if (n \u003c= 1) { result = 1; } else { result = n * rfact(n - 1); } return result; } 对应汇编代码: rfact: pushq %rbx movq %rdi, rbx movl $1, %eax cmpq $1, %rdi jle .L35 leaq -1(%rdi), %rdi call rfact imulq %rbx, %rax .L35: popq %rbx ret ","date":"2021-12-03","objectID":"/csapp/:2:7","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.8 数组分配和访问 C 语言的数组是一种将标量数据聚集成更大数据类型的方式。 3.8.1 基本原则 对于数据类型 T 和整型常数 N，声明如下: T A[N]; 起始位置表示为 $x_A$。这个声明有两个效果。首先，它在内存中分配一个 L·N 字节的连续区域。这里 L 是数据类型 T 的大小(单位为字节)。其次，它引入了标识符 A，可以用 A 来作为指向数组开头的指针，这个指针的值就是 $x_A$。可用用 0~N-1 的证书索引来访问该数组元素。数组元素 i 会被存放在地址为 $x_A$+L·i 的地方。 3.8.2 指针运算 C 语言允许对指针进行运算，而计算出来的值会根据该指针引用的数据类型的大小进行伸缩。也就是说，如果 p 是一个指向类型为 T 的数据的指针，p 的值为 $x_p$，那么表达式 p+i 的值为 $x_p$+L·i，这里 L 是数据类型 T 的大小。 单操作数操作符 ‘$’ 和 ‘* ' 可以产生指针和间接引用指针。对于一个表示某个对象的表达式 Expr，\u0026Expr 是该对象的一个指针。对于一个表示地址的表达式 AExpr, *AExpr 是该地址的值。因此，表达式 Expr 与 * \u0026Expr 是等价的。可以对数组和指针应用数组下标操作。 3.8.3 嵌套数组 要访问多维数组的元素，编译器会以数组起始为基地址，偏移量为索引，产生计算期望的元素偏移量，然后使用某种 MOV 指令。 通常来说，对于一个声明如下的数组: T D[R][C] 的元素 D[i][j] 的内存地址为 $$ D[i][j] = x_D+L(C·i+j) $$ 3.8.4 定长数组 C语言编译器能够优化定长多维数组上的操作代码 ","date":"2021-12-03","objectID":"/csapp/:2:8","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.9 异质的数据结构 C 语言2提供了两种将不同类型的对象组合到一起创建数据类型的机制: 结构 (structure)，关键字 struct，将多个对象集合到一个单位中。 联合 (union)，用关键字 union 来声明，允许用几种不同的类型来引用一个对象。 3.9.1 结构 C 语言的 struct 声明创建一个数据类型，将可能不同类型的对象聚合到一个对象中。用名字来引用结构的各个组成部分。类似于数组的实现，结构的所有组成部分都存放在内存中一段连续的区域内，而指向结构的指针就是结构第一个字节的地址。 struct rect { int i; int j; int a[2]; int *p; }; 该结构在内存中的布局: 3.9.2 联合 联合提供了一种方式，能够规避 C 语言的类型系统，允许以多种类型来引用一个对象。一个联合的总的大小等于它最大字段的大小。 在一些上下文中，联合十分有用。但是，它也能引起一些讨厌的错误，因为他们绕过了 C 语言类型系统提供的安全措施。一种应用情况是，我们事先知道对一个数据结构中的两个不同字段的使用是互斥的，那么将这两个字段声明为联合的一部分，而不是结构的一部分，会减小分配空间的总量。 3.9.3 数据对齐 许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值 K (通常是2、4或8)的倍数。这种对齐限制简化了形成处理器和内存系统之间接口的硬件设计。 无论数据是否对齐，x86-64 硬件都能正确工作。不过，Intel 还是建议要对齐数据以提高内存系统的性能。对齐原则是任何 K 字节的基本对象的地址必须是 K 的倍数。 确保每种数据类型都是按照指定方式来组织和分配，即每种类型的对象都满足它的对齐限制，就可保证实施对齐。编译器在汇编代码中放入命令，指明全局数据所需的对齐。 .align 8 这命令就保证了它后面的数据的开始地址是 8 的倍数。因为每个表项长 8 个字节，后面的元素都会遵守 8 字节对齐的限制。 对于包含结构的代码，编译器可能需要在字段的分配中插入间隙，以保证每个结构元素都满足它的对齐要求。而结构本身对它的起始地址也有一些对齐要求。 假设如下的结构声明: struct S1 { int i; char c; int j; } 如果编译器用最小的9字节分配，内存布局会是这样: 但是它不满足字段 i 和 j 的4字节对齐要求，所以编译器在字段 c 和 j 之间插入一个 3 字节的间隙: ","date":"2021-12-03","objectID":"/csapp/:2:9","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.10 在机器级程序中将控制与数据结合起来 3.10.1 理解指针 一些指针和它们映射到机器代码的关键原则: 每个指针都对应一个类型。这个类型表明该指针指向的是哪一类对象。 每个指针都有一个值。这个值是某个指定类型的对象的地址。特殊的 NULL(0) 值表示该指针没有指向任何地方。 指针用 ‘\u0026’ 运算符创建。 *操作符用于间接引用指针。其结果是一个值，它的类型与该指针的类型一致。间接引用是用内存来实现的，要么是存储到一个指定的地址，要么是从指定的地址读取。 数组与指针紧密联系。一个数组的名字可以像一个指针变量一样引用(但是不能修改)。 将指针从一种类型强制转化成另一个类型，只改变它的类型，而不改变它的值。强制类型转换的一个效果是改变指针运算的伸缩。 指针也可以指向函数。这提供了一个很强大的存储和向代码传递引用的功能，这个引用可以被程序的某个其他部分调用。 函数指针: #include \u003cstdio.h\u003e int fun(int x, int *p); int (*fp)(int, int *); int main() { fp = fun; int y = 1; int result = fp(3, \u0026y); printf(\"%d\\n\", result); } int fun(int x, int *p) { *p += x; return *p; } ","date":"2021-12-03","objectID":"/csapp/:2:10","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":null,"content":"3.11 浮点代码 处理器的浮点系统结构包括多个方面，会影响对浮点数据操作的程序如何被映射到机器上，包括: 如何存储和访问浮点数据。通常是通过某种寄存器方式来完成。 对浮点数据操作的指令。 向函数传递浮点数参数和从函数返回浮点数结构的规则。 函数调用过程中保存寄存器的规则。 x86-64 浮点体系结构的历史: 如图所示，AVX 浮点体系结构允许数据存储在 16 个 YMM 寄存器中，名字是 %ymm0~%ymm15。每个 YMM 寄存器都是 256(32 字节)。当对标量数据操作时，这些寄存器值保存浮点数，而且只使用低 32 位(对于 float) 或 64 位(对于 double)。汇编代码用寄存器的 SSE XMM 寄存器名字 %xmm0~%xmm15 来引用它们，每个 XMM 寄存器都是对应的 YMM 寄存器的低 128 位(16字节)。 3.11.1 浮点传送和转化操作 GCC 只用标量传送操作从内存传送数据到 XMM 寄存器或从 XMM 寄存器传送数据到内存。对于在两个 XMM 寄存器之间传送数据，GCC 会使用两种指令之一，即用 vmpovaps 传送单精度数，用 vmovapd 传送双精度数。对于这些情况，程序复制整个寄存器还是只复制低位值。既不会影响程序功能，也不会影响执行速度，所以使用这些指令还是针对标量数据的人指令没有实质上的差别。指令名字中的字母 ‘a’ 表示 “aligned(对齐的)\"。当用于读写内存是，如果地址不满足16字节对齐，它们会导致异常。在两个寄存器之间传送数据，绝不会出现错误对齐的状况。 浮点数和整数数据类型之间以及不同浮点格式之间进行转换的指令集合。 把一个从 XMM 寄存器或内存中读出的浮点值进行转换，并将结果写入一个通用寄存器。把浮点值转换成整数时，指令会执行截断(truncation)，把值向 0 进行舍入。 3.11.2 过程中的浮点代码 在 x86-64 中，XMM 寄存器用来向函数传递浮点参数，以及从函数返回浮点值。具有以下规则: XMM 寄存器 %xmm0~%xmm7 最多可以传递 8 个浮点参数。按照参数列出的顺序使用这些寄存器。可以通过栈传递额外的浮点参数。 函数使用寄存器 %xmm0 来返回浮点值。 所有的 XMM 寄存器都是调用者保存的。被调用者可以不同保存就覆盖这些寄存器中任意一个。 当函数包含指针、整数和浮点数混合的参数时，指针和整数通过通用寄存器传递，而浮点值通过 XMM 寄存器传递。也就是说，参数到寄存器的映射取决于它们的类型和排列的顺序。例如: // 这个函数会把 x 存放在 %edi 中，y 放在 %xmm0 中，z 放在 %rsi 中。 double f1(int x, double y, long z); // 这个函数的寄存器分配与函数 f1 相同。 double f2(double y, int x, long z); // 这个函数会将 x 放在 %xmm0 中，y 放在 %rdi 中，z 放在 %rsi 中。 double f1(float x, double *y, long *z); 3.11.3 浮点运算操作 下图描述了一组执行算术运算的标量 AVX2 浮点指令。每条指令有一个($S_1$)或两个($S_1, S_2$)，和一个目的操作数 D。第一个源操作数 $S_1$ 可以是一个 XMM 寄存器或一个内存位置。第二个源操作数和目的操作数都必须是 XMM 寄存器。每个操作多有一条针对当精度的指令和一条针对双精度的指令。结果存放在目的寄存器中。 3.11.4 定义和使用浮点常数 和整数运算操作不同，AVX 浮点操作不能以立即数值作为操作数。相反，编译器必须为所有的常量值分配和初始化存储空间。然后代码再把这些值从内存读入。 3.11.5 在浮点代码中使用位级操作 3.11.6 浮点比较操作 浮点比较指令会设置三个条件码: 零标志位 ZF, 进位标志位 CF 和奇偶标志位 PF。 ","date":"2021-12-03","objectID":"/csapp/:2:11","tags":null,"title":"深入理解计算机系统","uri":"/csapp/"}]